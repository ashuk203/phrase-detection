

Iteration 1...

Sorted Patterns:
[[{'TEXT': 'in'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'for'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'with'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'that'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'from'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'the'}, {'TEXT': 'art'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'with'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'using'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'novel'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'machine'}, {'TEXT': 'learning'}, {'POS': 'NOUN'}], [{'TEXT': 'recently'}, {'TEXT': 'proposed'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'real'}, {'TEXT': 'world'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'black'}, {'TEXT': 'box'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'first'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'on'}, {'TEXT': 'two'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': '\n'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'many'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'large'}, {'TEXT': 'scale'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': '\n'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'learning'}, {'TEXT': 'and'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'which'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': '\n'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'learning'}, {'TEXT': 'and'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'benchmark'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'end'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'using'}, {'TEXT': 'standard'}, {'POS': 'NOUN'}], [{'TEXT': 'we'}, {'TEXT': 'study'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'many'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'particular'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'processing'}, {'TEXT': 'and'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'global'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'large'}, {'POS': 'NOUN'}], [{'TEXT': 'vision'}, {'TEXT': 'and'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': '\n'}, {'TEXT': 'supervised'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'fundamental'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'other'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': '\n'}, {'TEXT': 'can'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'conventional'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'commonly'}, {'TEXT': 'used'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'statistical'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'large'}, {'TEXT': 'training'}, {'POS': 'NOUN'}], [{'TEXT': 'highly'}, {'TEXT': 'successful'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'traditional'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': '\n'}, {'TEXT': 'many'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'to'}, {'TEXT': 'other'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'numerous'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'speech'}, {'TEXT': 'recognition'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'information'}, {'TEXT': 'retrieval'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'current'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'vision'}, {'TEXT': 'or'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'retrieval'}, {'TEXT': 'and'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'go'}, {'TEXT': 'atari'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'from'}, {'TEXT': 'complex'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'and'}, {'TEXT': 'standard'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'most'}, {'TEXT': 'used'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': '\n'}, {'TEXT': 'explainable'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'robotics'}, {'TEXT': 'and'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'deploy'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'transparently'}, {'TEXT': 'enabling'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'which'}, {'TEXT': 'many'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'methods'}, {'TEXT': 'utilize'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'near'}, {'TEXT': 'optimal'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'driven'}, {'TEXT': 'relational'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'segmentation'}, {'TEXT': '.'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'TEXT': 'solving'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'high'}, {'TEXT': 'performance'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'recent'}, {'TEXT': 'years'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'some'}, {'TEXT': 'classical'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'an'}, {'TEXT': 'autonomous'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'neuroscience'}, {'TEXT': 'and'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'and'}, {'TEXT': 'optimizing'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'many'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'networks'}, {'TEXT': 'based'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'actively'}, {'TEXT': 'researched'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'deployed'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'pushing'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'that'}, {'TEXT': 'make'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'to'}, {'TEXT': 'its'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'classifiers'}, {'TEXT': 'and'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'have'}, {'TEXT': 'enabled'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'human'}, {'TEXT': 'learning'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'challenged'}, {'TEXT': 'adaptive'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'classical'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'on'}, {'TEXT': 'popular'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'outperform'}, {'TEXT': 'other'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'outperform'}, {'TEXT': 'traditional'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'can'}, {'TEXT': 'design'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'particular'}, {'TEXT': 'automated'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'to'}, {'TEXT': 'executing'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'like'}, {'TEXT': 'other'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'gpu'}, {'TEXT': 'accelerated'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'conventional'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'art'}, {'TEXT': 'supervised'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'preprocessors'}, {'TEXT': 'and'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'extend'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'develop'}, {'TEXT': 'new'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'basic'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'agent'}, {'TEXT': 'driven'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'using'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'attempts'}, {'TEXT': 'using'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'other'}, {'TEXT': 'standard'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'mining'}, {'TEXT': 'and'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'fully'}, {'TEXT': 'automated'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'fully'}, {'TEXT': 'automating'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'many'}, {'TEXT': 'classical'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'cognitive'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'ehr'}, {'POS': 'VERB'}], [{'TEXT': '\n'}, {'TEXT': 'chemical'}, {'POS': 'VERB'}], [{'TEXT': 'propose'}, {'TEXT': 'cognitive'}, {'POS': 'NOUN'}], [{'TEXT': 'custom'}, {'TEXT': 'oriented'}, {'POS': 'NOUN'}], [{'TEXT': 'endowing'}, {'TEXT': 'relational'}, {'POS': 'NOUN'}], [{'TEXT': 'endow'}, {'TEXT': 'relational'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'relational'}, {'POS': 'NOUN'}], [{'TEXT': 'unlabeled'}, {'TEXT': 'chemical'}, {'POS': 'NOUN'}], [{'TEXT': 'microsoft'}, {'TEXT': 'coco'}, {'POS': 'NOUN'}]]
Sorted Keywords:
['machine learning', 'deep learning', 'neural networks', 'natural language', 'neural network', 'reinforcement learning', 'speech recognition', 'deep networks', 'deep reinforcement learning', 'real world', 'machine translation', 'training data', 'artificial intelligence', 'question answering', 'neural machine translation', 'computer vision', 'visual question answering', 'language modeling', 'real time', 'sentiment analysis', 'object recognition', 'gradient descent', 'representation learning', 'image classification', 'automatic speech recognition', 'unsupervised learning', 'language models', 'word embeddings', 'large scale', 'object detection', 'transfer learning', 'character level', 'natural language processing', 'domain adaptation', 'word level', 'feature extraction', 'high level', 'visual dialog', 'classification problems', 'word embedding', 'feature learning', 'dialogue systems', 'beam search', 'semantic segmentation', 'data driven', 'multi label', 'hidden layers', 'black box', 'back propagation', 'pattern recognition', 'model based', 'generative models', 'long term', 'higher level', 'neural architectures', 'multi task', 'sequence labeling', 'data sets', 'language understanding', 'generative model', 'benchmark datasets', 'stochastic gradient descent', 'encoder decoder', 'image segmentation', 'multi agent', 'many applications', 'multi label classification', 'gradient based', 'structured prediction', 'information retrieval', 'neural models', 'dimensionality reduction', 'training samples', 'knowledge base', 'evolutionary algorithms', 'statistical machine translation', 'model parameters', 'batch normalization', 'recurrent network', 'network architecture', 'text classification', 'input features', 'multi view', 'latent variables', 'sentence classification', 'experimental results', 'attention based', 'multi layer', 'sequence modeling', 'residual networks', 'graphical models', 'computational cost', 'data set', 'open domain', 'local minima', 'deep reinforcement', 'activation functions', 'meta learning', 'stochastic gradient', 'neural machine', 'deep learning models', 'network architectures', 'multi class', 'memory networks', 'training set', 'curriculum learning', 'latent variable', 'error rate', 'building blocks', 'domain knowledge', 'classification tasks', 'input output', 'genetic programming', 'dynamic programming languages', 'goal oriented', 'test set', 'lstm networks', 'long range', 'feature representations', 'image processing', 'continuous speech', 'end framework', 'natural language generation', 'data augmentation', 'high quality', 'information extraction', 'adversarial perturbations', 'natural language understanding', 'latent space', 'deep learning images', 'classification accuracy', 'neural network models', 'neural network language', 'deep learning algorithms', 'neural language modeling', 'deep learning methods', 'fewer parameters', 'deep learning architectures', 'sample extension', 'multi language image', 'gesture recognition', 'natural language text', 'response generation', 'abstract syntax trees', 'real world applications', 'neural sequence models', 'error rates', 'recent years', 'evaluation metrics', 'neural network layers', 'sentence level', 'automatic speech', '3d point clouds', 'variational inference', 'image recognition', 'higher level inference', 'deep convolution', 'neural network sentence', 'decision making', 'neural language', 'many nlp applications', 'intelligent text recognition', 'neural turing', 'better speech recognition', 'batch size', '3d point', 'real time object', 'convolutional architectures', 'sparse windows generation', 'dynamic programming', 'recurrent network models', 'optical character', 'convolutional layer computation', 'neural sequence', 'unsupervised domain adaptation', 'algorithms', 'neural network architecture', 'latent dirichlet', 'malware images', 'knowledge bases', 'optimization algorithms', 'free text', 'dynamic programming algorithm', 'iterative image segmentation', 'electronic health records', 'arcade learning', 'deep learning approaches', 'new source nodes', 'user interactions', 'statistical machine', '3d data', 'maximum likelihood', 'backpropagation', 'feature repository', 'hand crafted', 'backpropagation training', 'deep learning tasks', 'unsupervised domain', 'embedded devices', 'many computer vision', '3d computed', 'black box optimization', 'semantic image segmentation', 'extensible self service', 'optimization algorithm', 'many machine learning', 'statistical machine translations', 'algorithm known', 'hierarchical reinforcement learning', 'current computing possibilities', 'recent work', 'neural sequence modeling', 'speech tagging', 'convolutional nets', 'neural dependency', 'deeper networks', 'deep models', 'optical character recognition', 'recurrent network architectures', 'latent sentences', 'artificial intelligence c', 'mathematical language processing', 'image analysis', 'multi agent domains', 'speech tags', 'visual turing test', 'error detection', 'extensible self', 'semantic parsing tasks', 'particular machine learning', 'outputs recognition', 'relation classification', 'many nlp tasks', 'neural network decisions', 'malware classification', 'different network architectures', 'better user experience', 'deep learning dl', 'high level features', 'embedded speech recognition', 'lstm models', 'network training', 'kernel machines', 'artificial intelligence models', 'feature selection', 'resource constrained', 'visual dialog systems', 'visual object recognition', 'visual dialog models', 'natural language data', 'most nlp applications', 'multiple image datasets', 'optimization problems', 'medical image analysis', 'inference engines', 'neural networks area', 'interior point methods', 'image data', 'language processing', 'artificial intelligence systems', 'kernel based', 'document parsing', 'input hidden', 'word error', 'real users', 'art parsing', 'simple rnns', 'dependency parsing', 'neural approach', 'feature preprocessors', 'traditional computer vision', 'previous work', 'third party developers', 'convolutional layer', 'code generation', 'recurrent networks', 'semantic parsing', 'better recognition accuracies', 'gaussian process', 'deep learning approach', 'hierarchical reinforcement', 'structured prediction problems', 'question answer', 'gradient updates', 'ai tasks', 'databases', 'text data', 'mobile applications', 'other algorithms', 'open information extraction', 'deep auto encoders', 'linear autoencoders', 'd vector extraction', 'neural error', 'artificial networks', 'several language modeling', 'less computation', 'inductive program synthesis', 'unsupervised pattern classification', 'neural error detection']

Iteration 2...

Sorted Patterns:
[[{'TEXT': 'in'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'on'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'of'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'from'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'in'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'that'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'neural'}, {'TEXT': 'network'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'as'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'recurrent'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'from'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'propose'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': '\n'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'in'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'propose'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'deep'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'from'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'novel'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'from'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'of'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'using'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'art'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'the'}, {'TEXT': 'proposed'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': '\n'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'novel'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'that'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'using'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'by'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'and'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'a'}, {'TEXT': 'novel'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'that'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'short'}, {'TEXT': 'term'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'a'}, {'TEXT': 'new'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'art'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'that'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'recently'}, {'TEXT': 'proposed'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'and'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'is'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'art'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'as'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'POS': 'VERB'}, {'POS': 'VERB'}], [{'TEXT': 'on'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'by'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'TEXT': 'an'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'PROPN'}, {'POS': 'NOUN'}], [{'TEXT': 'into'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'PROPN'}], [{'TEXT': 'for'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'our'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'a'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'new'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'new'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'to'}, {'TEXT': 'learn'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'recurrent'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'than'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'the'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'the'}, {'POS': 'NOUN'}], [{'TEXT': 'term'}, {'TEXT': 'memory'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'novel'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'as'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'real'}, {'TEXT': 'world'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'new'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'present'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'and'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'through'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'across'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'introduce'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'our'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'towards'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'over'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'VERB'}], [{'TEXT': 'from'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'while'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'PROPN'}, {'POS': 'NOUN'}], [{'TEXT': 'by'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'the'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'and'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'proposed'}, {'POS': 'NOUN'}], [{'TEXT': 'that'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'with'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'the'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'end'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': '\n'}, {'TEXT': 'learning'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'that'}, {'TEXT': 'these'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'high'}, {'TEXT': 'dimensional'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'between'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'from'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'in'}, {'TEXT': 'an'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'the'}, {'POS': 'NOUN'}], [{'TEXT': '\n'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'deep'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'two'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'first'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'to'}, {'POS': 'NOUN'}], [{'TEXT': 'develop'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'zero'}, {'TEXT': 'shot'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'art'}, {'POS': 'NOUN'}], [{'TEXT': 'sequence'}, {'TEXT': 'to'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}], [{'TEXT': 'to'}, {'TEXT': 'end'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'ADJ'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'PROPN'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'these'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'via'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'ADJ'}, {'POS': 'VERB'}], [{'TEXT': 'recently'}, {'TEXT': 'proposed'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'deep'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'black'}, {'TEXT': 'box'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'by'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'supervised'}, {'TEXT': 'and'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'PROPN'}], [{'TEXT': 'in'}, {'TEXT': 'many'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'data'}, {'TEXT': 'and'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'like'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'via'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}], [{'TEXT': 'than'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'deep'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'that'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'through'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'deep'}, {'TEXT': 'learning'}, {'POS': 'NOUN'}], [{'TEXT': 'machine'}, {'TEXT': 'learning'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'natural'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'simple'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'large'}, {'TEXT': 'scale'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'unlike'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'end'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'an'}, {'TEXT': 'unsupervised'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'g'}, {'TEXT': '.'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'we'}, {'TEXT': 'explore'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'PROPN'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'into'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'for'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'NOUN'}], [{'TEXT': 'over'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'our'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'modeling'}, {'TEXT': 'and'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'improve'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'we'}, {'TEXT': 'propose'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'reinforcement'}, {'TEXT': 'learning'}, {'POS': 'NOUN'}], [{'TEXT': 'by'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'large'}, {'TEXT': 'scale'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'develop'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'use'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'TEXT': 'the'}, {'POS': 'NOUN'}], [{'TEXT': 'propose'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'deep'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'representations'}, {'TEXT': 'and'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'between'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'train'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'at'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'to'}, {'TEXT': 'generate'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'two'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'train'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'into'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'a'}, {'TEXT': 'deep'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'word'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'presents'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': '\n'}, {'TEXT': 'deep'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'proposed'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'ADJ'}, {'POS': 'PROPN'}], [{'TEXT': 'in'}, {'TEXT': 'image'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'that'}, {'TEXT': 'this'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'on'}, {'POS': 'ADJ'}, {'POS': 'PROPN'}], [{'TEXT': 'a'}, {'TEXT': 'deep'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': '.'}, {'TEXT': 'however'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'like'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'data'}, {'TEXT': 'and'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'via'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'POS': 'ADJ'}, {'POS': 'VERB'}], [{'TEXT': 'learning'}, {'TEXT': 'and'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'novel'}, {'POS': 'NOUN'}, {'POS': 'ADJ'}], [{'TEXT': 'classification'}, {'TEXT': 'and'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'by'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'to'}, {'POS': 'PROPN'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'among'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'all'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'recurrent'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}]]
Sorted Keywords:
['neural networks', 'deep learning', 'neural network', 'machine learning', 'reinforcement learning', 'natural language', 'speech recognition', 'deep reinforcement learning', 'training data', 'deep networks', 'machine translation', 'question answering', 'real world', 'language modeling', 'gradient descent', 'visual question answering', 'language models', 'neural machine translation', 'sentiment analysis', 'language model', 'real time', 'computer vision', 'representation learning', 'artificial intelligence', 'character level', 'automatic speech recognition', 'large scale', 'unsupervised learning', 'object detection', 'word embeddings', 'object recognition', 'experimental results', 'transfer learning', 'image classification', 'domain adaptation', 'word level', 'model based', 'feature extraction', 'multi label', 'black box', 'learning rate', 'feature learning', 'results show', 'data driven', 'encoder decoder', 'generative models', 'high level', 'generative model', 'benchmark datasets', 'semi supervised', 'classification problems', 'word embedding', 'multi task', 'long term', 'knowledge base', 'network architecture', 'dialogue systems', 'higher level', 'multi layer', 'back propagation', 'hidden layers', 'supervised learning', 'language understanding', 'attention mechanism', 'multi label classification', 'semantic segmentation', 'deep network', 'information retrieval', 'attention based', 'pattern recognition', 'beam search', 'data set', 'visual dialog', 'data sets', 'natural language processing', 'network architectures', 'sequence labeling', 'stochastic gradient descent', 'image segmentation', 'objective function', 'hidden layer', 'neural architectures', 'latent variable', 'neural language models', 'multi agent', 'gradient based', 'adversarial perturbations', 'batch normalization', 'latent variables', 'residual networks', 'activation functions', 'recurrent network', 'memory networks', 'test set', 'learning algorithms', 'evolutionary algorithms', 'neural models', 'error rate', 'optimization problem', 'dimensionality reduction', 'learning algorithm', 'classification tasks', 'training set', 'goal oriented', 'computational cost', 'lstm rnn', 'adversarial examples', 'pre trained', 'structured prediction', 'prior knowledge', 'local minima', 'statistical machine translation', 'batch size', 'input output', 'model parameters', 'training samples', 'loss function', 'meta learning', 'sequence modeling', 'multi view', 'text classification', 'open domain', 'acoustic models', 'textual entailment', 'multi class', 'latent space', 'deep reinforcement', 'multi task learning', 'input features', 'many applications', 'curriculum learning', 'existing approaches', 'stochastic gradient', 'graphical models', 'neural network architecture', 'language processing', 'existing methods', 'evaluation metrics', 'continuous speech', 'extreme learning', 'pre training', 'lstm networks', 'sentence classification', 'classification accuracy', 'domain knowledge', 'recent work', 'high quality', 'genetic programming', 'general purpose', 'deep learning approach', 'deep learning models', 'relation classification', 'image processing', 'memory network', 'experiments show', 'results suggest', 'learning models', 'algorithms', 'recognition tasks', 'neural network language', 'data augmentation', 'feature representations', 'maximum likelihood', 'neural machine', 'error rates', 'variational inference', 'programming language', 'phoneme recognition', 'long range', 'activation function', 'target language', 'previous work', 'sentence level', 'building blocks', 'neural language', 'feature space', 'response generation', 'fewer parameters', 'networks rnns', 'neural network models', 'question answer', 'large vocabulary', 'hand crafted', 'natural language understanding', 'deep learning methods', 'input sequence', 'memory lstm', 'deep q', 'deep learning architectures', 'spectral clustering', 'better performance', 'automatic speech', 'backpropagation', 'network training', 'deep learning algorithms', 'source sentence', 'natural language generation', 'real world applications', 'decision making', 'learning tasks', 'information extraction', 'output layer', 'de identification', 'dynamic programming languages', 'deep learning based', 'open source', 'turing test', 'network rnn', 'model achieves', 'image recognition', 'gaussian process', 'sequence learning', 'image analysis', 'deep learning approaches', 'speaker recognition', 'embedded devices', 'deep learning opens', 'optimization algorithm', 'deep learning applied', 'neural language modeling', 'image', 'neural turing', 'input', 'model', 'end framework', 'universal perturbations', 'data', 'neural network model', 'classification performance', 'doom game', 'deep learning framework', 'vector representations', 'feature selection', 'several benchmark datasets', 'real time embedded', 'kernel based', 'many machine learning', 'attention model', 'deep learning images', 'neural network rnn', 'floating point', 'neural sequence', 'significant improvement', 'semantic parsing', 'value function', 'optimization problems', 'latent dirichlet', 'semantic image segmentation', 'extreme learning machines', 'statistical machine', 'malware', 'layer wise', 'knowledge bases', 'real world user', 'standard benchmark datasets', 'unsupervised feature', 'optical character', 'neural sequence models', 'networks dnns', 'deep learning dl', 'learning machines', 'gesture recognition', 'convolutional networks', 'neural network learning', '3d point clouds', 'dependency parsing', 'optical character recognition', 'learning methods', 'recurrent network models', 'backpropagation algorithm', 'multi language image', 'black box optimization', 'word error', 'neural network approach', 'language inference', 'new features', 'enhance developer', '3d environment', 'neural turing machine', 'visual object recognition', 'network based', 'algorithm', 'abstract syntax trees', 'skip thought', 'recurrent networks', 'neural network dnn', 'deep learning makes', 'natural language text', 'dynamic programming', 'text', 'simplified speech recognition', 'improve performance', 'modern gpu clusters', 'visual turing test', 'unsupervised domain', 'atari domain', 'convolutional nets', 'gradient updates', 'deep models', 'error detection']

Iteration 3...

Sorted Patterns:
[[{'TEXT': 'in'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'ADJ'}, {'POS': 'ADJ'}], [{'TEXT': 'for'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'for'}, {'POS': 'ADJ'}, {'POS': 'ADJ'}], [{'TEXT': 'on'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'POS': 'ADJ'}, {'POS': 'ADJ'}], [{'TEXT': 'with'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'for'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'from'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'in'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'that'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'neural'}, {'TEXT': 'network'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'from'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'propose'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'of'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'recurrent'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': '\n'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'propose'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'from'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'deep'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'novel'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'from'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'of'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'using'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'propose'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'ADJ'}], [{'TEXT': 'the'}, {'TEXT': 'art'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'the'}, {'TEXT': 'proposed'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'a'}, {'TEXT': 'novel'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'propose'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'deep'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': '.'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'the'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': '\n'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'using'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'that'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'by'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'and'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'a'}, {'TEXT': 'novel'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'that'}, {'TEXT': 'our'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'that'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'short'}, {'TEXT': 'term'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'art'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'that'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'and'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'PROPN'}, {'POS': 'VERB'}], [{'TEXT': 'is'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'new'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}], [{'TEXT': 'the'}, {'TEXT': 'art'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'POS': 'VERB'}, {'POS': 'VERB'}], [{'TEXT': 'recurrent'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'PROPN'}], [{'TEXT': 'on'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'by'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'into'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'PROPN'}], [{'TEXT': '.'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'TEXT': 'an'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'PROPN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'new'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'of'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'art'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'learn'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'new'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}], [{'TEXT': 'than'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'our'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'recently'}, {'TEXT': 'proposed'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'that'}, {'TEXT': 'the'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'novel'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'on'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'a'}, {'TEXT': 'single'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'real'}, {'TEXT': 'world'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'new'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'present'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'and'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'through'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'ADJ'}], [{'TEXT': 'the'}, {'TEXT': 'deep'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'across'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'our'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'introduce'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'towards'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'POS': 'NOUN'}, {'POS': 'ADJ'}], [{'TEXT': 'over'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'PROPN'}, {'POS': 'NOUN'}], [{'TEXT': 'term'}, {'TEXT': 'memory'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'from'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'while'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'PROPN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'PROPN'}, {'POS': 'ADJ'}], [{'TEXT': 'with'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'the'}, {'POS': 'NOUN'}], [{'TEXT': 'and'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'that'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': '.'}, {'TEXT': 'the'}, {'POS': 'NOUN'}], [{'TEXT': 'by'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': '\n'}, {'TEXT': 'learning'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'the'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'that'}, {'TEXT': 'these'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'to'}, {'POS': 'VERB'}], [{'TEXT': 'between'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'by'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'the'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'from'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'recurrent'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'in'}, {'TEXT': 'an'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'end'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}], [{'TEXT': '\n'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'on'}, {'TEXT': 'two'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'first'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'develop'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'short'}, {'TEXT': 'term'}, {'POS': 'NOUN'}, {'POS': 'PROPN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'VERB'}], [{'TEXT': 'zero'}, {'TEXT': 'shot'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'POS': 'ADJ'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'this'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'high'}, {'TEXT': 'dimensional'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'the'}, {'POS': 'NOUN'}], [{'TEXT': 'with'}, {'POS': 'NOUN'}], [{'TEXT': 'recently'}, {'TEXT': 'proposed'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'via'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'sequence'}, {'TEXT': 'to'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'TEXT': 'a'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'these'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'neural'}, {'TEXT': 'network'}, {'POS': 'NOUN'}], [{'TEXT': 'black'}, {'TEXT': 'box'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'end'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'by'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'a'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'to'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'POS': 'ADJ'}, {'POS': 'PROPN'}], [{'TEXT': 'neural'}, {'TEXT': 'networks'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}], [{'TEXT': 'supervised'}, {'TEXT': 'and'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'deep'}, {'TEXT': 'reinforcement'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'machine'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'data'}, {'TEXT': 'and'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'and'}, {'TEXT': 'the'}, {'POS': 'NOUN'}], [{'TEXT': 'via'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'than'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'from'}, {'POS': 'ADJ'}], [{'TEXT': 'from'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'that'}, {'TEXT': 'the'}, {'POS': 'NOUN'}], [{'TEXT': 'through'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'in'}, {'TEXT': 'many'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'art'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'like'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'simple'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'of'}, {'TEXT': 'natural'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'ADJ'}, {'POS': 'VERB'}], [{'TEXT': 'unlike'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'end'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'deep'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'a'}, {'TEXT': 'visual'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'g'}, {'TEXT': '.'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'the'}, {'TEXT': 'neural'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'TEXT': 'a'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}], [{'TEXT': 'we'}, {'TEXT': 'explore'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'POS': 'PROPN'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'the'}, {'POS': 'NOUN'}], [{'TEXT': 'into'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'for'}, {'TEXT': 'the'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'for'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'NOUN'}], [{'TEXT': 'large'}, {'TEXT': 'scale'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'TEXT': 'a'}, {'POS': 'NOUN'}], [{'TEXT': '.'}, {'TEXT': 'our'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'improve'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'by'}, {'TEXT': 'the'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'large'}, {'TEXT': 'scale'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'natural'}, {'TEXT': 'language'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'deep'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'develop'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'to'}, {'TEXT': 'use'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'as'}, {'POS': 'VERB'}, {'POS': 'NOUN'}], [{'TEXT': 'over'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'deep'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'in'}, {'TEXT': 'a'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}, {'POS': 'VERB'}], [{'TEXT': 'we'}, {'TEXT': 'propose'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}], [{'TEXT': 'representations'}, {'TEXT': 'and'}, {'POS': 'NOUN'}, {'POS': 'NOUN'}], [{'TEXT': 'of'}, {'TEXT': 'a'}, {'POS': 'NOUN'}]]
Sorted Keywords:
['neural networks', 'deep learning', 'neural network', 'machine learning', 'reinforcement learning', 'natural language', 'speech recognition', 'deep reinforcement learning', 'training data', 'deep networks', 'machine translation', 'question answering', 'real world', 'language modeling', 'gradient descent', 'visual question answering', 'language models', 'language model', 'neural machine translation', 'sentiment analysis', 'semi supervised', 'real time', 'computer vision', 'artificial intelligence', 'representation learning', 'attention mechanism', 'automatic speech recognition', 'character level', 'large scale', 'unsupervised learning', 'word embeddings', 'object detection', 'object recognition', 'learning rate', 'experimental results', 'transfer learning', 'supervised learning', 'image classification', 'domain adaptation', 'word level', 'high dimensional', 'model based', 'feature extraction', 'multi label', 'black box', 'deep convolutional', 'data driven', 'encoder decoder', 'generative models', 'high level', 'feature learning', 'benchmark datasets', 'generative model', 'deep network', 'word embedding', 'classification problems', 'deep neural', 'objective function', 'multi task', 'hidden layer', 'long term', 'knowledge base', 'neural language models', 'learning algorithm', 'dialogue systems', 'higher level', 'network architecture', 'multi layer', 'back propagation', 'results show', 'multi label classification', 'hidden layers', 'semantic segmentation', 'language understanding', 'information retrieval', 'pattern recognition', 'pre trained', 'attention based', 'prior knowledge', 'learning algorithms', 'lstm rnn', 'beam search', 'existing methods', 'visual dialog', 'data set', 'data sets', 'natural language processing', 'recognition tasks', 'network architectures', 'sequence labeling', 'learning models', 'image segmentation', 'stochastic gradient descent', 'neural architectures', 'acoustic models', 'pre training', 'multi agent', 'loss function', 'gradient based', 'latent variable', 'adversarial perturbations', 'optimization problem', 'batch normalization', 'residual networks', 'latent variables', 'adversarial examples', 'activation functions', 'memory network', 'multi task learning', 'large vocabulary', 'recurrent network', 'existing approaches', 'feature space', 'memory networks', 'textual entailment', 'test set', 'evolutionary algorithms', 'error rate', 'neural models', 'de identification', 'extreme learning', 'general purpose', 'classification tasks', 'training set', 'recurrent neural', 'computational cost', 'goal oriented', 'dimensionality reduction', 'structured prediction', 'local minima', 'statistical machine translation', 'batch size', 'proposed method', 'input output', 'model parameters', 'training samples', 'sequence modeling', 'multi view', 'open domain', 'text classification', 'meta learning', 'deep q', 'recursive neural', 'multi class', 'better performance', 'generative adversarial', 'latent space', 'deep reinforcement', 'non linear', 'many applications', 'input features', 'learning tasks', 'programming language', 'curriculum learning', 'graphical models', 'stochastic gradient', 'continuous speech', 'evaluation metrics', 'neural network architecture', 'layer wise', 'open source', 'activation function', 'language processing', 'sentence classification', 'lstm networks', 'classification accuracy', 'model', 'domain knowledge', 'recent work', 'spectral clustering', 'phoneme recognition', 'high quality', 'attention model', 'genetic programming', 'experiments show', 'deep learning models', 'networks rnns', 'data', 'image processing', 'relation classification', 'vector representations', 'memory lstm', 'model achieves', 'significant improvement', 'image', 'results suggest', 'learning machines', 'deep learning approach', 'learning methods', 'feature representations', 'algorithm', 'data augmentation', 'turing test', 'maximum likelihood', 'neural machine', 'neural network language', 'target language', 'error rates', 'variational inference', 'output layer', 'input sequence', 'input', 'network rnn', 'convolutional neural', 'long range', 'deep learning based', 'previous work', 'skip thought', 'building blocks', 'proposed model', 'sentence level', 'neural language', 'network based', 'neural network model', 'source sentence', 'response generation', 'fewer parameters', 'neural network models', 'value function', 'question answer', 'floating point', 'language inference', 'hand crafted', 'algorithms', 'neural', 'natural language understanding', 'classification performance', 'deep learning methods', 'malware', 'deep learning architectures', 'improve performance', 'speaker recognition', 'sequence learning', 'neural network rnn', 'deep learning algorithms', 'network training', 'automatic speech', 'universal perturbations', 'natural language generation', 'real world applications', 'decision making', 'artificial neural', 'model outperforms', 'network', 'information extraction', 'text', 'dynamic programming languages', 'neural turing machine', 'image analysis', 'gaussian process', 'neural network dnn', 'image recognition', 'deep learning approaches', 'extreme learning machines', 'embedded devices', 'neural networks rnns', 'convolutional networks', 'penn treebank', 'deep learning opens', 'optimization algorithm', 'deep learning applied', 'neural language modeling', 'neural turing', 'multilayer perceptron', 'deep learning framework', 'end framework', 'doom game', 'deep', 'backpropagation', 'enhance developer', 'feature selection', 'unsupervised feature', 'neural network approach', 'several benchmark datasets', 'challenging task', 'kernel based', 'real time embedded', 'deep learning images', 'many machine learning', 'neural sequence', 'models', 'semantic image segmentation', 'semantic parsing', 'latent dirichlet', 'optimization problems', 'method', 'statistical machine', 'knowledge bases', 'real world user', 'evolutionary algorithm', 'networks', 'framework', 'standard benchmark datasets', 'networks dnns', 'neural sequence models', 'optical character', 'deep learning dl', 'backpropagation algorithm', 'gesture recognition', 'networks rnn']
Final Sorted Keywords:
[('neural networks', 1.0864029229229815), ('deep learning', 1.0656432774497229), ('neural network', 1.0635100019316603), ('machine learning', 1.0389277342799663), ('reinforcement learning', 1.0249798814983664), ('natural language', 1.0226716439581685), ('speech recognition', 1.0135141022368637), ('deep reinforcement learning', 1.0078225293474954), ('training data', 1.006812680670135), ('deep networks', 1.0066201789693414), ('machine translation', 1.0058111342384248), ('question answering', 1.0054832107347327), ('real world', 1.004935484871314), ('language modeling', 1.004511874869501), ('gradient descent', 1.0043161287167903), ('visual question answering', 1.004315268324755), ('language models', 1.0040855791603154), ('language model', 1.003887482258332), ('neural machine translation', 1.0031984043313766), ('sentiment analysis', 1.0031758281248098), ('semi supervised', 1.0028750468434842), ('real time', 1.0027468845606806), ('computer vision', 1.0025823622065744), ('artificial intelligence', 1.0024553065468658), ('representation learning', 1.0024383988764096), ('attention mechanism', 1.0023262397133512), ('automatic speech recognition', 1.0022169950835982), ('character level', 1.0022127761295454), ('large scale', 1.0021820593934132), ('unsupervised learning', 1.0021471447271226), ('word embeddings', 1.0021102808319966), ('object detection', 1.002085497510097), ('object recognition', 1.0020167951752161), ('learning rate', 1.0020145647763035), ('experimental results', 1.0020077356507897), ('transfer learning', 1.001944543440022), ('supervised learning', 1.0019421541323243), ('image classification', 1.001937296970565), ('domain adaptation', 1.0018821488125869), ('word level', 1.0017794501131578), ('high dimensional', 1.0017472332562622), ('model based', 1.0015778544643588), ('feature extraction', 1.0014763508744011), ('multi label', 1.0013869294372184), ('black box', 1.001380158439581), ('deep convolutional', 1.0013709369049146), ('data driven', 1.0012801374177953), ('encoder decoder', 1.0012478402050229), ('generative models', 1.0012448221138583), ('high level', 1.0012429995080447), ('feature learning', 1.0012200629096961), ('benchmark datasets', 1.001211210631991), ('generative model', 1.001199411353973), ('deep network', 1.0011762540723674), ('word embedding', 1.0011762444665762), ('classification problems', 1.001158363286764), ('deep neural', 1.00113790748264), ('objective function', 1.0011343876294752), ('multi task', 1.0011088131590533), ('hidden layer', 1.0010979231897563), ('long term', 1.0010959925931462), ('knowledge base', 1.0010687218321426), ('neural language models', 1.0010646991758878), ('learning algorithm', 1.0010430113691755), ('dialogue systems', 1.001036434042527), ('higher level', 1.00102744727279), ('network architecture', 1.001020146403737), ('multi layer', 1.001018657291253), ('back propagation', 1.0010138747918296), ('results show', 1.0010043172743825), ('multi label classification', 1.0009961536316472), ('hidden layers', 1.0009899123177817), ('semantic segmentation', 1.000977143195805), ('language understanding', 1.0009562298066088), ('information retrieval', 1.0009523479342484), ('pattern recognition', 1.0009440788905721), ('pre trained', 1.0009385380988496), ('attention based', 1.0009344050889177), ('prior knowledge', 1.0009277011120672), ('learning algorithms', 1.000906096074981), ('lstm rnn', 1.000860003523913), ('beam search', 1.0008467801045895), ('existing methods', 1.0008454723451212), ('visual dialog', 1.0008243940632588), ('data set', 1.0008201084843855), ('data sets', 1.0007944581052), ('natural language processing', 1.0007864984552324), ('recognition tasks', 1.0007673648599646), ('network architectures', 1.0007605239956936), ('sequence labeling', 1.000749248018228), ('learning models', 1.0007400507555453), ('image segmentation', 1.0007390845837703), ('stochastic gradient descent', 1.000737919392712), ('neural architectures', 1.000720985229642), ('acoustic models', 1.000712939464519), ('pre training', 1.0006990224501795), ('multi agent', 1.000696766576316), ('loss function', 1.0006949682396888), ('gradient based', 1.0006851963885754), ('latent variable', 1.000681708999549), ('adversarial perturbations', 1.0006688864988882), ('optimization problem', 1.0006607080101215), ('batch normalization', 1.0006416704847247), ('residual networks', 1.0006351412774526), ('latent variables', 1.0006292911548917), ('adversarial examples', 1.0006270309676133), ('activation functions', 1.0006205338942722), ('memory network', 1.0006184579385011), ('multi task learning', 1.00060937897717), ('large vocabulary', 1.000605668700795), ('recurrent network', 1.0006027564921565), ('existing approaches', 1.0005896335440616), ('feature space', 1.0005884956582327), ('memory networks', 1.0005880792662005), ('textual entailment', 1.0005789891360373), ('test set', 1.0005708496701748), ('evolutionary algorithms', 1.0005455184859218), ('error rate', 1.0005343298125804), ('neural models', 1.0005323002557824), ('de identification', 1.0005230995283825), ('extreme learning', 1.0005181879823541), ('general purpose', 1.0005178824480208), ('classification tasks', 1.0005176374753142), ('training set', 1.0005149734054615), ('recurrent neural', 1.0005125271503954), ('computational cost', 1.0005022283480824), ('goal oriented', 1.0005005076811215), ('dimensionality reduction', 1.0004981938232862), ('structured prediction', 1.000491403593), ('local minima', 1.0004853589132698), ('statistical machine translation', 1.0004834090422603), ('batch size', 1.000471111883159), ('proposed method', 1.000470994406056), ('input output', 1.000466301238833), ('model parameters', 1.0004648023547171), ('training samples', 1.0004540824925918), ('sequence modeling', 1.0004500042252893), ('multi view', 1.0004497189865134), ('open domain', 1.0004496676504542), ('text classification', 1.0004479780506779), ('meta learning', 1.0004432397327925), ('deep q', 1.0004382823367535), ('recursive neural', 1.0004357293091135), ('multi class', 1.0004283107106353), ('better performance', 1.0004272356395658), ('generative adversarial', 1.0004263398959181), ('latent space', 1.0004249131227192), ('deep reinforcement', 1.0004225222805996), ('non linear', 1.0004173353766523), ('many applications', 1.0004161996619427), ('input features', 1.0004152890796905), ('learning tasks', 1.000410975709152), ('programming language', 1.0004059007555195), ('curriculum learning', 1.0003964710677633), ('graphical models', 1.000393546671743), ('stochastic gradient', 1.0003933124447928), ('continuous speech', 1.0003857677395613), ('evaluation metrics', 1.0003840936280852), ('neural network architecture', 1.0003794743884622), ('layer wise', 1.0003737198136498), ('open source', 1.0003719927760153), ('activation function', 1.0003716713121866), ('language processing', 1.0003714812729836), ('sentence classification', 1.000368432817551), ('lstm networks', 1.0003644076244187), ('classification accuracy', 1.0003624992788585), ('model', 1.0003603649060409), ('domain knowledge', 1.000359864925595), ('recent work', 1.0003584795328473), ('spectral clustering', 1.0003563864920557), ('phoneme recognition', 1.0003556851183908), ('high quality', 1.000354380614611), ('attention model', 1.00035203109287), ('genetic programming', 1.0003511838838328), ('experiments show', 1.0003469278336736), ('deep learning models', 1.0003456479495016), ('networks rnns', 1.0003452187668012), ('data', 1.0003422158849071), ('image processing', 1.0003368600768803), ('relation classification', 1.000335239080314), ('vector representations', 1.000334159112026), ('memory lstm', 1.000333887844179), ('model achieves', 1.0003338724336048), ('significant improvement', 1.0003328364151733), ('image', 1.0003272776466956), ('results suggest', 1.0003265658621234), ('learning machines', 1.000326111852193), ('deep learning approach', 1.0003259442320998), ('learning methods', 1.0003198551977552), ('feature representations', 1.0003186829951953), ('algorithm', 1.000315496082786), ('data augmentation', 1.000315460092366), ('turing test', 1.0003143418969918), ('maximum likelihood', 1.0003125761993716), ('neural machine', 1.000312339191402), ('neural network language', 1.0003071524583027), ('target language', 1.0003062663371909), ('error rates', 1.0003030280723495), ('variational inference', 1.0003013899869757), ('output layer', 1.0002962805181446), ('input sequence', 1.0002896968402928), ('input', 1.0002869636973213), ('network rnn', 1.0002868355804), ('convolutional neural', 1.0002842036161212), ('long range', 1.000283929774228), ('deep learning based', 1.0002815720698293), ('previous work', 1.0002804124865015), ('skip thought', 1.000279192349703), ('building blocks', 1.0002762181334361), ('proposed model', 1.000275968762103), ('sentence level', 1.0002730448234682), ('neural language', 1.0002728364476758), ('network based', 1.000272375863146), ('neural network model', 1.000271730879751), ('source sentence', 1.000270863305323), ('response generation', 1.0002690171461912), ('fewer parameters', 1.0002682278736237), ('neural network models', 1.000265103939208), ('value function', 1.000264654010355), ('question answer', 1.0002590827162172), ('floating point', 1.0002576742262708), ('language inference', 1.000257123788676), ('hand crafted', 1.0002568862948509), ('algorithms', 1.0002497684954486), ('neural', 1.0002496649125858), ('natural language understanding', 1.000246155985389), ('classification performance', 1.0002437078946627), ('deep learning methods', 1.0002436813850493), ('malware', 1.0002434721562523), ('deep learning architectures', 1.0002414069068941), ('improve performance', 1.0002408444910618), ('speaker recognition', 1.0002394017530576), ('sequence learning', 1.0002365802326822), ('neural network rnn', 1.0002358003601663), ('deep learning algorithms', 1.0002336619782084), ('network training', 1.0002324736328736), ('automatic speech', 1.000231989010518), ('universal perturbations', 1.000229457149822), ('natural language generation', 1.0002289186315565), ('real world applications', 1.0002269193969742), ('decision making', 1.0002266141950524), ('artificial neural', 1.0002259942716147), ('model outperforms', 1.0002254712797616), ('network', 1.0002251000690636), ('information extraction', 1.0002241267005827), ('text', 1.0002235470862437), ('dynamic programming languages', 1.0002214677648051), ('neural turing machine', 1.0002130773560445), ('image analysis', 1.0002109960415675), ('gaussian process', 1.0002105962868442), ('neural network dnn', 1.0002099169530834), ('image recognition', 1.0002079604976208), ('deep learning approaches', 1.0002058321118439), ('extreme learning machines', 1.0002057552478298), ('embedded devices', 1.0002048915755988), ('neural networks rnns', 1.0002044832704235), ('convolutional networks', 1.0002033845972458), ('penn treebank', 1.000203067757264), ('deep learning opens', 1.0002012524915327), ('optimization algorithm', 1.000200221491917), ('deep learning applied', 1.0001994308531306), ('neural language modeling', 1.0001985856083768), ('neural turing', 1.000198501317416), ('multilayer perceptron', 1.0001984864820284), ('deep learning framework', 1.0001974284012465), ('end framework', 1.0001957591147805), ('doom game', 1.0001938599976183), ('deep', 1.0001926207123402), ('backpropagation', 1.0001924374184128), ('enhance developer', 1.0001914633653028), ('feature selection', 1.0001906085732288), ('unsupervised feature', 1.0001895671657273), ('neural network approach', 1.000189466421347), ('several benchmark datasets', 1.0001894651518395), ('challenging task', 1.0001893791493877), ('kernel based', 1.000189365087768), ('real time embedded', 1.0001878730026885), ('deep learning images', 1.0001858533410446), ('many machine learning', 1.0001847413527931), ('neural sequence', 1.0001835208557257), ('models', 1.0001821203299173), ('semantic image segmentation', 1.0001820135351067), ('semantic parsing', 1.0001818094214459), ('latent dirichlet', 1.0001816740267138), ('optimization problems', 1.0001813188102755), ('method', 1.0001803000551965), ('statistical machine', 1.0001799735264978), ('knowledge bases', 1.000179086472714), ('real world user', 1.0001790425286987), ('evolutionary algorithm', 1.000178921123743), ('networks', 1.0001788092882151), ('framework', 1.00017849345487), ('standard benchmark datasets', 1.0001772347266082), ('networks dnns', 1.000177048653025), ('neural sequence models', 1.0001758908169982), ('optical character', 1.0001756822962076), ('deep learning dl', 1.0001755166450061), ('backpropagation algorithm', 1.0001754249233807), ('gesture recognition', 1.0001735305997537), ('networks rnn', 1.0001729805377237), ('neural language model', 1.000172913325328), ('3d point clouds', 1.0001723794730493), ('dependency parsing', 1.0001722162373234), ('optical character recognition', 1.0001721720444892), ('neural network learning', 1.000171153429229), ('recurrent network models', 1.000171073168522), ('multi language image', 1.000170484399849), ('black box optimization', 1.000169857586899), ('3d point', 1.0001693501171172), ('new features', 1.0001683914913289), ('recognition datasets', 1.0001672146578253), ('word error', 1.0001669288050037), ('3d environment', 1.000166613872823), ('visual object recognition', 1.0001665142415634), ('abstract syntax trees', 1.000165390063115), ('matching videos', 1.0001651781090657), ('apache spark', 1.000165170742198), ('recurrent networks', 1.0001649587114223), ('results demonstrate', 1.0001647169295023), ('simulator', 1.0001642331369645), ('natural language text', 1.000164228379932), ('deep learning makes', 1.0001640906696116), ('dynamic programming', 1.000163757656351), ('visual turing test', 1.0001626174512266), ('rnn', 1.0001624527289106), ('unsupervised domain', 1.0001622655920417), ('atari domain', 1.0001622465519877), ('modern gpu clusters', 1.0001621174646582), ('simplified speech recognition', 1.000161387905198), ('significant improvements', 1.0001611744905237), ('gradient updates', 1.0001607293130592), ('deep models', 1.0001593616383464), ('tensorflow', 1.0001587827485428), ('standard machine learning', 1.000158744820958), ('error detection', 1.000158680685713), ('convolutional architectures', 1.0001584997914237), ('turing machine', 1.0001574771509636), ('recent years', 1.000156948091721), ('learn', 1.000156858646515), ('convolutional nets', 1.0001565074408345), ('neural translation model', 1.000155495123058), ('input space', 1.0001554567875663), ('arcade learning', 1.000155251888471), ('image manipulation', 1.0001551781507585), ('boltzmann machine', 1.0001548421832707), ('neural network layers', 1.0001538861712003), ('hierarchical reinforcement learning', 1.0001530192006602), ('active user', 1.0001525072401458), ('abstract syntax', 1.000152292143382), ('multiple gpus', 1.0001522515943972), ('backpropagation training', 1.0001519292232117), ('deep convolution', 1.0001517032703378), ('https github', 1.0001502469244783), ('sequence models', 1.0001501690659682), ('play video', 1.0001497747346793), ('real world users', 1.000149476081397), ('type annotations', 1.0001493121041714), ('neural network sentence', 1.000149293821103), ('software repositories', 1.0001491244129652), ('semantic parsers neural', 1.0001491099236925), ('sample extension', 1.0001490927333323), ('better speech recognition', 1.0001490825368666), ('tasks', 1.0001487258017685), ('learning chatbot', 1.0001485604142593), ('popular machine learning', 1.0001482632492116), ('software package', 1.0001480123323792), ('intelligent text recognition', 1.0001479802884934), ('lstm', 1.0001476882952711), ('recurrent models', 1.0001473475865459), ('test time', 1.0001472777620377), ('new framework called', 1.0001472753722918), ('deep network architecture', 1.000147229307211), ('multiple atari', 1.0001470530638628), ('other machine learning', 1.000146965611642), ('lstm based', 1.0001468423161448), ('emulate', 1.0001468379950955), ('neural network algorithm', 1.000146664528415), ('parsing performance', 1.0001462437916429), ('line kernel', 1.0001460526224863), ('network models', 1.00014592309345), ('computational complexity', 1.000145487908015), ('deep architecture', 1.0001453451481468), ('end', 1.0001453279870463), ('many nlp applications', 1.000145270678514), ('system exploits', 1.0001449996616214), ('images', 1.000144966189331), ('neural network classifiers', 1.0001449586551519), ('modern gpu', 1.0001449415054), ('sparse windows generation', 1.0001447707973796), ('parallel computing hardware', 1.0001447640352483), ('multiple kernel', 1.0001447156039156), ('new levels', 1.0001446583950373), ('higher level inference', 1.000144024746502), ('lstm models', 1.0001438180901325), ('lstm network', 1.0001435972176644), ('art performance', 1.0001435183681402), ('inference algorithm', 1.0001432895974955), ('neural speech synthesis', 1.0001432212880297), ('benchmark cross domain', 1.0001430634763226), ('unified framework', 1.000142868418218), ('convolutional layer computation', 1.0001426548353867), ('3d world', 1.0001425237117434), ('artificial intelligence task', 1.0001423319140021), ('neural net', 1.0001422226770527), ('malware images', 1.0001421664372936), ('recognition task', 1.0001420952498141), ('state space', 1.0001420657421232), ('neural networks dnns', 1.0001419161631215), ('novel visual', 1.000141878537918), ('convolutional recurrent', 1.0001418420059267), ('machine', 1.0001417737032174), ('neural text', 1.000141724741417), ('free text', 1.0001416799514318), ('source language', 1.000141651685434), ('datasets', 1.0001414860506024), ('traditional turing machine', 1.0001414003591877), ('neural architecture', 1.0001410624793194), ('real time object', 1.000140703464142), ('real users', 1.0001405771211043), ('iterative image segmentation', 1.0001403998319474), ('2.8x speedup', 1.0001399281713819), ('new source nodes', 1.0001399252270569), ('neural networks e', 1.0001396726582106), ('embedded platforms', 1.00013959631602), ('nlp applications', 1.0001395469952459), ('non convex', 1.0001394712517708), ('turing challenge', 1.0001393030284247), ('semantic segmentation models', 1.0001392115252723), ('deep autoencoder', 1.0001390833524484), ('networks lstm', 1.000138936627739), ('3d data', 1.0001389147748063), ('task', 1.0001387157421775), ('many computer vision', 1.000138507599462), ('convolutional architecture', 1.0001384929672934), ('neural training model', 1.0001384145515957), ('simple framework based', 1.0001381550133455), ('dynamic programming algorithm', 1.0001380906807824), ('syntactic kernels', 1.000137912366881), ('3d computed', 1.000137890243662), ('sequence', 1.0001377702680225), ('feature repository', 1.0001377606966464), ('remote sensing', 1.0001374483303371), ('learning dl', 1.0001374372651548), ('deep learning run', 1.00013741647473), ('convolutional autoencoder', 1.000137248153341), ('framework allows', 1.0001372034977878), ('deep learning tasks', 1.0001369202258417), ('learning approach', 1.0001366951225317), ('unsupervised deep', 1.0001366702655372), ('neural network training', 1.0001366230270319), ('dialogue system', 1.000136620737214), ('user interactions', 1.0001364858813395), ('current computing possibilities', 1.0001362626086223), ('feedforward neural', 1.000136194777664), ('convolutional learning', 1.0001360933010612), ('unsupervised domain adaptation', 1.0001360807090363), ('neural sequence modeling', 1.0001360071182717), ('neural networks based', 1.0001359381721624), ('extensible self service', 1.0001358491525236), ('deep learning improve', 1.0001355602220086), ('network dnn', 1.0001354974140326), ('technical ubuntu', 1.0001354921284398), ('mobile devices', 1.00013544197718), ('language multitasking', 1.0001354104574987), ('resource constrained', 1.0001352741203644), ('users', 1.0001352525125222), ('dependency parser', 1.000135202733021), ('optimization algorithms', 1.000135181933435), ('neural nets', 1.0001350969187899), ('runtime performance', 1.0001350921680823), ('statistical machine translations', 1.00013493939672), ('reusable kernels', 1.0001348529500318), ('simple optimization problem', 1.0001348328945365), ('toolkit', 1.0001346066650822), ('train lstm', 1.0001344033425734), ('deep learning task', 1.0001343472728836), ('supervised learning problem', 1.0001342787017486), ('algorithm known', 1.000134179460945), ('neural representation learning', 1.0001339758280303), ('vision datasets', 1.0001339378946377), ('latent sentences', 1.0001336014388669), ('applications', 1.000133500946342), ('recurrent network architectures', 1.0001334288200887), ('weakly supervised', 1.0001333527772158), ('mathematical language processing', 1.0001333033092232), ('convolutional autoencoders', 1.0001332295473728), ('word', 1.0001331302494014), ('framework based', 1.0001330175987402), ('3d human', 1.0001329596738346), ('build systems', 1.0001328352744625), ('neural network technique', 1.0001328063781678), ('neural network translation', 1.000132797705463), ('particular machine learning', 1.0001327162844005), ('exploit information', 1.000132635551281), ('multi agent domains', 1.0001326118907394), ('neural machine reading', 1.0001324223120118), ('such bigram', 1.000132291670017), ('artificial intelligence c', 1.0001322594929742), ('learning machine', 1.0001320669078146), ('restricted boltzmann machine', 1.0001320506552587), ('sequence seq2seq', 1.0001319055458773), ('training', 1.0001318452746744), ('neural network policies', 1.0001318127593513), ('interpreter models', 1.0001317582049292), ('rendering model', 1.0001317287189717), ('framework called', 1.0001317208883855), ('algorithm called', 1.0001316151012467), ('different vision datasets', 1.0001315919254892), ('framework using', 1.0001315322617819), ('multiple optimization problems', 1.0001314991401458), ('framework implements', 1.0001313838570318), ('bayesian deep', 1.0001313300628607), ('art', 1.0001312114146343), ('better user experience', 1.0001311309570624), ('deep rnns', 1.0001310820097982), ('outputs recognition', 1.0001309361106006), ('ubiquitous computing devices', 1.0001307582249495), ('neural networks called', 1.0001306730647095), ('convolutional network', 1.0001306671442571), ('image pixels', 1.000130562976601), ('artificial intelligence models', 1.0001305432536483), ('computer algorithms', 1.0001304003584437), ('using lstm', 1.0001303199527902), ('different tasks', 1.0001303197910065), ('recurrent model', 1.0001302982999853), ('malware classification', 1.0001302321299297), ('approach', 1.0001301609453095), ('method can', 1.0001301552253998), ('semantic parsing tasks', 1.000130155177909), ('autoencoder', 1.0001301438159498), ('rnn model', 1.0001300225664396), ('speech tagging', 1.0001299796292702), ('gpu based', 1.0001299113126547), ('same game', 1.000129886675062), ('computing nodes', 1.0001298309681643), ('standard gradient descent', 1.000129802288992), ('extensible self', 1.0001297244667684), ('learning', 1.0001296917812406), ('current state', 1.0001296419097423), ('deep lstm', 1.000129604379686), ('neural network decisions', 1.0001295886170072), ('convolutional layer', 1.0001295678046485), ('recursive matching', 1.0001295602478446), ('computational learning setup', 1.000129466263253), ('electronic health records', 1.0001294440235762), ('graphical web', 1.000128990589119), ('input data', 1.0001289904284514), ('embedded speech recognition', 1.0001288304710787), ('actor critic', 1.0001288149987557), ('training dataset', 1.0001287865164596), ('convolutional', 1.0001285616355202), ('many ai research', 1.0001285458605966), ('recognition techniques', 1.00012853289536), ('neural translation', 1.0001285059070388), ('lstm results', 1.0001284656618357), ('deeper networks', 1.0001284276993294), ('standalone tool', 1.000128386114564), ('optimization', 1.0001281331497205), ('speech tags', 1.0001281183567736), ('many nlp tasks', 1.0001280274968039), ('networks trained', 1.0001279635242237), ('sentiment analysis task', 1.0001279215059184), ('new framework', 1.0001278713007546), ('visual dialog systems', 1.0001278375856517), ('different network architectures', 1.000127820116478), ('traditional turing', 1.0001277711361234), ('networks neural', 1.0001276008084619), ('constraint solvers', 1.0001275011714075), ('deep architectures', 1.0001274357783114), ('kernel machines', 1.0001272302812882), ('high level features', 1.000127080709853), ('proposed algorithm', 1.0001268899048046), ('natural language queries', 1.000126862195485), ('neural link prediction', 1.00012676030802), ('speech synthesis', 1.0001267432527172), ('neural model', 1.0001266834549243), ('neural regression algorithms', 1.0001265996096325), ('deep boltzmann', 1.0001265793852372), ('hierarchical reinforcement', 1.000126571894962), ('most nlp applications', 1.0001264026439445), ('multiple image datasets', 1.0001263951433008), ('framework extends', 1.0001262872578232), ('optimization framework', 1.000126200882645), ('natural language data', 1.0001261349855726), ('algorithmic tasks e', 1.0001261282833287), ('neural networks area', 1.0001260704724764), ('neural networks requires', 1.0001260218013663), ('visual', 1.000125920131904), ('interior point methods', 1.0001258572008802), ('algorithm depends', 1.0001258074722366), ('unsupervised relevance', 1.000125753211362), ('automated speech', 1.0001255588827047), ('code generation', 1.0001255568571799), ('training images', 1.0001254848247634), ('text summarization', 1.0001254789849017), ('inference engines', 1.0001254260247239), ('conditional computation achieving', 1.0001253247936663), ('neural dependency', 1.0001251432311333), ('python code', 1.0001251421769726), ('visual dialog task', 1.0001249830691743), ('supervised machine', 1.0001247688885915), ('lstm units', 1.0001247378684353), ('q learning', 1.0001247272198583), ('visual dialog models', 1.0001247117425367), ('new algorithm', 1.0001246784284452), ('simpler lstm', 1.0001245995849015), ('3d', 1.0001245532670793), ('recurrent networks based', 1.0001244677151675), ('input text', 1.0001244429148168), ('extract features', 1.000124441207553), ('recognition learning', 1.000124250899116), ('different architectures', 1.0001241681997948), ('lstm architecture', 1.0001241295002852), ('framework can', 1.000123936759344), ('artificial intelligence systems', 1.0001236298194853), ('planning algorithm', 1.0001234642504628), ('input hidden', 1.0001234583857304), ('sequence autoencoder', 1.0001233197128931), ('solving machine', 1.0001232981831127), ('exploit language', 1.0001232874673867), ('art parsing', 1.0001232042601222), ('hierarchical recurrent', 1.0001231741518395), ('network language', 1.0001231544296358), ('such kernel', 1.0001230879879017), ('network model', 1.000122916024951), ('traditional computer vision', 1.0001228368472106), ('neural speech', 1.000122824803943), ('runtime', 1.000122824740619), ('model architecture', 1.0001228066880283), ('framework provides', 1.0001227968386344), ('kernel activation', 1.0001225797290516), ('medical image analysis', 1.0001225787681904), ('standard lstm', 1.0001225461048664), ('novel machine learning', 1.0001224474400736), ('knowledge transfer', 1.0001224302126315), ('auto generated', 1.00012234353539), ('document parsing', 1.000122265260343), ('methods', 1.0001222260107223), ('imagenet', 1.0001222165635129), ('malware binaries', 1.0001221932673776), ('large language modeling', 1.000122147154131), ('sequence tasks', 1.0001221376088234), ('computation', 1.0001221309662611), ('generate', 1.0001221083130156), ('gpu', 1.0001220999515903), ('gpus', 1.0001220939001523), ('challenging computer', 1.0001220731512215), ('language tasks', 1.0001220651839078), ('parsing model', 1.0001220393261467), ('visual dialog model', 1.000121999723234), ('simple rnns', 1.0001219313407435), ('implicit features', 1.0001218517418176), ('lstm rnn models', 1.0001218153800713), ('neural approaches', 1.0001217591772718), ('visual turing', 1.000121748614099), ('convolutional feature', 1.000121577934826), ('large lstm', 1.000121502936033), ('ssl', 1.0001214919468275), ('benchmark image recognition', 1.0001213355213265), ('support vector', 1.0001212731948637), ('network algorithm', 1.0001212095689804), ('rnn trained', 1.000121168607701), ('algorithm will', 1.000121132788422), ('ai systems', 1.0001210203597888), ('tagging dependency', 1.0001208797440626), ('unsupervised feature representation', 1.0001208608746164), ('rnn models', 1.0001207091614888), ('third party developers', 1.0001206817910364), ('classification', 1.0001206751365992), ('feature preprocessors', 1.0001206670363199), ('pac rnns', 1.000120564268143), ('neural training', 1.000120536943042), ('raw image', 1.0001205289160302), ('visual recognition', 1.0001204815044809), ('knowledge representation', 1.0001204588798238), ('play algorithm', 1.0001203516562667), ('algorithmic tasks', 1.0001202018938722), ('large datasets', 1.0001201835191211), ('learning representations', 1.0001201541552551), ('user', 1.0001200628660631), ('networks using', 1.0001200060032276), ('mobile application user', 1.0001199447775093), ('efficient algorithms', 1.0001198654314338), ('network frameworks', 1.000119827673567), ('compute operations', 1.0001195557491103), ('application', 1.000119531811732), ('3d shapes', 1.0001193843119414), ('natural language questions', 1.000119291253887), ('graphical user', 1.0001192401372636), ('neural image', 1.000119179908468), ('model complexity', 1.0001191364916842), ('better recognition accuracies', 1.0001191150759734), ('recognition accuracy', 1.0001190107701516), ('neural dependency parser', 1.0001189136475102), ('developer', 1.0001188900547977), ('restricted boltzmann', 1.0001188087462363), ('programming process', 1.0001186904004822), ('such kernel dictionaries', 1.0001186543393774), ('rendering', 1.0001186106605013), ('turing', 1.0001185990503783), ('supervised feature learning', 1.0001185447287504), ('neural attention', 1.0001185180613017), ('neural networks employs', 1.000118485648864), ('component based', 1.0001183736685801), ('bigram types', 1.0001182755285518), ('develop rnn', 1.000118207442028), ('neural network components', 1.0001181567586437), ('feature', 1.000118151798767), ('computational learning', 1.0001181086911544), ('neural variational', 1.0001180924234745), ('processing', 1.0001180479401879), ('dynamical systems', 1.0001179041572466), ('automatic evaluation metrics', 1.0001178677059201), ('general framework', 1.0001177765825453), ('other algorithms', 1.0001177463934587), ('several language modeling', 1.000117686999504), ('learning vector', 1.000117648444626), ('networks can', 1.0001175331882044), ('learning agents', 1.0001175330479162), ('keyword spotting', 1.0001175045032011), ('procedural content', 1.0001174856496537), ('unsupervised learning allowing', 1.0001174259369774), ('photo editing', 1.0001173342499667), ('convolutional evaluation', 1.0001172597529746), ('open information extraction', 1.000117151386207), ('multi core processors', 1.0001170774087484), ('mobile applications', 1.0001170737420897), ('ai tasks', 1.000117047254435), ('linear autoencoders', 1.0001169905665817), ('d vector extraction', 1.0001169733692181), ('distributed algorithm', 1.0001168466187824), ('path finding', 1.0001167772447939), ('input dimension', 1.0001167630905987), ('memories lstms', 1.0001165011825095), ('build automated', 1.0001164822751245), ('feedforward deep', 1.0001164196571075), ('artificial networks', 1.000116416521208), ('online representation learning', 1.0001164114698353), ('dynamic memory tensor', 1.000116400288343), ('successful matching algorithm', 1.0001162535077945), ('image data', 1.000116252385727), ('neural error', 1.0001162193207547), ('deep auto encoders', 1.0001162018591703), ('unsupervised methods', 1.0001161349698937), ('rule extraction', 1.0001161266788539), ('memory lstms', 1.0001161004793757), ('multi object tracking', 1.0001160734165697), ('perceptrons', 1.0001160582187574), ('architecture', 1.0001160537690283), ('svms parameters', 1.0001160006717897), ('speedup offered', 1.0001158993673167), ('constraint programming', 1.0001158975188944), ('multi layer input', 1.0001158518590696), ('computational models', 1.0001158058139707), ('algorithms based', 1.0001157994527368), ('computation time', 1.000115765295968), ('core algorithms', 1.0001157070311457), ('unsupervised pattern classification', 1.0001156915335543), ('sandbox', 1.000115555338784), ('compact framework', 1.0001154814897688), ('simulated robotics tasks', 1.0001153920567674), ('parallel computational', 1.0001153903188065), ('unsupervised context', 1.0001153507857385), ('modified version', 1.0001153322702017), ('neural error detection', 1.0001152620508695), ('bayesian network', 1.0001152204003982), ('computations', 1.0001151782634703), ('neural pca', 1.0001151230332956), ('new method', 1.0001150896458166), ('interpret debug', 1.0001150884646541), ('neural approach', 1.0001150590067294), ('multilayer neural', 1.0001150460894555), ('backpropagation possible', 1.0001150145998725), ('autoencoders', 1.0001149734443568), ('multi view network', 1.0001149180791864), ('extracting features', 1.0001148876595018), ('simple neural', 1.0001148827759567), ('latent segmentation', 1.0001148447019408), ('art algorithms', 1.0001147143412508), ('feedforward network', 1.000114688257854), ('rnn training', 1.0001146444488995), ('gaming environments', 1.0001146408340378), ('imagenet image', 1.0001145543256464), ('performance', 1.00011454860284), ('deep belief networks', 1.000114534724349), ('polynomial time', 1.0001145066493835), ('system builds', 1.0001144608405548), ('structured prediction problems', 1.0001144498145684), ('computation required', 1.0001144302746638), ('easy medium', 1.0001144218484124), ('word2vec embedding', 1.0001143106243613), ('large scale optimization', 1.000114288161102), ('multilayer perceptrons', 1.000114228329483), ('query embeddings', 1.0001141661859028), ('commercial speech systems', 1.0001140797138401), ('perceptron', 1.0001140767266283), ('standard autoencoders', 1.0001140159082547), ('computational paradigm', 1.0001138795217452), ('vector semantics', 1.0001138551352198), ('less computation', 1.0001137536742326), ('neural regression', 1.0001137087067826), ('numerical computation', 1.0001136439002853), ('artificial intelligence asks', 1.0001135869636502), ('new feature learning', 1.0001135640906758), ('many pattern recognition', 1.000113562140991), ('linear rnns', 1.0001134369474491), ('computational', 1.0001134087237047), ('probabilistic models', 1.0001133848069677), ('learning pipelines', 1.000113333102768), ('translation systems', 1.000113323245981), ('matching tasks', 1.000113223626806), ('unsupervised evaluation', 1.0001132052847748), ('real world datasets', 1.0001131985826808), ('rnn language', 1.000113189515915), ('rnn architecture', 1.0001131607533977), ('conventional machine learning', 1.0001131281934519), ('rnn architectures', 1.0001129857462654), ('time series', 1.000112934083007), ('matching image', 1.000112893668114), ('multilingual recognition systems', 1.0001128061515006), ('higher order abstractions', 1.000112712367473), ('different kernel', 1.0001126706986176), ('many training algorithms', 1.0001126353828182), ('algorithm uses', 1.000112513169021), ('framework compares', 1.0001125105245297), ('multi label problems', 1.0001124106088706), ('executing machine', 1.000112404453144), ('nonlinear pca', 1.0001124032042032), ('implementation trick', 1.000112331108826), ('modeling sequences', 1.0001123107275658), ('computer graphics', 1.000112219250779), ('mobile application', 1.0001121960587722), ('semantic parsers', 1.000112147991429), ('computational algorithms', 1.0001121479685193), ('networks anns', 1.0001120992193202), ('previous sparse coding', 1.0001120822464886), ('summarization question', 1.0001120622801791), ('execution efficiency', 1.0001120401258177), ('network parser', 1.0001119818305642), ('computational time', 1.0001118984180288), ('unstructured text', 1.0001118350449754), ('constraint solving', 1.0001118124238368), ('unsupervised component', 1.0001117844197074), ('offline', 1.000111660531198), ('bayesian optimization', 1.0001115569411771), ('network embedding', 1.0001115277038064), ('gaussian binary restricted', 1.0001114899432175), ('dedicated user', 1.0001114316611104), ('simple language model', 1.0001114272786717), ('speedup', 1.0001114205814088), ('fewer mode collapses', 1.0001114036571759), ('smart phones wearables', 1.000111378207076), ('statistical language models', 1.0001113283812317), ('inductive program synthesis', 1.0001113152606993), ('prolog', 1.0001111995278442), ('image classifiers', 1.0001111655714832), ('network classifiers', 1.000111157351493), ('spoken dialogue systems', 1.0001111416878168), ('user devices', 1.0001110187773106), ('speech', 1.000110980533741), ('novel kernel based', 1.000110961557215), ('language', 1.0001108733568391), ('feedforward networks', 1.0001108492646995), ('user preferences', 1.0001108424258165), ('efficient neural', 1.000110740544619), ('new algorithmic', 1.0001107194602774), ('temporal difference', 1.0001106599830407), ('feature visualization', 1.0001106376638869), ('artificial intelligence capabilities', 1.0001105830366557), ('graphical processing units', 1.0001104506262013), ('gradient descent techniques', 1.0001103581668556), ('cad', 1.000110357314021), ('supervised recognition tasks', 1.0001103137501206), ('feature embedding', 1.0001102695904673), ('hierarchical latent variable', 1.0001102585086776), ('neural world', 1.0001102515605114), ('write program', 1.0001102019286878), ('various network architectures', 1.0001101781090462), ('features optimized', 1.0001101726564203), ('structured sparsity learning', 1.0001101101402021), ('human machine translation', 1.000109994931869), ('natural language inference', 1.0001099743942656), ('probabilistic programming', 1.0001099533643099), ('practical hardware implementations', 1.0001098757566462), ('kernel', 1.0001098738584557), ('developers', 1.0001097337571876), ('general unsupervised', 1.000109712850494), ('conditional lstm', 1.0001096289467786), ('new sampling algorithm', 1.0001095926872619), ('use', 1.0001095617121012), ('prior program structure', 1.0001094909264832), ('language queries', 1.000109480189831), ('traditional machine learning', 1.0001094739974348), ('atari games', 1.0001094545336213), ('end memory', 1.000109431468388), ('art methods', 1.0001093529441394), ('deep rendering model', 1.0001093348120007), ('dependency parsers', 1.0001092893870227), ('user inputs', 1.0001092366591138), ('computation resources', 1.0001091941186193), ('nlp tasks', 1.0001091296719224), ('distributed system', 1.0001090694313706), ('different atari', 1.000109056156538), ('structured output problems', 1.000108909124258), ('features', 1.0001088943729877), ('complex segmentation tasks', 1.0001088784866845), ('unsupervised pattern', 1.000108863135245), ('integrating word', 1.000108772386416), ('level language', 1.0001087190318212), ('voxel', 1.0001087083771947), ('networks dnn', 1.0001086180697143), ('function complexity', 1.000108616799876), ('visual chatbot', 1.000108581821977), ('several benchmark', 1.0001085743213851), ('quantum game', 1.0001085264782703), ('generating text', 1.0001084704393546), ('neural fields', 1.00010835489197), ('hybrid hidden markov', 1.0001082647046144), ('model can', 1.0001082597184765), ('firefly algorithm', 1.0001081673361285), ('full network embedding', 1.0001081449527893), ('training algorithms', 1.0001080859853049), ('sql based', 1.0001080700655778), ('learning framework', 1.0001080522901997), ('classifier trained', 1.0001080292168885), ('output', 1.000108018891018), ('hierarchical computation', 1.0001079605794767), ('learning problems', 1.0001079126444847), ('unsupervised nonlinear', 1.0001078575516391), ('recognition translation', 1.0001078420773353), ('multiple datasets', 1.0001078067288753), ('machine translations', 1.0001076799323103), ('inductive program', 1.0001076393502202), ('fast inference', 1.0001075466534968), ('physics simulation', 1.0001075262424084), ('wearable devices', 1.0001074396542493), ('simple optimization', 1.0001074306788296), ('latent representation', 1.0001074121525293), ('optimal solution', 1.000107363712083), ('source features', 1.0001073418916802), ('target network', 1.0001073372363216), ('neural attention model', 1.0001073234754598), ('recursive process', 1.0001073207016757), ('computational proof', 1.0001073110328027), ('unsupervised manner', 1.0001072855542976), ('lstm matrix', 1.0001072813469316), ('automatic captioning tagging', 1.00010724638672), ('auto encoders', 1.0001072190324194), ('discrete memory representation', 1.000107212880719), ('toolkit consists', 1.0001071989494446), ('perform optimization', 1.0001071822418552), ('binary classification', 1.0001070793904574), ('ubuntu', 1.00010704390641), ('convolutional filter', 1.0001069969896201), ('deep learning driven', 1.000106965508554), ('different datasets', 1.0001069585976676), ('tasks machine', 1.0001069486648502), ('language expressions', 1.0001068694228896), ('computational graph', 1.0001068541372966), ('architectures', 1.0001068302867953), ('algorithm extends', 1.0001067774972143), ('novel method', 1.0001066870124966), ('most preprocessing', 1.0001066633617033), ('neural encoder decoder', 1.000106645637375), ('other recursive', 1.0001066082855952), ('matlab', 1.0001066050996963), ('word models', 1.0001065966530474), ('language modelling', 1.0001065370476427), ('inference outputs', 1.0001065144380092), ('convolutional layers', 1.000106514368312), ('state compatibility', 1.0001064832797553), ('compute time', 1.0001064631795957), ('intelligent algorithms', 1.0001064489477616), ('neural data', 1.000106419999678), ('significant speedup', 1.000106353876721), ('matlab code', 1.0001063533257375), ('neural networks involves', 1.0001063353111528), ('neural qa system', 1.0001063318241636), ('net based', 1.0001063134621724), ('distributional semantics composing', 1.0001063033851365), ('such models', 1.000106230344259), ('parser states', 1.0001062230432771), ('hierarchical latent', 1.0001061249243293), ('feature vectors', 1.000106101925549), ('unsupervised data', 1.0001060146692584), ('multilingual speech recognition', 1.0001059700030461), ('large scale learning', 1.000105918824205), ('numerical features', 1.0001059103589802), ('non lstm', 1.0001058985974254), ('grayscale images', 1.0001058441275046), ('generative image models', 1.0001057948808247), ('end user', 1.0001057863287015), ('system need', 1.0001057599677556), ('neural dependency parsers', 1.000105539709835), ('classifier', 1.0001054913086056), ('sparse windows', 1.0001054787945372), ('output substrings', 1.000105403401515), ('real world rendered', 1.0001053861935476), ('multi language', 1.0001053391236505), ('exploit', 1.0001053335562073), ('graph time', 1.000105319495857), ('network learning', 1.0001053100745367), ('visual feature', 1.0001052894334752), ('robotics applications', 1.0001052760656683), ('gradient penalty', 1.0001052623078848), ('better user', 1.000105246781783), ('sentiment algorithms', 1.000105217349139), ('computational resources', 1.0001051765822218), ('program verification', 1.0001051479416478), ('optimal complexity', 1.0001051344225889), ('truncating gradient', 1.0001050785801144), ('svm training', 1.000105076187896), ('latent topics', 1.0001050403532763), ('input layer', 1.000104993262287), ('segmentation outputs', 1.0001049352084974), ('algorithms combine', 1.000104847866082), ('ai skills', 1.0001048356158158), ('algorithmic information', 1.0001046589333162), ('multiple computing', 1.0001046578468267), ('simple preprocessing', 1.0001046183858808), ('phone recognition', 1.000104605291038), ('user others', 1.0001045658169057), ('least squares algorithm', 1.0001045499528336), ('recommender systems', 1.0001045365136982), ('iterative algorithms', 1.000104468394865), ('pose estimation', 1.0001044192727029), ('reinforcement', 1.000104410054349), ('tree based', 1.000104382134022), ('standard denoising', 1.0001043469404947), ('language objects', 1.0001043401588996), ('sequence model', 1.0001043293562224), ('sparql queries', 1.0001042764153343), ('visual features', 1.0001041953772776), ('explicit neural', 1.0001041130297892), ('standard architectures called', 1.0001041042941612), ('small context window', 1.000104102735606), ('generative modeling', 1.000104094500476), ('network classifier', 1.0001040546171058), ('recent visualization algorithms', 1.0001040479754684), ('convolutional feature extractors', 1.0001040406718689), ('conditional language models', 1.0001040258661789), ('neural sequence labeling', 1.0001040125437874), ('temporal pattern recognition', 1.0001040037867703), ('text processing', 1.0001039954460387), ('expressive power', 1.0001039869856156), ('text8 datasets', 1.000103949534253), ('domain ontology', 1.00010390657335), ('different kernel functions', 1.0001038993651483), ('standard backpropagation', 1.0001038866970293), ('multi classifier models', 1.0001038638369066), ('data science', 1.0001038507450128), ('art neural', 1.0001038264405628), ('unsupervised vocabulary', 1.000103825658182), ('image generation', 1.0001037827082364), ('probabilistic framework', 1.0001037643911983), ('many nlp systems', 1.000103628740575), ('interpretable cad system', 1.0001036090527868), ('greedy search', 1.0001035853149187), ('optimal graph', 1.0001035848857258), ('networks requires', 1.0001034699731455), ('artificial intelligence psychology', 1.0001034663884547), ('semantic analysis', 1.000103427964004), ('learning classifier', 1.000103410329269), ('accelerator chips', 1.0001034098822994), ('translation model', 1.0001033858377617), ('rnn encoder', 1.0001033837107884), ('classical machine learning', 1.0001032535410885), ('modeling images', 1.0001032253778217), ('planning computation', 1.0001031588270113), ('reduce computation', 1.0001031501018218), ('improve recognition', 1.0001031358540324), ('results', 1.0001030956301562), ('online reinforcement', 1.0001030774849902), ('computational infeasibility', 1.0001030592117748), ('configurable network architecture', 1.000103032340729), ('computer', 1.0001029554589564), ('neural cache', 1.000102867734044), ('vanishing gradients', 1.0001028480758127), ('analysis tool', 1.0001028290521325), ('input image', 1.0001028132706153), ('svms parameters optimization', 1.0001027746092206), ('automated story', 1.0001027526181674), ('kernel perceptrons', 1.0001027312496586), ('semantic segmentation demonstrate', 1.0001026881031887), ('memory rnns', 1.000102667802111), ('tree structures', 1.0001026665427046), ('standard multitask', 1.0001026270466526), ('particular lstms', 1.0001025691383731), ('supervised recognition', 1.0001025195359647), ('matching tokens', 1.0001024855293654), ('computational block', 1.0001024733935473), ('programming', 1.0001024533453053), ('open domain question', 1.0001024308385875), ('brute search', 1.0001024278913226), ('user specified', 1.0001024154335583), ('api related', 1.0001023866610173), ('gradient methods', 1.0001023278927084), ('deterministic neural', 1.0001023153362827), ('output sequence', 1.0001023153345894), ('kernel methods', 1.0001023017292887), ('language identification', 1.0001022677585818), ('existing implementations', 1.0001022349246598), ('user model', 1.0001022320241222), ('multi task reusability', 1.0001022025046795), ('sequential data', 1.0001021759668502), ('language input', 1.0001021658652347), ('software allows', 1.0001021615478165), ('word collocation', 1.0001021188931083), ('adaptive computation', 1.0001021032999795), ('deep learning showing', 1.000102078921583), ('recursive convolutional', 1.000102014592215), ('graph approximation', 1.000102008283402), ('lstms', 1.0001019933174355), ('unsupervised training', 1.0001019724713864), ('multiple optimization', 1.0001019589493205), ('evolutionary algorithms involves', 1.0001019562109252), ('structured output spaces', 1.0001019354475436), ('complex tasks', 1.0001018796683065), ('conditional batch', 1.0001018070594327), ('neural computation', 1.0001017453065775), ('tool allowing', 1.0001016828513731), ('network regularizer', 1.0001016474284445), ('adversarial samples inputs', 1.0001015868830974), ('net', 1.0001015777096702), ('imagenet classification', 1.0001015746795483), ('corresponding optimization', 1.000101550550743), ('search space', 1.000101500856352), ('memory augmented', 1.0001014778186261), ('natural language tokens', 1.0001014442613052), ('source code', 1.0001014383916402), ('spam filtering', 1.0001014343821126), ('networks based', 1.0001014244026623), ('topic allocation', 1.0001013589591004), ('new approach', 1.0001013565791346), ('graphical processing', 1.0001013275152606), ('text data', 1.0001012933849915), ('natural language sentences', 1.0001012811128793), ('joint distribution matching', 1.0001012595123204), ('users preference', 1.00010125127273), ('hidden objects', 1.0001012426674734), ('hierarchical memory network', 1.00010122540306), ('novel search algorithm', 1.0001012203509136), ('proposed algorithms', 1.0001011776956235), ('multi task autoencoders', 1.0001011757222606), ('stochastic gradient methods', 1.0001011551349717), ('external memory', 1.0001011228154828), ('labeling datasets', 1.0001011153338457), ('tool allows', 1.000101114604981), ('nonlinear function approximation', 1.0001010933814372), ('nlp systems', 1.0001010380633115), ('neural operations', 1.0001010347544894), ('transforming images', 1.0001010136896527), ('benchmark tasks', 1.0001010122605967), ('different application', 1.0001009943345074), ('many tasks', 1.0001009351384724), ('training algorithm', 1.0001009206712466), ('continuous learning reinforcement', 1.0001008806001799), ('classify images', 1.000100857923671), ('optimum solutions', 1.0001008262667208), ('latent', 1.000100801910663), ('stochastic search techniques', 1.0001007974269578), ('word lstm', 1.0001007555174308), ('machine intelligence', 1.0001006701520831), ('policy gradient', 1.0001006680257802), ('linear support vector', 1.0001006396118606), ('program can', 1.0001005777776664), ('various bigram types', 1.0001005521953061), ('language generation', 1.0001005498197715), ('probabilistic models including', 1.0001005364553082), ('computer programmer', 1.0001005040687334), ('practical goal oriented', 1.0001004416640313), ('efficient architecture search', 1.0001004258459045), ('learning architecture', 1.0001004163001723), ('hidden nodes', 1.0001004152448707), ('multi label object', 1.0001004016315693), ('binary classification task', 1.0001003978676308), ('markov decision', 1.0001003933652206), ('validation set', 1.0001003769592636), ('delayed rewards', 1.0001003210725017), ('object', 1.000100301149624), ('supervised data', 1.0001002672761725), ('computational convergence rates', 1.0001002520819873), ('cognitive robots', 1.0001002451118564), ('dataset', 1.0001002371342447), ('svms decision', 1.0001002310401668), ('prove queries', 1.0001002167304485), ('consistent performance improvements', 1.0001001948190984), ('gradient computations', 1.0001001861966494), ('3d reconstruction', 1.0001001700542962), ('traditional binary', 1.0001001573296995), ('translation models', 1.0001001049658829), ('metric learning', 1.000100088084912), ('sparse binary', 1.0001000847315153), ('optimization difficulty', 1.000100064418674), ('inference', 1.0001000337089079), ('complexity', 1.000100029132121), ('frameworks', 1.0001000271026812), ('virtual data improves', 1.0001000209485844), ('several probabilistic', 1.000099963975161), ('particular asynchronous', 1.0000999362233318), ('distribution algorithms', 1.0000999320226176), ('language tokens', 1.0000998945661632), ('automatic keyword', 1.0000998826477914), ('specific sentiment analysis', 1.0000998332618318), ('different complexity', 1.0000998312228602), ('experiments demonstrate', 1.0000997709932242), ('depth image', 1.0000996832418148), ('spiking networks', 1.0000996604428007), ('computing elements', 1.000099584028836), ('many applications e', 1.0000995588994865), ('unlabeled data', 1.0000995519671458), ('factorization machine', 1.000099534385982), ('learn kernels', 1.0000994640255507), ('particular image data', 1.0000993747755662), ('most atari', 1.0000993203929662), ('minimization problem', 1.000099305943843), ('adversarial network', 1.0000992697538151), ('specific reasoning capabilities', 1.0000992341738215), ('optimization issues', 1.000099231588163), ('neural move predictors', 1.000099215113246), ('visualization', 1.000099168049478), ('learning architectures', 1.0000991484674409), ('trained networks', 1.0000991063565192), ('convert images', 1.0000990205796778), ('input images', 1.0000990044928548), ('sparse network', 1.0000989273355623), ('such learning parameters', 1.0000989181142705), ('standard computer vision', 1.0000988848554198), ('neural models yield', 1.000098859960119), ('fast unsupervised', 1.0000988382708524), ('rnn makes', 1.0000988081257653), ('many nlp', 1.0000986814933182), ('simple algorithms sorting', 1.0000986626304513), ('learning rule', 1.0000986257609492), ('chatbot', 1.0000985981912165), ('online convex optimization', 1.0000985926544304), ('visual feature mapping', 1.0000985830042155), ('doom', 1.0000985470221668), ('optimization objective', 1.0000985341065625), ('learning embeddings', 1.000098504222837), ('inverse reinforcement learning', 1.0000984283116028), ('free text statements', 1.0000983642612167), ('rnns integrating', 1.00009830365965), ('recent output representations', 1.0000982923097228), ('nlp research', 1.0000981024694762), ('system outperforming', 1.000098096608266), ('complexity related', 1.0000980028184305), ('edge devices', 1.0000979983371394), ('image datasets', 1.000097987796805), ('natural language dialog', 1.0000979569860546), ('recognition performance', 1.0000979384286242), ('numerous word embedding', 1.0000978763119341), ('algorithmic approach', 1.0000978682478003), ('sampling algorithm', 1.0000978619711853), ('standalone components', 1.0000978543079102), ('text modeling', 1.000097759358189), ('stochastic search', 1.0000977518274181), ('late hidden layers', 1.000097719592277), ('recursive', 1.0000977184991613), ('offline storage', 1.000097690656884), ('recurrent architecture', 1.0000976801307357), ('stochastic optimization processes', 1.0000976569428564), ('trained vector', 1.0000975868873065), ('save computation', 1.0000975609641334), ('deterministic function', 1.0000975345827139), ('computing vector', 1.0000974850795519), ('end learning', 1.0000974789673955), ('hidden units', 1.000097460170981), ('robotic tasks', 1.0000974348912126), ('unbounded memory', 1.000097428904695), ('architectures based', 1.000097424592561), ('incremental speech recognition', 1.000097422777912), ('benchmark datasets shows', 1.0000973137303655), ('convolutional text', 1.0000973124492816), ('large scale data', 1.0000972560164116), ('simple framework', 1.000097255672822), ('conventional algorithms', 1.0000972519691864), ('software', 1.0000972367085872), ('dialog task', 1.000097203157461), ('dynamic memory network', 1.0000971940843353), ('low level', 1.000097183536445), ('hardware compute', 1.0000971738283084), ('abstract data structures', 1.0000971093580917), ('pre trained networks', 1.0000970565385692), ('wide range', 1.0000970259770823), ('several classification datasets', 1.0000970239674694), ('neural encoder', 1.000097006435311), ('final algorithm', 1.000096996393472), ('individual lstm', 1.0000969510845743), ('textual data', 1.0000968346260968), ('optimization technique', 1.0000968285190448), ('specifying annotations', 1.0000967645331176), ('input dimensionality', 1.0000967544729245), ('cheminformatics software', 1.000096727790109), ('input samples', 1.00009670744237), ('visual object', 1.0000966756431253), ('output tree', 1.0000966281775425), ('best lstm', 1.0000966039649288), ('compute', 1.0000965893983724), ('optimization pso', 1.0000965713402978), ('dynamic data sets', 1.0000965186220852), ('end training', 1.000096513790503), ('image description', 1.0000965052260726), ('multimodal embedding', 1.0000964819031295), ('generated architectures', 1.0000964694448697), ('multi media text', 1.000096413370181), ('proposed approach', 1.0000963870003974), ('software modules', 1.0000963757633072), ('information', 1.0000963597356116), ('simple algorithms', 1.000096335436257), ('recurrent architectures', 1.000096313096722), ('given preprocessing', 1.000096282963357), ('optimization methods', 1.0000962761871597), ('computational convergence', 1.000096273880945), ('web document', 1.000096273071898), ('networks cnns', 1.000096266619695), ('mnist', 1.0000962608280093), ('unsupervised labeling', 1.0000962454713258), ('parameterization technique', 1.0000960548260578), ('encoder network', 1.000096042108181), ('embeddings', 1.0000960200586593), ('spoken language understanding', 1.0000960028989005), ('convolutional sequence', 1.0000959934298186), ('memory architectures', 1.0000959834626453), ('statistical learning', 1.0000959721640978), ('current cad systems', 1.0000959663161741), ('commonsense reasoning', 1.0000959561966276), ('datasets containing', 1.0000959366802868), ('neural transfer', 1.0000959281514294), ('kernel method', 1.000095873256819), ('neural reasoner', 1.0000958499690635), ('auto encoding', 1.0000957696251003), ('performant', 1.000095757388346), ('predefined classes', 1.0000957395280987), ('gradient', 1.0000957304602172), ('sequence framework', 1.000095696599035), ('used features should', 1.0000956623041983), ('data points', 1.0000956578031777), ('hard problem', 1.0000956419883122), ('feature engineering', 1.0000956242952501), ('sparse constraints', 1.0000956035150523), ('dnn', 1.0000955758836787), ('training networks', 1.0000955692544422), ('semantic understanding', 1.000095516962402), ('optimization tool', 1.000095459155208), ('proposed framework', 1.0000954426674014), ('artificial agents', 1.0000954187311737), ('unsupervised', 1.0000954093275667), ('game ai', 1.0000954000262448), ('benchmark cross', 1.0000953569330446), ('various applications', 1.000095334237405), ('deterministic', 1.0000953242105028), ('sentiment classification', 1.0000953078256574), ('new neural', 1.0000951364285893), ('most neural', 1.0000950549025318), ('dynamic time warping', 1.0000950117365681), ('compatible translation', 1.0000949111190023), ('subsequent network layers', 1.0000949037709443), ('algorithmic', 1.0000948806726377), ('specify subroutine', 1.0000948786875206), ('new optimization', 1.0000948011236668), ('deep model', 1.0000947994642693), ('benchmark image', 1.0000947252186372), ('graph partitioning', 1.0000946298354905), ('various rnn', 1.0000945988060619), ('optimization corner', 1.0000945126859184), ('corresponding outputs', 1.0000945078837464), ('different language tasks', 1.000094383721502), ('nets rnns', 1.0000943407843008), ('deep inference', 1.0000943266159854), ('deep linear', 1.0000943108720663), ('deep tensor', 1.0000942995831668), ('optimization models', 1.0000942905954366), ('current computing', 1.0000942881969705), ('image preprocessing', 1.0000942841317604), ('bayesian optimization using', 1.0000942793826804), ('context', 1.0000942565099025), ('multi relational', 1.0000942305017981), ('network classification', 1.0000941776962071), ('simple clustering methods', 1.0000941471033409), ('dnn model', 1.000094146142837), ('possible inputs', 1.0000941460097967), ('single bit', 1.0000941303410056), ('entire source', 1.0000940989319154), ('abc algorithm', 1.0000940310856872), ('video dataset', 1.0000939558878104), ('model architectures', 1.0000939450055928), ('such improvements', 1.0000939381473395), ('less computations', 1.0000939374777325), ('graph structured', 1.0000939345955342), ('real world robotics', 1.0000939223282748), ('network structure', 1.0000938336568528), ('incremental learning', 1.0000938057478141), ('stacks queues', 1.000093794987082), ('various bigram', 1.0000937761201836), ('crowdsourced data', 1.0000936945187542), ('internet web', 1.0000936680042674), ('computer go', 1.0000936624438703), ('other tasks', 1.0000936090671688), ('standard rnn', 1.00009353533789), ('distributed representations', 1.0000935130343913), ('visual reasoning', 1.0000935091742222), ('content information', 1.0000934898970053), ('remote server', 1.0000934695625456), ('standard machine comprehension', 1.0000934523326892), ('cross domain object', 1.0000934277929474), ('cross domain', 1.0000934268554649), ('image features', 1.0000934124003298), ('conditional random', 1.0000933568749983), ('problem instances', 1.0000933214359702), ('computer code', 1.0000932999577463), ('novel algorithm', 1.000093236384344), ('task clustering', 1.0000931306823124), ('single object tracking', 1.0000931284241696), ('extensive experiments', 1.000093086249958), ('forward computation', 1.0000930580766645), ('multilayer network', 1.0000930385262314), ('scalable architecture', 1.0000929843368167), ('computing weight', 1.0000929721903877), ('neural network topologies', 1.000092881396286), ('iterative manner', 1.0000928571269239), ('natural images', 1.0000928435780365), ('trusted data', 1.0000927899026186), ('standard algorithms', 1.0000927660853747), ('storage complexity', 1.0000927322786175), ('training vector', 1.0000927003025972), ('em shadow', 1.0000926928538612), ('advanced pattern classifiers', 1.0000926926764555), ('optimisation problems', 1.0000926867886648), ('multi class classification', 1.0000925825900349), ('train', 1.0000925154107363), ('mnist data', 1.0000924904925321), ('backpropagation convergence', 1.0000924728758884), ('real data behave', 1.0000924562801894), ('miss modes', 1.0000924148353927), ('learning frameworks', 1.0000924004285816), ('semantic image', 1.0000923977644667), ('rnns', 1.0000923821400898), ('sequential processing', 1.0000923531153003), ('human experts', 1.000092339132993), ('layer', 1.0000923310314818), ('hierarchical recurrent encoder', 1.0000922958002534), ('multiple abstractions', 1.0000922873250526), ('low level features', 1.0000922088269022), ('existing datasets', 1.0000922003178565), ('natural images video', 1.0000921606683109), ('high level concepts', 1.000092152962927), ('current cad', 1.0000921254722395), ('stochastic updates', 1.0000921254371364), ('query', 1.0000920904135315), ('rnn encoders', 1.000091994661321), ('biomedical word embeddings', 1.0000919693633985), ('macro actions', 1.000091917967463), ('user click', 1.0000918962829133), ('program representation', 1.0000918696693115), ('new tasks', 1.0000918145024762), ('rule based', 1.0000917827747635), ('new architectures', 1.000091782266131), ('large number', 1.0000917558029516), ('rnn may', 1.000091723120927), ('network parameters', 1.0000917139821217), ('dialog systems', 1.0000917099691315), ('many output symbols', 1.000091597111497), ('learned autoencoder', 1.000091572263904), ('neural image captioning', 1.0000915617599984), ('learned kernels', 1.0000915482532544), ('image annotation', 1.0000915482353667), ('new applications', 1.0000915347565884), ('quadratic constraints', 1.0000915224913587), ('trainable parameters', 1.0000915136756852), ('learning parameters', 1.0000914797336733), ('state', 1.0000914237489527), ('separation algorithms', 1.0000914035276434), ('learning pipeline', 1.0000913744936875), ('sparse pointer', 1.0000913712612163), ('differentiable interpreter', 1.0000913644081613), ('architecture search', 1.000091308128343), ('encoder', 1.0000912983919925), ('input manipulation', 1.0000912754051443), ('current ides', 1.0000911900301024), ('equality constraints', 1.0000911797990342), ('neuromorphic architectures', 1.0000911778153574), ('concept drift', 1.0000911663437044), ('application domains', 1.0000911271038764), ('dnns', 1.000091105779094), ('low resource language', 1.0000910629409332), ('evolving semantics', 1.0000910524183946), ('graph embeddings', 1.0000910164310204), ('powerful gpu', 1.0000909950067078), ('image classifier', 1.0000909919394696), ('sequential learning capabilities', 1.0000909760751096), ('meta embeddings', 1.0000909726291063), ('solving reinforcement', 1.000090940520649), ('standard benchmark', 1.000090898542042), ('commercial web', 1.000090881845942), ('leverage dependencies', 1.0000908753313364), ('preprocessing', 1.000090869299967), ('measuring similarity', 1.0000908138536513), ('classification task', 1.0000908137090503), ('configurable network', 1.000090810283576), ('handwritten digit classification', 1.0000907999758992), ('network hidden', 1.000090792873412), ('software baseline', 1.0000907563616188), ('nonlinear networks including', 1.0000907128599397), ('synthetic data', 1.0000906808564285), ('encoding instructions', 1.0000906559535383), ('sparse representation', 1.0000906103442042), ('computer science', 1.0000905479120719), ('large vocabulary speech', 1.0000905330625434), ('program input', 1.000090517858209), ('independent attribute controls', 1.0000905078763174), ('spiking neural', 1.0000904144072926), ('novel convolutional', 1.000090412540391), ('compute resources', 1.000090382707298), ('dynamic texture', 1.0000903612057566), ('stack contents', 1.0000903374766295), ('radial basis', 1.0000903130576306), ('deep learning scenario', 1.0000902985808218), ('reusable components', 1.0000902479042022), ('recurrent autoencoder', 1.0000902435346997), ('neural image description', 1.0000902335239752), ('learning sample', 1.0000902234262354), ('networks graphs', 1.0000901710612429), ('neural transfer function', 1.0000901532709752), ('table querying', 1.0000900944977678), ('structured sparsity', 1.0000900085933415), ('bidirectional image', 1.0000900027112287), ('dialog system', 1.0000900001487798), ('source', 1.0000899734454713), ('embedded', 1.0000898673472116), ('document feature', 1.0000898470600255), ('common benchmarking framework', 1.0000898464455803), ('translation modeling', 1.000089834390833), ('appropriate hardware support', 1.0000898156979174), ('software developers', 1.0000898024447171), ('embedded scenarios', 1.0000897134385736), ('mapping algorithm', 1.0000896750446293), ('fine grained', 1.0000896599102673), ('generative models mapping', 1.0000896446845255), ('standard image', 1.0000896071166527), ('architecture components', 1.0000895779869148), ('temporal computations', 1.0000895550790094), ('greedy parser', 1.0000895515578923), ('hierarchical latent variables', 1.0000895400444518), ('nonlinear pca models', 1.000089539371301), ('approximation error', 1.0000895168175596), ('optimize', 1.0000894900534103), ('useful feature representations', 1.0000894872230723), ('dnn can', 1.000089481488707), ('arbitrary stream data', 1.000089478018435), ('source images', 1.0000894179542943), ('store information', 1.0000893968134819), ('statistical translation', 1.0000893906029726), ('integrated framework', 1.0000893890351592), ('truncation span', 1.0000893731467893), ('weight regularization', 1.0000893505416537), ('lstm improvements', 1.0000893324354194), ('intermediate representations', 1.0000893223930798), ('conditional computation', 1.0000893134215547), ('dataset containing', 1.000089294338725), ('large graphs', 1.0000892914162278), ('quantum games', 1.0000891946799058), ('natural languages', 1.0000891767536846), ('networks architectures', 1.0000891713701643), ('previous iterations', 1.0000891647748817), ('machine understanding', 1.0000891550090265), ('new feature', 1.0000891469463713), ('visual text', 1.0000891097884643), ('real world data', 1.0000890921249936), ('visualize', 1.0000890889828369), ('differentiable computation', 1.0000890714980342), ('greedy parsing', 1.0000889917231053), ('handwritten digit', 1.000088982488426), ('embed', 1.0000889101620096), ('sparse networks', 1.0000888980158662), ('intelligent text', 1.0000888289981518), ('various hardware software', 1.0000888220855688), ('alignment algorithm', 1.0000888103824164), ('adaptive learning rate', 1.0000886855519904), ('temporal convolutions', 1.0000886733432488), ('video sequence', 1.0000886604411905), ('language data', 1.0000886412631051), ('noisy speech recognition', 1.0000885327229174), ('neural layers', 1.0000885237534598), ('textual dataset', 1.0000885118472085), ('essay scoring', 1.0000885099217376), ('low latency', 1.0000884913233061), ('hierarchical 3d', 1.0000884749959125), ('data representation', 1.0000884664221799), ('dynamic boltzmann machine', 1.0000884594979524), ('iterations obtained', 1.0000884461884387), ('real datasets', 1.0000884220431252), ('recursive model', 1.000088397189705), ('semantic', 1.0000883204868876), ('classification datasets', 1.0000883078763319), ('optimization task', 1.0000883070527509), ('fewer mode', 1.0000883024287903), ('search techniques', 1.0000882875999033), ('network trained', 1.0000882792662305), ('aggregated state space', 1.0000882783972693), ('gaussian binary', 1.0000882383835317), ('using dependency', 1.0000882358260543), ('traditional auto encoder', 1.0000882348174032), ('optimized function', 1.0000882100727884), ('back ends', 1.000088201855355), ('inference steps', 1.0000881991362256), ('example api', 1.000088187573725), ('algorithm features', 1.0000881840629756), ('dynamic memory', 1.0000881655412377), ('neural qa', 1.0000881423986068), ('distributed patterns', 1.000088134989032), ('word2vec', 1.0000880643919774), ('adjacent pixels', 1.0000880399989247), ('knowledge', 1.0000880304945006), ('network complexity', 1.0000880199791171), ('speech signal', 1.000087938807785), ('virtual reference objects', 1.000087895631299), ('neuromorphic hardware', 1.0000878455249733), ('network need', 1.0000878207809167), ('systems based', 1.0000878143545582), ('morphological segmentation', 1.0000877726081938), ('unsupervised classes', 1.000087760787957), ('semantic labels', 1.0000877523679734), ('remote sensing multimodal', 1.0000877308163498), ('sparse rewards', 1.000087699366109), ('feedforward stochastic', 1.0000876245989383), ('feature vector', 1.0000876062889057), ('compatible function', 1.0000875948704602), ('address', 1.0000875252191344), ('program models', 1.0000874694332633), ('memory', 1.0000874458908338), ('iterative supervised', 1.0000874194547176), ('arbitrary inputs', 1.0000874147000187), ('original images', 1.0000874029924913), ('variational autoencoders', 1.000087356413401), ('learning distributed', 1.0000873559955514), ('parser', 1.0000873527454202), ('metaheuristic', 1.0000873503953356), ('wearable sensor data', 1.0000873193429125), ('benchmark', 1.0000872934199085), ('features based', 1.000087284617827), ('mapping objects', 1.0000872337832258), ('structured output', 1.0000871642276286), ('sparql', 1.000087161538318), ('cascaded convolution', 1.0000871490435836), ('search framework', 1.000087132923848), ('continuous markov decision', 1.000087122377253), ('deep nets', 1.0000871028118503), ('unstructured text e', 1.0000870645652575), ('distributed training', 1.0000870510862456), ('layer inputs', 1.0000870363734704), ('hyperparameter optimization', 1.000086961463738), ('time', 1.0000868778958532), ('natural conversational', 1.0000868770885218), ('multimodal datasets', 1.000086868067941), ('expressing program', 1.0000868379799486), ('web', 1.0000868363864768), ('methods problem', 1.0000868343341707), ('separate feature analysis', 1.000086826985917), ('successful optimization', 1.0000867563880271), ('sanity check', 1.000086735960711), ('computational requirements', 1.0000867161770903), ('lstm cells', 1.000086715938474), ('discriminative features', 1.0000866485876885), ('using dnn', 1.0000866397284924), ('biological neuron models', 1.000086564368237), ('efficient search', 1.000086552522879), ('raw pixel', 1.0000865029886006), ('long range dependencies', 1.0000864956068292), ('different image', 1.0000864928373263), ('provide features', 1.000086477834104), ('sentiment analysis depending', 1.0000864761826649), ('filter maps', 1.0000864689868099), ('learning controllers', 1.0000864617045813), ('artificial data', 1.0000864353486887), ('several architectures', 1.0000864129237719), ('structured prediction model', 1.0000863944719496), ('training examples', 1.0000863751040554), ('network distribute', 1.0000863604062942), ('robotics allowing', 1.0000863237851947), ('different users', 1.0000862877691727), ('image based', 1.0000862408379865), ('selecting features', 1.0000862369053112), ('different application areas', 1.0000862188118214), ('image handwriting', 1.000086198578057), ('compute truth', 1.000086197382423), ('novel neural', 1.0000861847497058), ('fewer iterations', 1.000086172413791), ('loss functions', 1.0000861690318044), ('intelligent machines', 1.0000861683355309), ('short text', 1.0000861627205149), ('decoding latent', 1.0000861451573202), ('reordering model', 1.0000860572389088), ('standard benchmark tasks', 1.0000860177112834), ('computing', 1.0000860090084576), ('parameterized task', 1.0000860057704093), ('user experience', 1.0000859860232947), ('search tree', 1.000085966484244), ('online', 1.000085935632319), ('parse xml', 1.000085927767127), ('input pattern', 1.0000859210699446), ('extend machine', 1.0000858840099143), ('systematic algorithm', 1.0000858713861631), ('minimal complexity', 1.0000858595822868), ('word vectors', 1.0000857241058427), ('traditional algorithms', 1.0000857224413928), ('model parallel', 1.0000857058180923), ('object localization', 1.0000857053851573), ('word output', 1.00008561612009), ('noisy channel', 1.000085568587783), ('source domain', 1.0000855490988765), ('language description', 1.0000854137462736), ('input words', 1.0000854083557986), ('prediction network', 1.0000853905821325), ('difference methods', 1.0000853223661543), ('human machine', 1.0000853122074282), ('game can', 1.0000853005604957), ('multiple feature maps', 1.0000852888055034), ('ubuntu dialogue', 1.0000852853758202), ('larger datasets', 1.0000852733497796), ('various applications including', 1.000085223239595), ('hmm decoder', 1.0000851795285737), ('iterative technique', 1.0000851757080258), ('fewer features', 1.0000851683897132), ('matching feature', 1.000085147094668), ('external simulation', 1.0000851096447483), ('particular source side', 1.000085025279496), ('constraint based', 1.0000849843161268), ('robust supervised', 1.0000849818892996), ('general np', 1.0000849763842934), ('solve', 1.0000849746856255), ('pre train', 1.0000849672106429), ('corrupted data', 1.0000849634773874), ('original image', 1.0000849274072445), ('image pixel', 1.0000849147142508), ('distributed deep', 1.0000849051062572), ('extensive simulations', 1.0000848378131477), ('automatic video highlight', 1.0000848132387035), ('compact network architecture', 1.0000848073149071), ('novel deep', 1.0000848025566969), ('short text classification', 1.0000847850905574), ('image patterns', 1.0000847829110493), ('simulated robotics', 1.0000847715859433), ('unsupervised learning inferring', 1.0000847306182674), ('minimizing edge', 1.0000847238971808), ('variational auto encoders', 1.0000846518547513), ('approach can', 1.0000846456520136), ('discrete speech code', 1.000084623209717), ('policy search', 1.000084603506982), ('multiple image', 1.0000845978095165), ('sentence simplification', 1.000084593969931), ('unsupervised way', 1.0000845820451296), ('deep rendering', 1.0000845433054848), ('open dataset', 1.0000845016238986), ('extensible', 1.0000844700444516), ('tractable learning', 1.0000844663283115), ('incremental network', 1.0000844129021194), ('generic neural', 1.0000843679514528), ('error oriented', 1.0000843571014113), ('art algorithm', 1.0000843431123407), ('embedding process', 1.0000843294003106), ('parameter sharing', 1.0000843227735683), ('parameterized tasks', 1.0000842925405724), ('generating images', 1.000084256961725), ('french translation task', 1.0000842548305824), ('ssl achieves', 1.000084252035698), ('embedding', 1.0000842429985652), ('image streams', 1.0000842222216484), ('review dataset', 1.00008422147922), ('recent visualization', 1.0000842105958903), ('programmer', 1.000084172431261), ('regression tasks', 1.0000841529875764), ('recognition', 1.0000841172626016), ('architecture allowing', 1.0000841065213848), ('deep inferences', 1.0000841034662384), ('such classifiers', 1.0000840954271992), ('low latency processing', 1.0000840194561997), ('input question', 1.000084006445243), ('random initialization can', 1.0000839874013454), ('networks models', 1.0000839804308845), ('continuous online learning', 1.000083955641331), ('standard evaluation datasets', 1.000083905125306), ('domains program', 1.0000838344316447), ('adversarial samples', 1.0000838336882933), ('current cad approaches', 1.0000838269583638), ('simpler subproblems', 1.0000837640588984), ('word distributions', 1.0000836249017704), ('improve optimization', 1.0000835613446042), ('training software', 1.0000835419978422), ('convolutional filters', 1.0000835383709625), ('heuristic methods', 1.0000835214841997), ('many cheminformatics software', 1.0000835018641965), ('binary multi', 1.000083483731053), ('multi class tasks', 1.000083481009393), ('temporal difference methods', 1.0000834527962075), ('computer aided', 1.0000833966428246), ('neural link', 1.0000833692657187), ('neural dialogue system', 1.0000833679440675), ('query tables', 1.0000833411667107), ('hidden layers consisting', 1.000083327784021), ('such networks depends', 1.000083311940588), ('discriminative model', 1.0000832452541262), ('gradient calculation methods', 1.0000832448649817), ('accurate feature selection', 1.000083226871054), ('optimization policy', 1.000083201672647), ('post processing', 1.0000832015372594), ('network traffic', 1.0000831696187449), ('logistic regression', 1.0000831501483527), ('full precision', 1.000083103354629), ('syntax', 1.0000830960002602), ('input vector', 1.000083065908341), ('optimal machine', 1.0000830421409603), ('neural representation', 1.0000830182703242), ('simple heuristic', 1.00008300884604), ('skip thought vectors', 1.0000830031804007), ('latent feature', 1.0000829591928992), ('dialog models', 1.0000829483444895), ('learning researchers', 1.0000828942830855), ('sensitivity analysis', 1.0000828619170155), ('incremental speech', 1.000082860004723), ('exploit image', 1.0000828229410816), ('generative machine', 1.0000827987175218), ('unsupervised estimation', 1.000082793034913), ('distributed store', 1.0000827915793111), ('sequential latent', 1.0000827527260694), ('variable length', 1.0000827496125166), ('artificial classes', 1.0000827128054959), ('extensive simulations demonstrating', 1.000082712795233), ('regression datasets', 1.0000827030215111), ('hierarchical memory', 1.0000826741374935), ('insufficient training data', 1.0000826349617093), ('discriminative training', 1.0000825957313382), ('need', 1.000082569126262), ('explore', 1.0000825593895073), ('sequential control learning', 1.0000825555584087), ('acoustic modelling', 1.0000825512789113), ('embedding layer', 1.0000825439920575), ('supervised feature', 1.000082513337003), ('candidate solutions', 1.000082495231997), ('object categorization', 1.0000824896335487), ('conditional entropy', 1.0000824397098813), ('go atari', 1.0000824350712385), ('single proxy', 1.0000823556640246), ('explaining predictions', 1.0000823440102267), ('datasets including', 1.000082315412657), ('larger dataset', 1.0000822895604213), ('version', 1.0000822392888549), ('ann graph', 1.0000821640767308), ('simpler features', 1.0000821640675206), ('generative image', 1.0000821444762005), ('learning model', 1.0000821375111806), ('massive datasets', 1.0000821244567784), ('embedding model', 1.0000821048074329), ('provided text', 1.000082092851072), ('limited memory', 1.000082083942228), ('genetic algorithm', 1.0000820427089463), ('hierarchical relational', 1.000082030418838), ('invariant feature', 1.0000820203590186), ('complex dependencies', 1.0000820170454552), ('semantic representation', 1.00008199043716), ('particular tasks domains', 1.0000819843730617), ('text communities', 1.0000818863409104), ('piecewise linear', 1.0000818795221709), ('perform inference', 1.000081859148511), ('standard architectures', 1.00008178770925), ('detected features', 1.000081782915938), ('interpretable cad', 1.0000817607508805), ('simulated robot', 1.0000817606190098), ('network predicts', 1.0000817095405576), ('several combinatorial', 1.000081698876414), ('academic reinforcement learning', 1.0000816557100598), ('cheap commodity hardware', 1.0000816524202678), ('domain', 1.0000816315274395), ('increasing complexity', 1.0000816212468875), ('successor map', 1.0000816205638816), ('maximizing classification', 1.0000815996076355), ('optimization processes', 1.0000815962961378), ('different', 1.0000815925276032), ('temporal modeling', 1.0000815560185543), ('bitwise network', 1.0000814953232948), ('neuromorphic chip', 1.0000814925601502), ('datasets consisting', 1.000081443053352), ('develop computer', 1.0000814338671928), ('data sparsity', 1.0000814338605533), ('latency constraints', 1.0000814283745287), ('3d recovery problem', 1.0000814271367), ('benchmark functions', 1.0000814124002493), ('word sequence', 1.000081358890174), ('streaming data', 1.0000813359285763), ('extension recursive', 1.0000813344263892), ('dynamic data', 1.000081313545557), ('gru model', 1.000081288799692), ('new regularization methods', 1.0000812761969449), ('biomedical question answering', 1.000081275141219), ('additional depth pruning', 1.0000812705811206), ('handle images', 1.0000812616494685), ('similarity graph', 1.000081239299162), ('goal driven', 1.0000812271592927), ('learning data', 1.0000811845624333), ('compress text', 1.0000811721355087), ('processing millions', 1.0000811607457598), ('multitasking', 1.0000811050995444), ('computational tractability', 1.0000810853679145), ('similarity search', 1.0000810835906795), ('speech benchmark', 1.000081082060313), ('optimality guarantees', 1.0000810529103663), ('small dnn', 1.000081042207397), ('prediction pipelines', 1.0000809863088305), ('method uses', 1.0000809478115433), ('physical robot', 1.0000809432786486), ('generate images', 1.000080908762869), ('multitask', 1.0000809040605767), ('latent gaussian', 1.0000809011037353), ('unstructured tasks', 1.0000808944832182), ('learning based', 1.0000808642378618), ('parallelism', 1.0000808446948317), ('training iterations', 1.0000808415257931), ('powerful paradigm', 1.0000808276146946), ('feature maps', 1.000080827599529), ('mnist data set', 1.0000808186122294), ('network predictions', 1.0000807998592562), ('framework generalizes', 1.0000807986429794), ('image channels', 1.0000807458619743), ('new synchronization protocol', 1.0000807025313292), ('game score', 1.0000806949449408), ('simple extensions', 1.0000806785768928), ('invariant features', 1.0000806301387788), ('gaussian process regression', 1.0000806173223558), ('binary features', 1.0000805789031197), ('realistic generator', 1.000080572205174), ('twitter dataset', 1.000080558210777), ('abstractions learning', 1.0000805531483385), ('grayscale', 1.0000805437904983), ('empirical learning', 1.00008053166304), ('mnist dataset', 1.000080526221935), ('sophisticated memory', 1.0000804964055083), ('computational efficiency', 1.0000804060976893), ('similar architectures', 1.0000803895353227), ('deep belief', 1.0000803830584806), ('cpus available', 1.0000803703481258), ('text line', 1.0000803426129141), ('different image patterns', 1.0000803325700018), ('networks learn', 1.0000803111763206), ('alternative architectures', 1.0000802997901428), ('distributional semantics', 1.000080292691915), ('tree graphs', 1.0000802827420394), ('analogical reasoning knowledge', 1.0000802713140244), ('visual sentiment prediction', 1.0000802265574178), ('real application', 1.0000802146014418), ('neural attention combining', 1.0000802055201834), ('graph grammar', 1.0000802048786734), ('speech signals', 1.0000801791924392), ('semantic classification', 1.0000801693849026), ('single machine', 1.0000801689205234), ('new variance reduction', 1.0000801519983633), ('big data', 1.0000801476082297), ('machine comprehension', 1.0000801174205063), ('electronic health', 1.0000801171023903), ('classifier weights', 1.0000800561682563), ('infer', 1.0000800010796143), ('image tagging', 1.000079943785161), ('feature processor', 1.0000799406342893), ('gradient descent schemes', 1.0000798872602525), ('new data representation', 1.0000798813481677), ('visual feature space', 1.000079874905246), ('single model', 1.0000798457915203), ('labeled training', 1.0000798030674785), ('word alignment', 1.000079783609759), ('regularization term', 1.0000797822766387), ('reproducing kernel', 1.0000797820972573), ('rnn regularizers', 1.0000797477144052), ('several cross language', 1.0000797422952934), ('abstractive sentence summarization', 1.0000797133184338), ('text embedding', 1.0000796813184638), ('downstream tasks', 1.000079679322246), ('dialog state', 1.0000796582938551), ('most nlp problems', 1.0000795817261303), ('abstract data', 1.0000795424832205), ('extraction patterns', 1.0000795276244636), ('image understanding', 1.000079507131819), ('unsupervised discovery', 1.0000794731878904), ('best gradient', 1.0000793939186279), ('mapping codes', 1.000079386069384), ('structural support vector', 1.0000793839844253), ('custom oriented', 1.000079375972907), ('deep latent', 1.0000793654293803), ('dataset size', 1.00007933148182), ('system', 1.000079285824209), ('sequential learning', 1.000079276382919), ('human robot', 1.0000792610423295), ('image question', 1.0000792407817456), ('original multimodal', 1.0000791468291552), ('parameters trained', 1.0000791020993547), ('large applications', 1.0000790703171594), ('quantum annealing', 1.0000790424360262), ('xor', 1.0000790266636428), ('understanding tasks', 1.0000789841267173), ('binary classification problem', 1.0000789585413983), ('most nlp', 1.0000789410216204), ('future optimization', 1.0000789334303712), ('edge device', 1.0000789189871613), ('sequential decision making', 1.0000789179653458), ('such bigram embeddings', 1.0000789133000945), ('previous learning theory', 1.0000788958348328), ('different application domains', 1.0000788874686417), ('complex tasks using', 1.0000788824520197), ('unstructured multi', 1.0000788736391912), ('hard code symmetries', 1.0000788704470616), ('robotics', 1.0000788695856573), ('cnn embedding', 1.0000788636876246), ('complex data processing', 1.0000788444272057), ('inverse reinforcement', 1.00007883161369), ('hmm based', 1.0000788264663747), ('digit recognition', 1.000078822520998), ('latent stochastic', 1.0000787964850972), ('only simulation', 1.0000787945315934), ('theoretical analysis', 1.0000787866794432), ('objective functions', 1.0000787593779532), ('parameterized set', 1.0000787510704945), ('rnn s', 1.000078730487439), ('joint optimization framework', 1.0000787150608237), ('generative', 1.0000786945177575), ('representations predictions', 1.0000786768882972), ('memetic algorithm', 1.000078663941682), ('problem', 1.0000786625753193), ('better recognition', 1.0000786503789179), ('dnn computer', 1.000078608189087), ('large training databases', 1.0000786048923223), ('key device', 1.0000785663611755), ('optimal implementation', 1.0000785523168583), ('human robot teams', 1.0000785237923253), ('new test inputs', 1.0000785096037703), ('same features', 1.0000785024286503), ('hierarchical trees', 1.0000784908593674), ('geometric semantic', 1.0000784601415311), ('latent embedding', 1.0000784561273597), ('text sources', 1.0000784426733056), ('end dialog', 1.0000784373879497), ('convergence rate', 1.000078430199511), ('interesting applications including', 1.000078407498743), ('local learning', 1.000078398108721), ('input vectors', 1.0000783712925985), ('labeled input', 1.0000783270150586), ('incremental learning using', 1.0000783166619496), ('self organizing', 1.0000783129544863), ('multi view networks', 1.0000783104024658), ('ontology', 1.0000782892886428), ('turn exploit', 1.000078265556165), ('concatenation', 1.0000782439522562), ('learning applied', 1.0000782259156724), ('clustering quality', 1.0000781953608644), ('novel approach', 1.0000781881095417), ('semantic space', 1.0000781521163156), ('activity recognition', 1.0000781314852842), ('new instances', 1.0000781277425288), ('pattern classification', 1.0000781115287394), ('efficient learning', 1.0000781041636564), ('recurrent dynamics', 1.0000780940572453), ('many cheminformatics', 1.0000780670348817), ('neural network expressivity', 1.000078049337265), ('structured logic rules', 1.000078042278839), ('simple preprocessing steps', 1.000078023814424), ('bits required', 1.0000779989059574), ('universal neuron', 1.0000779839066671), ('question', 1.000077977855478), ('many classification problems', 1.0000779719090105), ('prior class probabilities', 1.0000779559381), ('such architectures', 1.000077918515418), ('recurrent nn', 1.0000778948259155), ('linear classifiers', 1.0000778947759563), ('various tasks', 1.0000778928599507), ('first time', 1.000077891707825), ('multi label methods', 1.0000778819493128), ('generalized data inputs', 1.0000778759232212), ('improve', 1.0000778470526426), ('particular automated', 1.0000778357242046), ('chess engines', 1.0000778346035626), ('document analysis', 1.0000778336899767), ('optimal mutation learning', 1.0000778319243229), ('hyperparameter values', 1.0000777772584342), ('neural structure', 1.0000777671008214), ('standard image classification', 1.000077761933938), ('probabilistic human', 1.0000777419985876), ('parameterized action', 1.00007772400234), ('neural network pruning', 1.0000777088011636), ('neural factors', 1.0000776877181217), ('many recommender systems', 1.0000776542394745), ('continuous speech signals', 1.0000776512271659), ('particular image', 1.0000776315688593), ('semantic decoder component', 1.0000775926113068), ('hidden state', 1.0000775827838984), ('bit space', 1.0000775579666243), ('partial segmentations', 1.0000775569903129), ('universal neuron grid', 1.000077556871119), ('image patches', 1.0000775300686915), ('mesh', 1.000077525267047), ('physical simulation', 1.000077481054897), ('detailed model information', 1.0000774714049074), ('visualization method', 1.00007746804718), ('generalization error', 1.0000774656302913), ('accuracy', 1.0000774548447047), ('compact feature representations', 1.0000774466338045), ('deep recurrent', 1.0000774338951284), ('phoneme recognition task', 1.0000774186705141), ('architecture requires', 1.0000773967757812), ('several datasets', 1.0000773948264756), ('dialogue management', 1.0000773840615373), ('image level', 1.0000773498054825), ('existing images', 1.00007734867053), ('new input', 1.0000773285457478), ('network approach', 1.0000773208354141), ('generate search', 1.0000772997948755), ('translation support', 1.0000772902915411), ('layer activations', 1.000077275273934), ('metric learning based', 1.0000772371962714), ('interpreter', 1.0000772102150117), ('conditional lstm encoding', 1.0000772078490392), ('new dataset', 1.0000771539236908), ('autoencoder regularized', 1.0000771208967068), ('problem called', 1.000077119109444), ('generate models', 1.0000770996930068), ('pattern classifiers', 1.0000770819608897), ('nearest instances', 1.0000770718271652), ('core representation', 1.0000770692212262), ('continuous optimization', 1.0000770446503626), ('model simulations', 1.0000770071768454), ('network encoder', 1.0000769825203568), ('markup generation', 1.0000769294356968), ('latent task', 1.0000769086553196), ('high level representation', 1.0000769019372955), ('many computer', 1.0000768836253406), ('system outperforms', 1.0000768675641554), ('inductive semantic', 1.0000768557379944), ('medical image', 1.00007684541713), ('sentence', 1.0000768147379246), ('geometric model', 1.0000767724917745), ('clustering algorithm', 1.000076745892789), ('automatic evaluation', 1.0000767433037867), ('input sentence', 1.000076737469568), ('implicit preconditioning', 1.0000767148828658), ('simplified speech', 1.0000767144750848), ('markov chain', 1.0000766999847612), ('sql', 1.0000766953802978), ('single dataset', 1.0000766758195616), ('decision trees', 1.0000766681278523), ('text query', 1.0000766660655704), ('predict', 1.00007666161585), ('such networks', 1.00007663722246), ('several robotic', 1.0000766282000508), ('learning errors', 1.0000765942724434), ('program synthesis', 1.0000765928576623), ('single instance', 1.0000765657919837), ('deep generator networks', 1.0000765522250967), ('training corpora', 1.0000765099630524), ('output space', 1.000076487982866), ('perform', 1.0000764832566713), ('directed probabilistic', 1.0000764831719502), ('sparse feedback', 1.0000764587237874), ('network accelerator', 1.0000764363662036), ('joint optimization', 1.0000764273608502), ('suitable parameter initialization', 1.0000763695187462), ('multi classifier', 1.0000763343807937), ('finite datasets', 1.0000762871660602), ('inference task', 1.0000762677930197), ('document', 1.0000762628739208), ('syntactical symbols', 1.000076208986441), ('supervised image', 1.0000761931843423), ('graph', 1.0000761927003845), ('dataset based', 1.0000761795313273), ('raw pixel level', 1.0000761769477629), ('feature detectors', 1.0000761727497518), ('dual stream architecture', 1.0000761595503793), ('describe images', 1.000076146545168), ('high performance data', 1.000076130479065), ('processing videos', 1.0000761137676972), ('distributed word', 1.0000760933999417), ('non convex regularizations', 1.0000760860175095), ('manipulate objects', 1.0000760594781632), ('cluster analysis', 1.0000760537735587), ('build', 1.0000760523607999), ('core component', 1.0000760421046064), ('generated datasets', 1.0000760188943814), ('improving generalization', 1.0000760028122542), ('empirical evaluation', 1.0000759896848226), ('mode collapse', 1.0000759744304117), ('residual learning', 1.0000759374567085), ('better generalization', 1.0000758837585972), ('system based', 1.0000758757206754), ('parameters', 1.0000757739191215), ('single tasks', 1.000075772993121), ('stream data', 1.0000757539641592), ('automating data', 1.0000757537199496), ('architecture uses', 1.0000757502194915), ('applying reinforcement', 1.0000757501354043), ('output weights', 1.0000757036931007), ('classifier layer', 1.0000756989536472), ('propositional logic formulae', 1.0000756844623204), ('neural move', 1.000075670158063), ('method outperforms', 1.0000756650126237), ('probabilistic reasoning', 1.0000756633045715), ('feedforward pass', 1.0000756610011936), ('learning problem', 1.0000756551734475), ('statistical language', 1.0000756173535332), ('methods can', 1.0000755987388263), ('large set', 1.000075585733542), ('computational tractability grows', 1.000075539225924), ('generative tasks', 1.0000755281467621), ('hidden unit', 1.0000755271273094), ('number', 1.0000755103077115), ('process latent', 1.0000754949540895), ('learning speed', 1.0000754897598778), ('machine question', 1.0000754773071003), ('visual analysis', 1.0000754594616699), ('generate distributed', 1.0000754557363223), ('model learns', 1.0000754361499105), ('sampled images', 1.0000753714933996), ('translation system', 1.0000753545443968), ('particle swarm', 1.0000753383899987), ('many sequence learning', 1.0000753248903973), ('virtual data', 1.0000753034902452), ('new synchronization', 1.0000752979624765), ('many ai', 1.0000752376595916), ('discrete text samples', 1.0000751927781117), ('feature sharing', 1.0000751901169418), ('images using', 1.0000751726795267), ('probabilistic model', 1.0000751717149574), ('multi label prediction', 1.000075115126887), ('regularizers can', 1.0000751133399086), ('detection problem', 1.0000750734661497), ('multimodal sequences', 1.0000750632756494), ('rapid iteration', 1.0000750328872665), ('machines should', 1.0000750174941588), ('high level hidden', 1.000075011883394), ('fire microarchitecture', 1.000075002022445), ('probabilistic selection strategy', 1.000075000442301), ('word sequences', 1.000074974938671), ('spam detection', 1.0000749523003911), ('handwritten digits', 1.0000749317463815), ('linear regression task', 1.0000749312441408), ('real time data', 1.0000749094684163), ('video compared', 1.000074891412778), ('correct classifiers', 1.0000748771373507), ('autonomous learning', 1.0000748595581943), ('maximum learning', 1.0000748525148286), ('encoding information', 1.00007485159157), ('grammars', 1.0000748216343203), ('multidimensional grid', 1.0000748080923672), ('new datasets', 1.0000748055033288), ('verification tasks', 1.000074736976136), ('generative encoder', 1.0000747359085704), ('dbpedia', 1.0000747281883973), ('traditional data structures', 1.0000747253469005), ('iterative reconstruction', 1.0000747197669195), ('predictive coding', 1.000074692947534), ('semantic similarity word', 1.0000746578912338), ('standard applications', 1.0000746369233133), ('many applications causing', 1.0000746162550695), ('intrusion detection', 1.0000745949570145), ('datasets comparing', 1.0000745939275824), ('input pixels', 1.0000745786478542), ('shared response model', 1.0000745757781349), ('formal process', 1.000074571818917), ('supervised classification', 1.0000745504539932), ('gradient estimate', 1.000074544435313), ('markup model', 1.0000745242045495), ('word representations', 1.0000745220334049), ('learning network', 1.0000745156062723), ('annealing schemes', 1.0000744766343628), ('lower error solutions', 1.0000744542188593), ('vision tasks', 1.0000744494569016), ('same network', 1.0000744041356318), ('sequence user', 1.000074391740015), ('different scenarios', 1.0000743639133187), ('network approaches', 1.0000743537355061), ('problems', 1.0000743503224299), ('use program', 1.0000743483150056), ('auto', 1.0000743206059803), ('other network structures', 1.0000743201801363), ('logic rules', 1.0000742864577374), ('overfitting increases', 1.0000742755357637), ('memory access', 1.0000742571297367), ('experience replay', 1.0000742418529343), ('paper', 1.0000742355729453), ('such applications', 1.000074233817427), ('individual apis', 1.0000742322661889), ('deep multi', 1.0000742265745057), ('sparse hidden', 1.0000742144160089), ('efficient inference', 1.0000742095397184), ('discrete speech', 1.00007420120946), ('valid infrastructure', 1.000074179052632), ('bioinformatics speech', 1.0000741331624237), ('various hardware', 1.0000741033933245), ('weight updates', 1.0000740821048544), ('arbitrary depth', 1.0000740775706787), ('perform gradient', 1.0000740663910468), ('multiscale features', 1.00007404896398), ('machine learned', 1.0000740199046214), ('raw video', 1.0000740198517701), ('processing elements', 1.0000740005311513), ('special case', 1.0000739861388614), ('underlying recognition task', 1.0000739741534934), ('deep nonlinear', 1.0000739642775525), ('adversaries can', 1.0000739396564762), ('multilingual recognition', 1.0000739376736654), ('presentational markup', 1.000073926921726), ('parse', 1.0000739200985187), ('art rnn', 1.0000738887721508), ('other tasks interpretability', 1.0000738636120294), ('example', 1.0000738196002243), ('differentiable approximation', 1.000073812102038), ('regularization methods', 1.0000738010705077), ('artificial perception', 1.00007377809327), ('text document', 1.0000737641683919), ('model words', 1.0000737499138066), ('single task', 1.000073746536576), ('sparse targets', 1.0000737357947056), ('pre image', 1.000073662903945), ('answer questions', 1.0000736518934554), ('others might', 1.0000736349018993), ('logarithmic time lookup', 1.000073623637119), ('retrieval models', 1.0000736099231284), ('dependency tree', 1.000073604238517), ('knowledge based', 1.0000735994933436), ('feature set', 1.000073582626888), ('image signals', 1.0000735649614123), ('bayesian networks using', 1.0000735452405645), ('method achieves', 1.0000735441387003), ('time steps', 1.0000735248785209), ('available training data', 1.000073496734391), ('core tasks', 1.000073492121719), ('large discrete', 1.0000734746981583), ('reservoir computing', 1.0000734460831093), ('human face images', 1.000073445963951), ('continuous control tasks', 1.000073423731912), ('emergent behavior', 1.0000734038001549), ('molecular graph', 1.000073382021241), ('k bits', 1.0000733414419114), ('iterative inference', 1.0000733053089848), ('structured exploration strategies', 1.000073290996948), ('perform object', 1.000073274124572), ('linear discriminators', 1.0000732735886988), ('hidden weights', 1.000073273504285), ('matrix factorization', 1.0000732722666623), ('byte level', 1.000073267948226), ('applications e', 1.0000732457364852), ('features needed', 1.0000732361238935), ('other modules remain', 1.0000732311904), ('nonlinear networks', 1.0000731794189535), ('network layers', 1.0000731520327224), ('raw speech signals', 1.0000731498653321), ('original data', 1.0000731382752053), ('traditional computer', 1.0000731299125456), ('speech decoders', 1.0000731289854927), ('practical hardware', 1.0000731247243235), ('low resource', 1.000073115024431), ('feature matching', 1.000073100412219), ('recurrent deep', 1.0000730932991335), ('learning method', 1.0000730874862993), ('automatic training processes', 1.00007307667082), ('3d skeleton', 1.0000730534646576), ('several benchmark analogy', 1.0000730174184198), ('avoid overfitting', 1.0000729980539464), ('new task', 1.0000729833612916), ('qa system', 1.0000729600206957), ('labeling tasks', 1.0000729596001892), ('classes allowing', 1.000072947936164), ('multitask learning', 1.0000729235683803), ('ctc word', 1.0000729131145458), ('use parallelization', 1.0000729064079916), ('gradient information', 1.0000728994938162), ('network configurations', 1.0000728781096222), ('model sparsity', 1.0000728776093994), ('neural networks alleviate', 1.000072849111113), ('recognition systems', 1.0000728368884806), ('convex optimization', 1.0000728339492209), ('nonlinear function', 1.0000728056331767), ('step size', 1.0000727777913823), ('paragraph vectors', 1.000072746080291), ('low level descriptors', 1.0000727165438905), ('novel learning method', 1.0000727163090828), ('agent environment', 1.0000727117446748), ('novel task clustering', 1.0000727039192279), ('generalization performance', 1.0000727000705942), ('machine reading', 1.0000726884952078), ('random initialization', 1.0000726648676896), ('language descriptions', 1.000072659072188), ('unstructured environments', 1.0000726581701276), ('multi view crowdsourced', 1.000072619629919), ('proximity based', 1.0000725954180243), ('raw sensor data', 1.0000725717884533), ('inference process', 1.0000725461391684), ('arbitrary', 1.0000725404255242), ('weighted feature representations', 1.0000725258273035), ('cheap hardware', 1.0000725210873416), ('deployment using', 1.0000724905260763), ('show', 1.0000724888512265), ('words modeling', 1.0000724815558037), ('dialogue response', 1.0000724562973766), ('probabilistic graphical', 1.0000724391736302), ('visual attributes', 1.0000724184674878), ('image captioning', 1.0000724055197336), ('find', 1.000072384048619), ('iterative', 1.000072336117859), ('personalize', 1.0000723018553168), ('kernels', 1.0000722738760204), ('visualizing', 1.000072244874167), ('discrete feature', 1.0000722381508325), ('dnn based', 1.0000721977540172), ('linear reduction', 1.0000721943770825), ('tweaks', 1.0000721675015296), ('rnn receives', 1.0000721637446046), ('discriminative sentence modeling', 1.0000721527319916), ('document modeling', 1.0000721516998112), ('video action', 1.0000721494315679), ('storage size', 1.0000721294980126), ('optimal learning', 1.000072121755452), ('service requests', 1.000072109504419), ('networks require', 1.0000721094229874), ('collaborative image drawing', 1.0000721070005902), ('network generates', 1.000072099970715), ('different locations', 1.0000720677640267), ('artificial class', 1.0000720381684127), ('video scene', 1.0000720319611713), ('gradient vanishing', 1.000071952190439), ('robot based', 1.0000719393012107), ('predictive coding networks', 1.0000719263306885), ('speaker verification', 1.0000718938354916), ('hybrid recommender system', 1.0000718800149144), ('modern signal processing', 1.000071822898383), ('memory units', 1.0000718077292032), ('learning research', 1.0000718012233907), ('whole image classification', 1.0000717974855171), ('reduced overfitting', 1.0000717727585602), ('art imagenet', 1.000071747526665), ('neural feedback relevance', 1.000071732108324), ('exact matching', 1.0000717233193392), ('gaussian processes', 1.000071694568614), ('several data sets', 1.0000716706940427), ('small tweaks', 1.0000715961362139), ('approximation errors', 1.0000715905026027), ('network translation', 1.0000715738656625), ('classifiers', 1.00007156597093), ('limited hardware', 1.0000715330828716), ('svms', 1.00007153065118), ('representative parametric algorithms', 1.0000715292587141), ('conversational telephone speech', 1.000071526981663), ('flexible goal specifications', 1.0000715122586805), ('conventional token', 1.0000715087363437), ('artificial system', 1.000071504425025), ('low precision', 1.00007149138794), ('arbitrary stream', 1.0000714904819084), ('mobile computing', 1.0000714830993327), ('image video', 1.0000714830239745), ('method performs', 1.0000714745520838), ('process tasks', 1.000071471613565), ('large margin', 1.0000714664886292), ('update', 1.0000714638645987), ('same data sets', 1.0000714498592849), ('neural dialogue', 1.0000714459590476), ('speech recognizer', 1.000071429288941), ('semantic consistency', 1.0000714201130003), ('temporal variables describing', 1.0000714151332601), ('solving challenging', 1.000071390616954), ('latent vectors', 1.0000713663429477), ('temporal abstraction can', 1.0000713470420577), ('rnns outperform', 1.0000713436199746), ('system supported', 1.0000713396748586), ('discrete text', 1.0000713268683594), ('bayesian networks', 1.0000713045844691), ('gradient steps', 1.0000713043530098), ('infeasible amount', 1.0000713008358595), ('random spiking networks', 1.0000712571525259), ('computational hypothesis', 1.000071232987238), ('different domains', 1.000071231111948), ('validate', 1.0000712057216543), ('target', 1.000071195906649), ('traditional autoencoder models', 1.0000711953835173), ('raw sensor', 1.0000711906608477), ('faster learning', 1.0000711869729686), ('higher level representations', 1.0000711756268292), ('semantic learning', 1.0000711658343564), ('predefined', 1.0000711619821405), ('vanilla encoder', 1.0000711581745128), ('structured attention networks', 1.0000711270030864), ('high quality features', 1.0000711059786545), ('many programs', 1.0000710338846805), ('pre training data', 1.000070975849603), ('document models', 1.0000709716669987), ('dialog act', 1.0000709654656181), ('content', 1.0000709457924286), ('network enhanced', 1.0000709434180044), ('pointer network', 1.0000709391270917), ('text understanding', 1.0000709369258827), ('large data set', 1.0000709189795842), ('robot arm', 1.00007091181463), ('various test patterns', 1.0000709058976625), ('multimodal learning', 1.000070877511174), ('multimodal fusion', 1.00007086145228), ('embedding vectors', 1.0000708549983572), ('possible segmentations', 1.0000708403890195), ('word prediction', 1.000070819031011), ('particular machine', 1.0000708091422144), ('disentangled representations', 1.0000707975202145), ('reduce memory', 1.0000707913808378), ('appropriate hardware', 1.000070780217291), ('random search', 1.000070776509057), ('limited training data', 1.0000707639905777), ('tasks sentiment', 1.0000707269093594), ('performance robustness', 1.0000707155549404), ('specific propagation rule', 1.0000707001457538), ('interplay', 1.0000706926168488), ('detailed comparison', 1.0000706915174888), ('multi', 1.000070671579436), ('dnn techniques', 1.0000706704854385), ('cost function', 1.0000706638033823), ('modelling sequences', 1.000070653242663), ('large dnn', 1.0000706527240508), ('form', 1.00007064212843), ('strong network performance', 1.0000706296154798), ('end paradigm', 1.0000706236434909), ('architecture using', 1.0000706163792463), ('other data sets', 1.0000706122223082), ('networks called', 1.000070590370778), ('tractable learning sampling', 1.0000705829929697), ('enhanced', 1.0000705814666564), ('temporal attention', 1.0000705614992071), ('combine multimodal', 1.0000705565085446), ('queries', 1.0000705556376839), ('pattern analysis', 1.0000705423999785), ('nlp', 1.0000705409518131), ('least squares method', 1.0000705317627203), ('hyperparameter', 1.0000705236058929), ('prototypical networks', 1.000070516709426), ('many languages character', 1.0000705142489004), ('sequence discriminative', 1.0000705070903373), ('such generators captures', 1.0000705040178761), ('new data', 1.000070470003302), ('structured data', 1.0000704696575575), ('order', 1.000070458979323), ('datasets representing', 1.0000704538137053), ('generative kernels', 1.0000704365066144), ('step sizes', 1.0000704323549465), ('error corrections', 1.0000704278596644), ('pass decoding', 1.0000704086614283), ('tracking objects', 1.0000704079966465), ('sparse prediction', 1.000070389546685), ('decision boundary', 1.0000703777864661), ('experts layer', 1.0000703761477743), ('large problems', 1.0000703717973056), ('networks compression', 1.0000703547244019), ('input test', 1.000070341227354), ('layer following', 1.0000703239947484), ('unlabeled target data', 1.0000702973827444), ('model integration', 1.0000702942877713), ('relational rule', 1.0000702867665359), ('useful feature', 1.0000702505995063), ('sequential decision', 1.0000702300787623), ('supervised speech', 1.0000702216431923), ('value iteration', 1.000070203400046), ('baseline model', 1.0000701891475092), ('memory unit', 1.0000701781259225), ('deep features', 1.0000701666163345), ('supervised representation', 1.0000701661775704), ('financial ai', 1.0000701240887202), ('radial basis function', 1.0000700863360854), ('relational databases', 1.0000700833516045), ('deep learning methodology', 1.000070080160618), ('system identification', 1.000070054680019), ('segmentation problem', 1.0000700056665544), ('optimizing spiking', 1.0000699821313672), ('human annotators', 1.0000699805269226), ('stochastic updates suffer', 1.0000699777097515), ('evaluate', 1.0000699767195562), ('supervised classifications', 1.0000699198366163), ('applications related', 1.0000699114671847), ('learning theory', 1.0000698992537969), ('learning techniques', 1.0000698486731254), ('structured object', 1.0000698172621505), ('search', 1.0000698136624668), ('semi text', 1.0000697979537223), ('long term memory', 1.0000697940163317), ('human motion', 1.0000697737979716), ('heuristic rules', 1.000069758990454), ('probabilistic variant', 1.000069757019137), ('only simulation data', 1.000069754398509), ('final output', 1.0000697153241862), ('dynamic texture patterns', 1.0000696984498534), ('acoustic modeling', 1.000069674483583), ('input module', 1.0000696619320175), ('distributed paragraph', 1.0000696554507333), ('developed classifier', 1.0000696321941804), ('parameterization resulting', 1.0000695884504518), ('autonomous cars', 1.0000695823038914), ('visual objects', 1.000069577439761), ('sparse', 1.0000695647904032), ('2nd iteration', 1.0000695487520244), ('layer transformations', 1.0000695324694284), ('training procedure', 1.0000695305088254), ('larger text', 1.0000695275949303), ('original dataset', 1.000069527337756), ('cpu', 1.0000695253252725), ('compatible vector', 1.000069464892571), ('adversarial models', 1.0000694315612138), ('problem considers', 1.0000694055833135), ('adversarial training', 1.0000693946610877), ('image infer', 1.0000693916070953), ('real data', 1.0000693734735246), ('transducer computes', 1.0000693077715928), ('smooth optimisation', 1.0000692981437043), ('learn representations', 1.0000692953668835), ('corresponding output', 1.0000692861509344), ('benchmarks', 1.0000692561585771), ('domain experts', 1.0000692535554168), ('translation quality', 1.000069243168741), ('standard gradient', 1.000069234125775), ('slow reinforcement learning', 1.0000692164770588), ('stochastic control problems', 1.0000692153151982), ('time convolution', 1.0000691810862186), ('resulting models', 1.000069152877855), ('words model', 1.0000691223278024), ('3.3x', 1.0000691120675098), ('similarity classifier', 1.0000690995306798), ('network provides', 1.0000690961132475), ('work exploits', 1.0000690800027063), ('learning technique', 1.0000690642224177), ('learning systems', 1.0000690590551482), ('important word level', 1.0000690570794004), ('training convergence', 1.0000690557949368), ('dynamics inspired', 1.0000690525143308), ('hebbian learning', 1.0000689968700054), ('images generated', 1.000068939912799), ('deep speech', 1.0000689343483637), ('big data analysis', 1.000068930252497), ('simple game', 1.0000689284453952), ('imagenet dataset', 1.0000689273200631), ('multimodal sentiment analysis', 1.0000689201923842), ('network performance', 1.0000689192501617), ('challenging benchmarks', 1.0000689134047014), ('semantic relatedness', 1.0000689105863476), ('classification error', 1.0000689054049365), ('networks pac', 1.0000688849302004), ('modeling', 1.000068876731318), ('speech transcription', 1.0000688626405494), ('new model', 1.000068859306982), ('discrete memory', 1.0000688536906235), ('wide layer', 1.0000688204746622), ('data streams', 1.0000687968475628), ('multi object', 1.0000687675442559), ('varying complexity', 1.0000687655746474), ('recommending images', 1.0000687467025633), ('variance reduction', 1.0000687464082032), ('individual units', 1.0000687402851651), ('semantic similarity', 1.0000687400541322), ('textual reviews', 1.000068716821735), ('reconstruction error', 1.0000686600896862), ('decoding process', 1.0000686581478908), ('raw inputs', 1.0000686574028088), ('large corpora', 1.0000686510009), ('random method', 1.0000686328445487), ('dual sequence modeling', 1.0000685967640615), ('bi directional', 1.0000685767969137), ('sequential input', 1.000068575055253), ('related problems', 1.0000685517756345), ('projecting input', 1.0000685410587327), ('input structures', 1.0000685051079643), ('adversarial sample', 1.000068502612852), ('network functions', 1.0000684941880753), ('representations learned', 1.000068484523796), ('synthesis learning', 1.0000684782351799), ('supervised approach', 1.0000684580636305), ('natural data sets', 1.0000684211220916), ('provide', 1.0000684157557356), ('machines progresses', 1.0000683906642662), ('reconstructing images', 1.0000683385299656), ('parameter convergence rates', 1.0000683323224113), ('such tasks', 1.000068324792127), ('basic structures can', 1.000068294588725), ('visual world', 1.0000682746475436), ('multiple tasks', 1.000068268568869), ('model uses', 1.000068255692349), ('reward function', 1.000068254764795), ('sample images', 1.0000682321128451), ('gradient vectors', 1.000068213132509), ('unrolled iterative', 1.000068206482273), ('multimedia content', 1.0000681953813266), ('related approximation', 1.0000681792473758), ('architecture makes', 1.0000681734226813), ('transcribe speech', 1.0000681583530593), ('words models', 1.0000681015752046), ('handle occlusion', 1.000068072837055), ('theoretical proofs', 1.000068068003381), ('transition mapping', 1.000068050139473), ('accelerated deep', 1.0000680474805212), ('clustering algorithms', 1.0000680461939655), ('hyperparameters', 1.0000680129717388), ('noise vector', 1.0000680052111084), ('softmax', 1.000067982750575), ('using machine', 1.000067968723316), ('subgraphs', 1.000067957503654), ('optimized mapping', 1.0000679553400158), ('deep rl', 1.000067954689991), ('possible classes', 1.0000679340229446), ('multimodal sentiment', 1.0000679253481175), ('vector concatenation', 1.0000679174414648), ('features should', 1.0000679033184967), ('generated texts', 1.0000678809262653), ('set', 1.0000678800183402), ('new deep', 1.000067861406902), ('feedforward', 1.0000678604890505), ('local optima', 1.0000677785575112), ('learning tag', 1.000067757442725), ('develop', 1.0000677547544343), ('key value', 1.0000677496823553), ('sentiment prediction', 1.000067687881112), ('various visual', 1.0000676758318907), ('adaptive text prediction', 1.0000676536361044), ('visual domain', 1.0000676512766), ('image domain', 1.0000676461290723), ('subspaces layers', 1.000067645924535), ('pre segmentation', 1.0000676396711083), ('simulated data suggesting', 1.0000676351159639), ('recurrent network decoder', 1.00006763262862), ('single classifier', 1.0000676319879511), ('universal recurrent', 1.0000676042541417), ('other modules', 1.0000675995872002), ('manipulating objects', 1.0000675316475514), ('maximum likelihood learning', 1.0000675178902092), ('output activations', 1.0000675171097517), ('key phrase detection', 1.0000675035657225), ('classify patterns', 1.0000674991900362), ('given dataset', 1.0000674661077509), ('classification problem', 1.0000674471189313), ('problem domains', 1.0000674395769475), ('pre trained models', 1.000067438473158), ('large learning rates', 1.0000674321778327), ('similar features', 1.0000674176833206), ('arbitrary size', 1.0000674121342552), ('universal adversarial', 1.000067410113145), ('feature representation', 1.000067382543259), ('novel generative', 1.000067370280103), ('probabilistic pooling operation', 1.0000673569531358), ('recurrent', 1.0000673516894558), ('content selection', 1.0000673506823472), ('real tasks', 1.0000673490551009), ('advanced version', 1.0000673413982342), ('random indexing', 1.0000673167520346), ('distributed format', 1.0000672903693946), ('promising results', 1.0000672718020382), ('recent image classification', 1.0000672700973114), ('medical imaging', 1.000067262979614), ('wearable', 1.0000672554083518), ('average case', 1.0000672464506624), ('solution space', 1.0000672352402482), ('krylov subspace', 1.000067231440681), ('polynomials', 1.00006721628155), ('object tracks', 1.0000672139119917), ('iterative image', 1.0000672017314909), ('cumbersome substitute models', 1.0000671957348288), ('solvable problems', 1.000067193644633), ('limited complexity', 1.000067170678712), ('image saliency', 1.0000671511708934), ('key constraint', 1.0000671370377656), ('mesh learning', 1.0000671301833237), ('gaussian input', 1.0000671253022273), ('adversarial nets', 1.000067101577662), ('denoising autoencoders', 1.0000670848688722), ('embedding acquisition', 1.000067082083587), ('symmetric window', 1.0000670491681904), ('reordering prediction', 1.0000670423737044), ('belief networks', 1.0000670385915196), ('multiply adds', 1.0000670375094176), ('checking robustness', 1.0000670333203312), ('keyword', 1.0000670169059631), ('discrete actions', 1.000066980024316), ('code suggestion', 1.0000669747237705), ('search queries', 1.0000669564363494), ('different hyperparameters', 1.0000669392019914), ('input perturbations', 1.0000669321375362), ('policy gradients', 1.000066930338115), ('full precision networks', 1.0000669020777813), ('labelled data', 1.000066880874856), ('stacking blocks', 1.0000668766634762), ('image sample', 1.0000668632776173), ('comparison', 1.000066859419605), ('baseline systems', 1.000066858572736), ('dynamic time', 1.0000668564145991), ('stochastic model', 1.0000668026202215), ('spatial rnn', 1.0000667910094625), ('semantic descriptor', 1.000066775380986), ('improve word', 1.0000667698256975), ('network projects', 1.0000667685091058), ('greedy decoding', 1.0000667655662632), ('neural science', 1.000066751771844), ('relational rules', 1.0000667386484927), ('quadratic loss', 1.00006673274911), ('dynamic tasks', 1.0000667316440521), ('neuron bias', 1.0000667283919098), ('autonomous devices', 1.0000666852764757), ('images identification', 1.0000666751849179), ('center node', 1.0000666681171881), ('temporal abstraction', 1.0000666645687433), ('human evaluation', 1.0000666576522104), ('real world scenarios', 1.0000666456377458), ('regularization can', 1.0000666275236185), ('high confidence', 1.0000665750056692), ('existing multimodal', 1.0000665723244835), ('demonstrate', 1.0000665485575833), ('perform word', 1.0000665469436174), ('network size', 1.0000665414219203), ('various rnn regularizers', 1.0000665378703302), ('least squares', 1.0000665368123218), ('translation pairs', 1.0000665158794706), ('code', 1.000066510293357), ('different applications', 1.0000665032296252), ('sentence embeddings', 1.0000664505065417), ('shallow networks', 1.0000664458651598), ('text documents', 1.0000664396675425), ('factor graph', 1.0000664204003895), ('model predictions', 1.0000663616230447), ('3d recovery', 1.000066353832217), ('context information', 1.0000663530993823), ('improved pattern', 1.0000663378329315), ('gradient estimators', 1.0000663366311335), ('simple regularization', 1.000066319400846), ('sparql endpoint', 1.0000663013018452), ('dropout regularization', 1.00006629882742), ('evaluation datasets', 1.0000662949258412), ('method called', 1.0000662792232176), ('subsequences', 1.0000662571824774), ('image corresponding', 1.0000662525685744), ('future neuromorphic', 1.0000662523219133), ('output representation', 1.0000662516990462), ('architecture can', 1.0000661503216985), ('previous discretization', 1.0000661410051226), ('increase language', 1.000066137758603), ('self driving', 1.0000661287748773), ('image alignment', 1.0000661212820956), ('optimal hyperplane', 1.0000661102769597), ('adapting parameters', 1.000066093435426), ('word character', 1.0000660811448039), ('semantic processing', 1.0000660741271123), ('particular application', 1.000066058735511), ('accessibility tests', 1.0000660158266468), ('distant speech recognition', 1.000066006377416), ('multiclass model', 1.000066004911321), ('particle swarms', 1.0000660041149374), ('memristor synapses', 1.000065996390762), ('global minimum', 1.0000659885494367), ('network function', 1.0000659784579715), ('implicit distributions', 1.000065976046494), ('gaussian mixture', 1.0000659581846079), ('several tasks', 1.0000659568775607), ('evolve models', 1.0000659549685018), ('multimedia text', 1.0000659400500742), ('sequence generation', 1.0000659199191748), ('short text conversation', 1.0000659181675497), ('learn latent', 1.0000659143387278), ('network given', 1.0000658474083741), ('data instances', 1.0000658459663356), ('system called', 1.0000658417652963), ('limited dataset', 1.000065807708215), ('approximate inference', 1.0000658007094716), ('different scenarios demonstrating', 1.0000657692604584), ('bio imaging analysis', 1.0000657649398559), ('multimodal image', 1.0000657402224473), ('networks utilizing', 1.0000657211006345), ('real world deployment', 1.0000657141612792), ('similarity based', 1.0000657092869905), ('structured logic', 1.0000656944262456), ('architectures cnns', 1.0000656872825937), ('lookup', 1.0000656827726593), ('sequence network', 1.000065670409565), ('conversational responses', 1.0000656510319346), ('word similarity', 1.0000656410357114), ('construction graph', 1.0000656396425984), ('dnns improves', 1.0000656283765568), ('larger scale data', 1.0000656278876172), ('sparse reconstruction', 1.0000656173238907), ('logical semantics', 1.0000656027114645), ('words', 1.000065593895256), ('mnist database', 1.0000655922872541), ('abstract invariant features', 1.0000655898117148), ('compare entities', 1.0000655846387272), ('neuromorphic', 1.000065543266118), ('combining classifiers', 1.0000655373606466), ('optimal policy', 1.0000655264820402), ('stochastic control', 1.0000655217312817), ('specific application', 1.0000655139736643), ('dataset making', 1.0000655068440054), ('networks involves', 1.0000655046810811), ('matching networks', 1.0000654939693798), ('calculating gradients', 1.0000654781821514), ('evaluation functions', 1.0000654696044022), ('generalized constraint', 1.0000654618145908), ('different network', 1.0000654583897122), ('parameters shared', 1.000065451097539), ('random features', 1.0000654328443248), ('auxiliary character level', 1.000065424714445), ('textual representation', 1.0000654235403), ('gradients improve', 1.00006541891292), ('annotated training', 1.0000653949290705), ('formal analysis', 1.0000653886916304), ('multi task fashion', 1.000065384424822), ('context based', 1.000065374161233), ('whole network', 1.000065357652005), ('incremental', 1.000065338778021), ('sentence compression', 1.0000653367284542), ('element wise', 1.0000653327970428), ('binary encodings', 1.0000653258755223), ('produce images', 1.000065307007925), ('multiple languages', 1.0000652764202373), ('embedded speech', 1.0000652711612839), ('model trained', 1.0000652632606606), ('low data', 1.0000652442271625), ('annotated images', 1.0000652408726305), ('event embeddings', 1.0000651963312264), ('models trained', 1.0000651961964857), ('overfitting', 1.0000651916870258), ('dataset derived', 1.0000651873240385), ('end speech', 1.000065181522485), ('deep memory based', 1.0000651788309016), ('regular patch', 1.0000651767919866), ('generated adversaries', 1.0000651739283108), ('regularization', 1.0000651710610338), ('data space', 1.0000651618926215), ('implementation would', 1.000065146837207), ('current performance representation', 1.0000651459340144), ('edges called', 1.0000651216689898), ('document understanding', 1.0000651123945854), ('segmentation model', 1.0000651019599898), ('simulate', 1.0000650617831741), ('reduce dimensionality', 1.0000650513138207), ('real neurons', 1.0000650391427612), ('different dropping probabilities', 1.0000649951057714), ('binary units', 1.000064981409582), ('art networks', 1.0000649796875019), ('sparse prediction targets', 1.0000649511444284), ('multiple objects', 1.0000649463123161), ('discrete maze', 1.000064943393163), ('models paths', 1.0000649372120436), ('hidden representations', 1.0000649121493095), ('noisy estimation', 1.0000649031457305), ('content based', 1.0000648962531706), ('deep cnns', 1.000064882257624), ('bidirectional encoding', 1.0000648775788943), ('general paradigm', 1.0000648728284927), ('intrinsic sparse', 1.000064864125313), ('source domains', 1.0000648636153218), ('multidimensional data', 1.0000648429907608), ('online human', 1.0000648378119235), ('method operates', 1.0000648264895462), ('novel kernel', 1.0000648159720338), ('generative topic embedding', 1.0000648147508087), ('end object', 1.0000647960987985), ('optimisation', 1.0000647933057873), ('efficient training using', 1.000064792462643), ('resampled data', 1.0000647743584097), ('different learning problems', 1.0000647684942516), ('nonnegative matrix factorizations', 1.0000647674911718), ('local minimum starting', 1.0000647517510801), ('visual descriptors', 1.0000647439301715), ('network topologies', 1.0000647069124846), ('stochastic', 1.0000646881461288), ('developed network', 1.000064681884477), ('semantic matching', 1.0000646589189508), ('simple clustering', 1.000064638539712), ('prediction performance', 1.0000646309350165), ('adaptive text', 1.0000645919920261), ('challenging image', 1.000064590494602), ('multiple data', 1.00006458042543), ('framework ensures', 1.000064566285106), ('viewer', 1.0000645597072773), ('recurrent batch', 1.0000645593525963), ('generic image', 1.00006455266221), ('mathematical language', 1.000064550476513), ('other hand', 1.0000645371545798), ('large dnn models', 1.0000645316927126), ('raw speech signal', 1.0000645314843977), ('multiple layers', 1.0000645279238487), ('decision tree', 1.000064519144155), ('natural interaction', 1.0000645148747107), ('linear surrogate model', 1.000064508768207), ('lower bounds', 1.0000645000371111), ('learning time', 1.0000644962626055), ('snapshot learning', 1.000064471101949), ('addition', 1.0000644451884655), ('lagrangian relaxation', 1.0000644058965034), ('approximation', 1.0000643974672665), ('networks evolve', 1.0000643770954034), ('sentence representation', 1.000064376336023), ('images video', 1.000064296010094), ('english conversational speech', 1.0000642858273583), ('networks analysis', 1.000064273439183), ('most feature engineering', 1.0000642524109136), ('representation', 1.0000642285264396), ('different regularizers', 1.0000642174116228), ('compositional models', 1.0000641970495883), ('pattern recognizers', 1.0000641937278258), ('sms messages', 1.0000641812809186), ('tweet embeddings generated', 1.00006416912738), ('raw face videos', 1.0000641595121589), ('visual prompts', 1.000064145465037), ('neural feedback', 1.0000641209906098), ('linear regions', 1.0000641125508616), ('same hidden size', 1.0000641007055486), ('scheduling strategies', 1.000064071869321), ('fpga implementation', 1.0000640683335944), ('evaluation tasks', 1.0000640664361835), ('subtrees', 1.0000640631023539), ('joint learning', 1.0000640322552337), ('video', 1.0000640303066708), ('efficient deep', 1.000064021544203), ('hard parameter sharing', 1.0000640210346905), ('dynamic context', 1.0000640067014308), ('facial landmark detection', 1.0000639938098523), ('effective representations', 1.0000639844034638), ('submodular functions', 1.0000639700626774), ('understanding semantics', 1.0000639635109128), ('method generalizes', 1.0000639586314053), ('legends', 1.0000639473274833), ('robotics man', 1.000063912080068), ('gradient introduced', 1.0000638940340436), ('develop models', 1.0000638727181617), ('learning entities', 1.0000638704235405), ('cause update', 1.0000638618904019), ('visual question', 1.0000638574489735), ('available memory', 1.0000638552916843), ('tracking', 1.0000638405003621), ('real world images', 1.0000638230287278), ('bitwise', 1.0000638071146033), ('line feature', 1.0000637823536611), ('similarity matrix', 1.0000637801802765), ('many information retrieval', 1.0000637795679148), ('decoder network', 1.0000637623955013), ('tighter region bounds', 1.0000637543696975), ('program induction', 1.0000637456264188), ('many text', 1.0000637352324047), ('latent projection', 1.000063734273941), ('multi domain', 1.0000637253094873), ('discriminator function', 1.0000637242341452), ('meta learning framework', 1.0000636805486645), ('highest identification accuracy', 1.000063671924587), ('arcade', 1.000063665761418), ('different hyperparameter', 1.00006364392995), ('wearable sensor', 1.0000636289549176), ('model learning', 1.0000636178105051), ('several improvements', 1.000063611935088), ('online stream data', 1.0000636094289574), ('primitive based shape', 1.0000635994560534), ('video input', 1.0000635954774397), ('parametric speech', 1.0000635647832352), ('pixels', 1.0000635514060134), ('residual networks using', 1.0000635438220278), ('multidimensional data set', 1.0000635284114252), ('pixel', 1.000063522186019), ('training dnns', 1.0000634937634088), ('speech code', 1.0000634899869112), ('many content', 1.0000634864647848), ('loss gradients', 1.000063459914204), ('smoothed analysis', 1.0000634431832511), ('rnn cell', 1.0000634319888069), ('discriminative patterns', 1.0000634191846365), ('endpoint', 1.0000633847329543), ('recurrent step', 1.000063366305624), ('output sequences', 1.0000633376266286), ('whole image', 1.0000633067232307), ('capture', 1.0000632826344258), ('lasso type', 1.0000632771654476), ('low memory', 1.0000632738898294), ('challenging generalized', 1.0000632725759886), ('robustness', 1.0000632417088469), ('reproduce learning', 1.0000632286049569), ('bidirectional', 1.0000632089124644), ('improve comparisons', 1.0000631888017326), ('train models', 1.0000631820935715), ('real world setting', 1.0000631780696654), ('network can', 1.000063168804013), ('produce word', 1.000063142509983), ('validation', 1.0000631401812128), ('flexible factorization', 1.0000631070218806), ('speech frames', 1.0000630899982983), ('data generating', 1.0000630855820556), ('generative process', 1.0000630766357737), ('novel framework', 1.0000630647310975), ('semantic script', 1.000063056056636), ('human', 1.0000630435352689), ('source side', 1.000063041706539), ('final classifier', 1.000063025184096), ('high dimension', 1.000063018231068), ('biological neuron', 1.000062989818242), ('achieve', 1.0000629784614468), ('higher level representation', 1.0000629756785346), ('imitation learning', 1.0000629693601926), ('handwriting synthesis', 1.0000629352789667), ('small data sets', 1.0000629267203005), ('synchronization protocol', 1.0000629230955043), ('application areas', 1.0000629197914783), ('optimisation theory', 1.000062918103232), ('pattern', 1.0000629148463787), ('specification', 1.0000629143555888), ('image translation', 1.0000629109732342), ('theoretical guarantees', 1.0000628732496113), ('summarize existing', 1.0000628578210455), ('approach deploys', 1.0000628548966988), ('variable length sequences', 1.0000628395917914), ('grounded language', 1.000062838562064), ('minimize model', 1.0000628215459897), ('sequential control', 1.000062817011922), ('visual text composition', 1.0000628026017175), ('solve problems', 1.0000627968310936), ('physics based', 1.0000627959724704), ('learning inverse', 1.000062785445824), ('recognition unit', 1.0000627799271393), ('powerful decoders', 1.0000627729318763), ('target learning', 1.000062772391225), ('good dataset', 1.000062753514719), ('deep auto', 1.0000627385767724), ('deep latent gaussian', 1.0000627383810565), ('models based', 1.0000627109084856), ('multilingual speech', 1.0000626818534981), ('exploit knowledge', 1.0000626800712697), ('multivariate polynomials', 1.0000626618529682), ('semantic composition', 1.000062647214179), ('semantic manifold based', 1.0000626405819841), ('general applications', 1.0000626191688782), ('representation schemes', 1.0000626053222197), ('raw speech', 1.0000625886042684), ('heuristic hand crafted', 1.0000625833805243), ('input distributions', 1.0000625637128966), ('gaussian mixtures', 1.000062525916315), ('images aligned', 1.0000625231061522), ('multiple signal representations', 1.0000625170099355), ('memory capability', 1.0000625149805862), ('target labels', 1.0000625108996453), ('different hyperparameter choices', 1.000062490224751), ('spatial convolution', 1.000062487848657), ('following scenarios', 1.0000624682523835), ('communicate error', 1.0000624604787376), ('line learning', 1.0000624482001848), ('basic structures', 1.000062437916193), ('logistic sigmoid activations', 1.0000624371149571), ('multimodal data', 1.0000624250526746), ('lower bounds defined', 1.0000624171754893), ('generative encoder decoder', 1.0000623856645494), ('2x reduction', 1.0000623715971872), ('classification function', 1.0000623628931518), ('video sharing', 1.000062334761309), ('address sparsity', 1.0000623166894673), ('embedding learned', 1.0000623150882486), ('unseen environments', 1.0000623042088068), ('noise corrupted', 1.0000622788695344), ('fundamental problem', 1.0000622763074247), ('approach generates', 1.000062267231272), ('structured representations', 1.0000622576180231), ('image cluster', 1.0000622505056391), ('educational platforms', 1.0000622431963742), ('convolution', 1.0000622394285545), ('learning operations', 1.0000622367558045), ('token labels', 1.0000621913762127), ('parametric speech synthesis', 1.0000621874290567), ('several text', 1.0000621805466718), ('parameter convergence', 1.000062178884179), ('common subspace', 1.0000621773310665), ('representing tags', 1.0000621756296737), ('larger network sizes', 1.0000621687879256), ('grid data', 1.0000620982903112), ('probabilistic pooling', 1.000062062919162), ('unsupervised motion', 1.0000620435687213), ('data clustering', 1.000062042525646), ('prediction', 1.0000620332972512), ('enhancements', 1.0000620322772054), ('object classification', 1.000061980706317), ('eda framework', 1.0000619760102043), ('low rank factorizations', 1.0000619741201227), ('previous conversion methods', 1.0000619690209986), ('logarithmic time', 1.0000619684592857), ('better embedding', 1.0000619680121283), ('probabilistic', 1.0000619546119318), ('clinical information extraction', 1.000061954375778), ('object tracking', 1.0000619380528963), ('discrete action spaces', 1.0000619281583998), ('new vertices', 1.0000619238649395), ('stochastic sampling', 1.0000619222617724), ('features calculated', 1.0000619221516611), ('large corpus', 1.0000618977379792), ('many tasks thanks', 1.000061884027552), ('new source', 1.000061870997496), ('learning driven', 1.0000618463537603), ('more data', 1.000061816447729), ('softmax layer', 1.000061804791636), ('similar tasks', 1.0000618016947407), ('attention', 1.0000617991524818), ('adversarial generation', 1.0000617908281513), ('graphical structure', 1.0000617661702422), ('programming languages', 1.00006173908057), ('10k dialogs', 1.0000617145427046), ('enormous simulations', 1.0000617073434137), ('easier images', 1.0000617066388178), ('outputs given', 1.0000617059150332), ('associated apis', 1.0000616915496614), ('implement', 1.0000616767278843), ('network pruning', 1.0000616587414175), ('generating sentences', 1.000061647054554), ('supervised training', 1.000061645803327), ('level interaction', 1.0000616409415561), ('models achieve', 1.0000616215366522), ('classify objects', 1.0000616194675254), ('tighter rank approximation', 1.0000616188182707), ('current dialog', 1.0000615970431064), ('hard code', 1.0000615733548608), ('tutorial', 1.0000615640719601), ('result', 1.0000615616390303), ('novel network', 1.0000615197980043), ('epsilon greedy', 1.000061516215334), ('cross method', 1.0000615145765932), ('general architecture', 1.0000614929908025), ('sentiment compression', 1.0000614822496117), ('remedied datasets', 1.0000614640119025), ('model defines', 1.0000614494957092), ('relation extraction', 1.0000614485892265), ('move prediction', 1.0000614459551322), ('drug discovery', 1.0000614413569906), ('higher order', 1.0000614408009716), ('output vector', 1.0000614381335098), ('used features', 1.0000614324392318), ('principal components', 1.0000614304283784), ('high probability', 1.000061422761762), ('gaussian process models', 1.0000614110921775), ('standard hmm', 1.000061397409849), ('error propagation', 1.0000613966359098), ('matching', 1.0000613898131538), ('stochastic loss selection', 1.0000613833428666), ('annotations', 1.0000613784802268), ('null outputs', 1.0000613470685977), ('combinatorial item', 1.0000613306145463), ('producing segmentations', 1.0000613281956365), ('clustering using', 1.0000613211740763), ('heterogeneous text', 1.0000613140525676), ('label noise', 1.0000612984984787), ('microblog services', 1.000061290783731), ('additional feature', 1.0000612843700667), ('accomplish tasks', 1.000061274256284), ('language text', 1.0000612713143808), ('neural dynamics', 1.0000612700733775), ('iterations', 1.000061259525086), ('different networks display', 1.0000612479519269), ('new environments', 1.000061223530529), ('sequential sentence classification', 1.0000612202695414), ('desired subset', 1.000061212724312), ('hard parameter', 1.0000611962781871), ('generate reviews', 1.0000611908845305), ('word matching', 1.000061182288471), ('many machine', 1.000061180218549), ('linear support', 1.0000611785832154), ('new generative', 1.0000611723477784), ('deployed machine', 1.0000611719229213), ('identify features', 1.0000611669970467), ('languages character', 1.0000611481760895), ('structured approach', 1.000061144732356), ('observed training sequences', 1.0000611382099611), ('factoid questions', 1.0000611257540861), ('gaussian processes using', 1.0000611253738008), ('numerical vectors', 1.000061111728328), ('second confidence network', 1.000061110543751), ('memory blocks', 1.0000611093274827), ('multimodal', 1.0000611022092853), ('particular source', 1.0000610952712214), ('final networks', 1.0000610815399418), ('building data', 1.0000610808305288), ('spatial role labeling', 1.0000610667336123), ('segmentation', 1.0000610589069245), ('online multi', 1.000061014522673), ('greedy methodology', 1.000061008200746), ('traditional models', 1.0000610077609347), ('baseline version', 1.000060996258272), ('end gradient', 1.0000609939580474), ('generated sentences', 1.0000609205008968), ('online viewer comments', 1.0000609162053047), ('novel autoencoder', 1.0000609147890873), ('emergent property', 1.0000609099744675), ('network technique', 1.000060905495171), ('several basic', 1.0000609023251665), ('framework outperforms', 1.000060897948178), ('joint distribution', 1.0000608977401109), ('sequence sorting', 1.0000608972426508), ('detect patterns', 1.0000608811441096), ('common sense knowledge', 1.0000608435079015), ('maximum likelihood training', 1.000060842945503), ('incorporate constraints', 1.0000608389756618), ('various settings', 1.0000608315676762), ('traffic scene', 1.0000608273501421), ('rapid development', 1.0000608256582755), ('perceptual inference tasks', 1.0000608240204545), ('raw sensor input', 1.0000608201872698), ('sparse layers', 1.0000608098396926), ('shortest path', 1.00006080576973), ('current scheduling techniques', 1.0000607924182823), ('rnn conditioning', 1.0000607879599401), ('aligned image', 1.0000607828990036), ('adversarial examples found', 1.0000607752258155), ('real time speech', 1.0000607699785076), ('complicated queries', 1.0000607665562293), ('high speed', 1.0000607479953507), ('sequence training', 1.0000607433206747), ('dual lasso', 1.0000607311965162), ('combinatorial structures', 1.0000607110332185), ('execution time', 1.0000606943909394), ('micro variables', 1.000060694175325), ('method provides', 1.0000606895775674), ('comparable performance', 1.0000606727248487), ('segmentation quality', 1.0000606339524116), ('learning run', 1.0000606304213417), ('classifier level', 1.0000606279498965), ('classifier architecture', 1.0000606079100964), ('context translation', 1.0000605892025454), ('audio synthesis model', 1.000060586788671), ('speech systems', 1.000060565954599), ('soft attention', 1.0000605584396967), ('use shared', 1.0000605583421343), ('full gradient', 1.000060530973296), ('small footprint', 1.000060526436831), ('basic utility', 1.0000605129507392), ('small amount', 1.0000605100099424), ('users fashion', 1.0000604664102657), ('huge training data', 1.000060464269019), ('common world knowledge', 1.000060452148865), ('model allows', 1.0000604470232624), ('temporal dependencies', 1.0000604458332523), ('bootstrap', 1.0000604349333653), ('cluttered environments', 1.000060427825594), ('direct policy search', 1.0000604259828583), ('alzheimer s', 1.0000604242304172), ('discrete latent', 1.0000604182113857), ('learn enhanced', 1.0000603788566629), ('memory cell', 1.0000603771437537), ('document compose', 1.0000603768905114), ('signal analysis', 1.0000603750349697), ('abstractive summarization', 1.0000603265264334), ('learning approaches', 1.000060322967478), ('compression technique', 1.000060312620659), ('decoder paths', 1.0000602955710114), ('event detection', 1.0000602912406908), ('similar images', 1.0000602570472468), ('combinatorial games arising', 1.0000602395077083), ('many natural', 1.000060200979629), ('large storage sizes', 1.0000601989122815), ('learning process', 1.0000601821124124), ('transfer function', 1.0000601640942446), ('processing time', 1.0000601610445388), ('timestep', 1.000060153857735), ('camera inputs', 1.0000601442836863), ('randomization steps', 1.0000601438151993), ('relation network', 1.0000601402204643), ('novel quantization scheme', 1.0000601348742684), ('different attributes', 1.0000601089711525), ('output symbols', 1.0000601031306273), ('keras', 1.000060093909948), ('individual source', 1.00006009252589), ('graphical', 1.0000600734940763), ('model improves', 1.000060056022072), ('implementation', 1.0000600332807115), ('additional integer', 1.0000600280263698), ('new regularization', 1.0000600250563758), ('transform inputs', 1.000060023456073), ('general method', 1.0000600018498174), ('new architecture', 1.0000599685440252), ('suboptimal solutions', 1.0000599571865973), ('specific reasoning', 1.0000599514917938), ('compatible function approximation', 1.000059930650296), ('context results', 1.0000599286025171), ('first person', 1.0000599126279963), ('rendering mixture model', 1.0000599121497284), ('simpler network', 1.0000599118522056), ('proposed keyword', 1.000059905769534), ('semantic boundaries', 1.0000598833722796), ('annotation', 1.0000598398065328), ('simple latent distributions', 1.0000598369348195), ('simple sequential', 1.000059832750429), ('learning task', 1.0000598114536894), ('achieve state', 1.0000598029716263), ('analyzing sentiment', 1.0000597934825821), ('simple language', 1.0000597582979798), ('reasoning using', 1.0000597577850991), ('data transformations', 1.0000597558663251), ('probabilistic selection', 1.0000597485569127), ('different evaluation methods', 1.0000597446220705), ('2d', 1.000059717816134), ('test image', 1.000059711767435), ('simple detection', 1.0000597049628503), ('multiplicative update', 1.0000596844610716), ('convolutional spike', 1.0000596778073367), ('external annotations', 1.0000596762223841), ('bounds defined', 1.0000596731355058), ('test images', 1.0000596567809374), ('extend', 1.0000596302237221), ('biometric', 1.0000596134720043), ('random decision', 1.000059609806457), ('different layers', 1.000059608939571), ('pre trained word', 1.0000596057138706), ('biological neurons', 1.0000595980934368), ('further improvements', 1.0000595882803693), ('video generation', 1.0000595748307592), ('multi world approach', 1.000059569904511), ('typical task', 1.0000595620640869), ('layers using', 1.0000595619999588), ('different sequence modeling', 1.0000595502697744), ('linear', 1.0000595284999434), ('different discourse corpora', 1.0000594837569619), ('general problem', 1.0000594776862006), ('such models using', 1.0000594638553248), ('molecular graph regression', 1.0000594632418995), ('discriminative word', 1.000059457972308), ('programs', 1.000059453944243), ('pattern search', 1.000059445571475), ('networks employs', 1.0000594378421224), ('unseen scenarios e', 1.0000594350891248), ('error', 1.000059428178162), ('real world pattern', 1.0000594136419905), ('suboptimal performance', 1.0000594013102526), ('spike decoding', 1.0000593887801839), ('forward matrices', 1.000059384981), ('inputs', 1.0000593720510413), ('autonomous systems', 1.0000593665547979), ('compositional queries', 1.0000593595173815), ('technique outperforms', 1.0000593584981607), ('benchmarking environment', 1.000059312030444), ('efficient training', 1.0000592888680064), ('communicate scalars', 1.0000592713482785), ('explicit models', 1.0000592445297802), ('latent codes', 1.0000592377379582), ('model generates', 1.0000592275207985), ('such', 1.000059220195208), ('representative applications', 1.0000592065595828), ('convergence accuracy', 1.0000591812340671), ('single object', 1.0000591777957917), ('semantic coherence using', 1.0000591771963538), ('variational auto', 1.0000591703839954), ('large', 1.0000591556912928), ('efficient structures', 1.0000591398829115), ('input distribution', 1.000059112454678), ('segmentations produced', 1.0000590954520086), ('discrete latent variable', 1.000059093722787), ('synthetic dataset', 1.0000590840903796), ('algorithmic information theory', 1.0000590839372256), ('like comparisons', 1.0000590735232953), ('arbitrary cnn architectures', 1.0000590715494997), ('models learn', 1.0000590709433792), ('robot', 1.0000590688533852), ('training learning', 1.0000590620083551), ('visual storytelling', 1.0000590520672428), ('evolutionary deep', 1.0000589883130864), ('composable modules', 1.0000589777120485), ('neuroimaging data acquired', 1.0000589578296675), ('extensions', 1.0000589516180776), ('smoothed analysis techniques', 1.0000589499596941), ('experimental comparison', 1.0000588963851178), ('extracting information', 1.0000588961886454), ('adding location', 1.0000588961208696), ('binary', 1.0000588753185107), ('learned models', 1.0000588687218288), ('search direction', 1.0000588581316774), ('consistency performance', 1.000058834789921), ('method named', 1.0000588343757513), ('contextual rnn language', 1.0000588141303484), ('generative modules', 1.0000588140195268), ('generator network', 1.000058780849494), ('methods using', 1.0000587730986463), ('such automated', 1.0000587659420237), ('natural', 1.00005875605705), ('regularization scheme', 1.00005874910489), ('unstructured twitter', 1.000058748706745), ('seed voxels', 1.0000587193329915), ('efficient encoding', 1.0000587171997775), ('neural response properties', 1.000058716303513), ('orthogonal regularization', 1.0000586938532843), ('test', 1.0000586776113265), ('multiple visual', 1.0000586669495544), ('early recognition', 1.0000586620137801), ('real world domains', 1.0000586615300469), ('notable improvements', 1.0000586130692621), ('performant networks', 1.0000585997429243), ('several data', 1.0000585930779777), ('discrete', 1.0000585778295399), ('cifar', 1.0000585686889198), ('technique called', 1.0000585667486241), ('limited number', 1.0000585572471925), ('multi label image', 1.000058550681317), ('multiple modules', 1.0000584978504856), ('information stored', 1.0000584839116353), ('work', 1.0000584757825701), ('key enabling', 1.000058472408391), ('cnn svm', 1.0000584673011486), ('various network', 1.000058463864312), ('plain net', 1.0000584601986555), ('genetic encoding scheme', 1.0000584533613952), ('word view', 1.0000584422074053), ('model free', 1.0000584370533527), ('contrast', 1.0000584302997542), ('previous tasks', 1.0000584218472994), ('future development', 1.0000584001597426), ('automatic captioning', 1.00005837600523), ('memory component', 1.0000583749451337), ('differentiable memory', 1.0000583671867895), ('class labels', 1.000058362187065), ('control network', 1.0000583575984157), ('majorization minimization', 1.0000583244500418), ('tag recommendation', 1.0000583238239864), ('semantics', 1.0000583108687757), ('image search', 1.0000583023526943), ('previous layers', 1.0000582992732738), ('constraint', 1.0000582980319865), ('complex behaviors', 1.000058216774367), ('large databases', 1.000058199935989), ('open information', 1.0000581861197457), ('matching results', 1.000058178944287), ('label propagation', 1.000058140648366), ('intermediate problems', 1.0000581390081562), ('disentangle input', 1.0000581345001387), ('experiments', 1.0000581238057822), ('belief network', 1.0000581168712506), ('solve lasso', 1.0000581111490867), ('legged robot', 1.0000580750103574), ('similar approaches', 1.0000580677391357), ('decoding space', 1.0000580606726994), ('microblogging service', 1.0000580575349813), ('character language', 1.0000580566775406), ('web corpora', 1.0000580497126423), ('result methods', 1.000058040187097), ('stochastic loss', 1.0000579891161194), ('interactive learning mechanism', 1.0000579815816413), ('generator networks', 1.0000579608046276), ('spike domain processing', 1.0000579509818257), ('typical ann models', 1.000057948696123), ('next layer', 1.000057927186597), ('gated memory', 1.0000579194091497), ('complex problems', 1.000057900843125), ('resource allocating', 1.0000579007285406), ('improvements', 1.0000578915825444), ('visual display', 1.000057888286729), ('adaptive learning', 1.0000578816297028), ('principal graphs', 1.0000578746126108), ('simple latent', 1.0000578659341435), ('distance measure', 1.0000578655811008), ('multiple solution', 1.0000578547187025), ('linear time getting', 1.0000578417476433), ('intermediate level targets', 1.0000578316110036), ('such data', 1.0000578273085106), ('online tool', 1.0000578010138468), ('discrete decision', 1.0000577894656337), ('novel unsupervised', 1.000057789063183), ('online learning', 1.000057774589381), ('temporal variables', 1.0000577610479846), ('data can', 1.0000577606013277), ('unsupervised setting', 1.000057752981091), ('previous transition based', 1.0000577514722704), ('weak supervision', 1.0000577411647285), ('proxy', 1.000057739710372), ('propose', 1.0000577164888191), ('action space', 1.0000576742213256), ('wheeled robot', 1.0000576710329003), ('computers', 1.0000576666282002), ('stored experience', 1.0000576540726878), ('neural network based', 1.0000576346187122), ('output feature', 1.0000576134531551), ('recent benchmark', 1.0000576058984325), ('standard domain adaptation', 1.0000575983188866), ('input dependent', 1.0000575924808217), ('model performs', 1.0000575756157095), ('vertices', 1.0000575640930582), ('continuous state', 1.0000575638734939), ('byte', 1.000057560288112), ('nonlinear formulation', 1.0000575373233433), ('approximating samples', 1.0000575305225528), ('system performance', 1.000057519113679), ('reasoning tasks', 1.0000575190254393), ('object signature', 1.0000575067023865), ('parameter memory', 1.000057497574769), ('nonlinear latent', 1.0000574966859854), ('semantic structures', 1.0000574940283335), ('generative architecture', 1.0000574812597085), ('constrained sentence generation', 1.0000574337492527), ('numerical', 1.0000574308884358), ('robust controller', 1.000057409645066), ('conventional rnns', 1.0000573989923398), ('word based', 1.0000573915682853), ('text representations', 1.0000573688695165), ('continuous online', 1.0000573672097222), ('similar cnn models', 1.0000573548675915), ('base features', 1.000057353916961), ('metrics correlate', 1.0000573513887816), ('weight normalization', 1.0000573462987956), ('tasks supervised', 1.000057344685841), ('complex data', 1.0000573230870167), ('structured objects', 1.000057299008652), ('multiple word', 1.0000572972154522), ('various relation learning', 1.0000572845726992), ('learn vector', 1.000057271044887), ('networks should', 1.0000572285592957), ('neural baseline systems', 1.0000572179628355), ('mixed cooperative', 1.0000572093111895), ('relevant text containing', 1.0000571876148887), ('variational gaussian', 1.0000571728143153), ('lstm modules', 1.000057154325565), ('skip gram', 1.0000571433695238), ('classic problem', 1.0000571319406502), ('training labels', 1.0000571262171714), ('nonlinear discriminators', 1.0000571177779858), ('gan models', 1.000057114827333), ('monitoring capabilities', 1.0000571038899846), ('model validation', 1.0000571004436654), ('output distributions', 1.0000570991879625), ('real', 1.0000570973956746), ('learning scenario', 1.0000570867601144), ('append', 1.0000570816508247), ('patient note', 1.0000570771824777), ('redesign', 1.0000570761462286), ('complex behaviors including', 1.0000570701791518), ('robust value', 1.0000570635944186), ('proposed mesh', 1.0000570408241458), ('compositional sub tree', 1.0000570366734451), ('connectivity constraints', 1.0000570291666668), ('key limitations', 1.0000570231160548), ('separation incremental', 1.0000570199250487), ('dropout', 1.0000570170246812), ('translation image', 1.0000570133380686), ('networks allow', 1.0000570048036448), ('datasets pedestrian', 1.0000569843168623), ('network component', 1.0000569829776893), ('linear networks', 1.0000569824450813), ('appropriate regularization', 1.0000569820394156), ('multi person', 1.0000569808827444), ('networks excel', 1.0000569798407533), ('many', 1.0000569575784821), ('domain data', 1.0000569573593194), ('perfect accuracy', 1.000056952125441), ('input variables', 1.0000569353224629), ('variational inference based', 1.0000569294057313), ('explanation method', 1.0000569292143293), ('such learning tasks', 1.0000568962937435), ('extract information', 1.000056876126832), ('compare', 1.0000568699684056), ('internal representation', 1.000056841288723), ('parallel text', 1.00005682121144), ('dependency trees', 1.000056808092283), ('key features', 1.0000567661760655), ('accuracy improvement', 1.0000567549787025), ('additional data', 1.0000567449453972), ('large amounts', 1.0000567406343048), ('intelligent agent', 1.0000567354872874), ('ensemble method', 1.0000567353656395), ('joint sentence classification', 1.0000567118561956), ('line method', 1.0000567032488608), ('art lstms', 1.000056692485529), ('many text generation', 1.0000566800328756), ('longer paths', 1.0000566718184853), ('large supervised', 1.0000566360330405), ('current learning approaches', 1.000056620828001), ('different approaches', 1.0000566074973403), ('biometric decision', 1.0000566046672958), ('long term dependencies', 1.0000565917260873), ('different classes', 1.0000565631333558), ('memory length', 1.0000565464352547), ('extract knowledge', 1.000056533382734), ('low rank', 1.0000565256903295), ('continuous time case', 1.000056518143527), ('reasonable dimension d', 1.0000564880594236), ('low resource speech', 1.000056486867273), ('traditional recurrent', 1.0000564791538105), ('multiple patterns', 1.0000564583964722), ('domains', 1.000056450229452), ('artificial', 1.0000564498313642), ('stochastic textures', 1.0000564490878905), ('discrete maze solving', 1.0000564326828163), ('specific applications', 1.0000564259732838), ('tweet embeddings', 1.0000564256350462), ('linear surrogate', 1.0000564241059704), ('aggregate information', 1.0000564206571567), ('map word', 1.0000564198148238), ('heuristic', 1.0000564164721528), ('synthesis tool', 1.000056363957949), ('pos tagging', 1.00005635879299), ('evolution strategies', 1.000056338012237), ('effective generative', 1.000056327958533), ('combinatorial', 1.0000563079207698), ('recent years machine', 1.000056297791464), ('language structure', 1.0000562951007985), ('prior program', 1.000056282589169), ('neuroevolution', 1.0000562807340305), ('heterogeneous documents', 1.000056268734625), ('train networks', 1.000056259133652), ('explore driven', 1.000056254819788), ('problems involves', 1.000056253231475), ('solving learning', 1.0000562341297299), ('continuous latent', 1.0000562313861252), ('proposed architecture', 1.0000562231516255), ('dataset show', 1.0000562173845735), ('hidden feature', 1.0000562124032952), ('deep relu', 1.000056212010544), ('memory policy', 1.000056210917855), ('implicit', 1.0000561965137444), ('create', 1.0000561448061638), ('model selection', 1.0000561398009122), ('accuracy highlighting', 1.000056130120907), ('data utilized', 1.0000561247750406), ('adversarial sample creation', 1.0000561206490646), ('adversarial manipulation', 1.0000561185745525), ('quantify generalization', 1.0000561055525328), ('art results', 1.0000561015506055), ('human evaluation metrics', 1.0000560947206658), ('speaker vectors', 1.0000560837904957), ('feature extractor', 1.0000560823937992), ('black box manner', 1.0000560800254075), ('expert go', 1.00005605917211), ('reward functions', 1.0000560503590346), ('signal processing', 1.0000560285736133), ('benchmarks including', 1.0000560277513253), ('hybrid nn', 1.000056024799842), ('super convergence', 1.000056021614515), ('extract edges', 1.000056021117531), ('different classifiers show', 1.0000560014991091), ('layers required', 1.0000559720506268), ('more input', 1.0000559717376472), ('general video', 1.0000559649471417), ('larger network', 1.0000559625966314), ('accuracy complexity', 1.0000559585724664), ('network differs', 1.0000559520884749), ('weight vectors', 1.0000559413864256), ('network components', 1.0000559408663654), ('feature importance', 1.0000559302497152), ('different parameter settings', 1.0000558985617904), ('sub word', 1.0000558619661362), ('learning rl', 1.000055859280938), ('new stochastic', 1.0000558584676091), ('noise robust', 1.0000558299445852), ('multilayered networks', 1.0000558237590789), ('conventional backpropagation', 1.0000558113746303), ('other information', 1.000055795278857), ('future feature frames', 1.0000557867695954), ('find patterns', 1.0000557818887812), ('unseen scenarios', 1.0000557668315146), ('recognize object', 1.0000557628184814), ('document e', 1.0000557576250173), ('acoustic model', 1.0000557551416256), ('structured learning', 1.0000557467963562), ('network sentence', 1.000055745540943), ('harder image', 1.0000557442424003), ('efficient handling', 1.0000557387282807), ('advance', 1.000055728190308), ('face processing', 1.0000557255666962), ('better image', 1.0000556461193058), ('neural code', 1.000055585103305), ('compare gradient', 1.0000555704522762), ('successful applications', 1.0000555642669), ('modern ides', 1.0000555585888375), ('visual systems', 1.0000555534464375), ('semantic content', 1.0000555499269028), ('human language understanding', 1.000055541533569), ('action output', 1.0000555394377633), ('soft rnn', 1.0000555203631367), ('language dialog', 1.0000555160928646), ('distributional representations', 1.0000555030987277), ('labelled training', 1.0000554926941867), ('discrete action types', 1.000055478942859), ('conditional language', 1.000055471173549), ('memory based', 1.0000554638461296), ('visual content', 1.0000554637459789), ('methods generalizing', 1.0000554572579141), ('single label classification', 1.0000554431500113), ('accelerated performance', 1.0000554253189817), ('shallow pattern matching', 1.0000554244394304), ('small number', 1.0000554057335616), ('input parameters', 1.0000554029632027), ('novel spatial', 1.0000553882443728), ('adversarial autoencoders', 1.0000553776249155), ('network support', 1.0000553686446758), ('continuous control', 1.0000553664042608), ('word co', 1.0000553640396919), ('classifying mnist', 1.0000553548146698), ('dialogue applications', 1.0000553512357293), ('systematic design', 1.0000553442092233), ('boolean functions', 1.0000553390186746), ('types assigned', 1.0000553375359134), ('play go', 1.0000553113806538), ('problems considered', 1.0000552800183784), ('common problem', 1.0000552755045622), ('graphs', 1.0000552704086878), ('original data space', 1.0000552638579117), ('individual data points', 1.0000552593723442), ('video prediction', 1.0000552545229344), ('learn features', 1.000055245503384), ('predictive performance', 1.0000552260671884), ('models require', 1.0000552235238063), ('data referred', 1.0000552045809625), ('clean object', 1.0000552029353718), ('real time manner', 1.0000552021128175), ('explicit model', 1.0000551953054462), ('systems', 1.0000551863093776), ('discrete structures', 1.0000551231997445), ('fixed number', 1.0000551186410052), ('probabilistic observation', 1.0000550950256515), ('compositional model', 1.000055084925978), ('various tweet categorization', 1.0000550778350574), ('particular discrete', 1.0000550481703778), ('word distribution', 1.000055034534683), ('cv benchmark', 1.000055034529109), ('bayesian framework', 1.000055033726296), ('ubiquity', 1.000055021475544), ('method combining', 1.0000550055091793), ('heuristic hand', 1.0000549958818508), ('average case memory', 1.0000549491829538), ('perform tasks', 1.0000549342862197), ('online representation', 1.000054927972328), ('task space', 1.0000548968061895), ('asr systems', 1.0000548930177175), ('semantic coherence', 1.0000548868509684), ('human similarity judgments', 1.000054862888651), ('multi target dnn', 1.0000548482452936), ('particular tasks', 1.0000548462301488), ('realistic flexible', 1.0000548350220841), ('universal image', 1.0000548171985875), ('raw motion capture', 1.0000548142771897), ('text associated', 1.0000548121525465), ('other data', 1.0000548098610669), ('conventional sub word', 1.000054750701395), ('compositional rnn', 1.0000547170603065), ('task completion', 1.0000547132401447), ('tag representations', 1.0000547113075282), ('speech engineering', 1.0000547071022865), ('train embeddings', 1.0000547000901843), ('reduce', 1.000054695329757), ('crowdsourced', 1.00005469250325), ('method based', 1.0000546708622597), ('audio synthesis', 1.0000546539122825), ('learning showing', 1.0000546431477497), ('main machine', 1.0000546410280255), ('answering questions', 1.0000546385875912), ('human level', 1.0000546347385637), ('hybrid architecture', 1.0000546321125343), ('systems rely', 1.000054614143812), ('detect', 1.0000545841779176), ('bio imaging', 1.0000545813881037), ('deep cnn', 1.000054576775236), ('basic building block', 1.0000545656940796), ('benchmark genomics challenges', 1.0000545636666456), ('decoding enables', 1.0000545620919317), ('example applying', 1.0000545396248492), ('symmetric skip connection', 1.0000545346355438), ('fixed points', 1.0000545162900654), ('relevant text', 1.0000544969992988), ('tasks domains', 1.0000544794297506), ('complex segmentation', 1.0000544767103552), ('synthetic images', 1.0000544637036664), ('medical diagnosis', 1.000054463677643), ('general public', 1.000054455251199), ('utilize error', 1.00005445088587), ('parameter settings', 1.0000544498298691), ('recent image', 1.0000544179237842), ('autonomous navigation', 1.00005440275731), ('unstructured', 1.000054388350995), ('art reinforcement', 1.0000543813952467), ('benchmark performance', 1.000054354631497), ('experimental evaluation', 1.0000543511399995), ('unlabeled observations', 1.0000543253527245), ('standard inference techniques', 1.000054313589462), ('verification', 1.000054278904299), ('sequential mapping', 1.0000542660493938), ('traditional autoencoder', 1.000054240094349), ('available corpora', 1.0000542348652146), ('ground truth', 1.000054222064163), ('long sequences', 1.0000542158959838), ('synthetic datasets', 1.0000541918812078), ('dependency based', 1.0000541742616536), ('error condition', 1.0000541615704284), ('additional explicit', 1.0000541300012595), ('semantic nature', 1.0000541256081523), ('make use', 1.0000541191150734), ('proxy reward', 1.0000541157865939), ('smaller networks', 1.000054101171639), ('large dialogue corpora', 1.0000540874495847), ('perception tasks', 1.0000540768593487), ('conditional version', 1.0000540735879493), ('multiple related domains', 1.000054062285782), ('benchmark data', 1.0000540571207974), ('full network', 1.0000540414440304), ('better modeling performance', 1.000054032452579), ('preliminary dataset', 1.00005401713645), ('full datasets', 1.000054013769648), ('interesting applications', 1.000053999588218), ('information gain', 1.0000539829843544), ('blind application', 1.0000539667972004), ('entries can', 1.0000539591707627), ('single dnn', 1.000053941834405), ('method described', 1.0000539351832012), ('simple transformations', 1.0000539244906455), ('competitive generalization', 1.0000539007644638), ('different classifiers', 1.0000538972540323), ('training asr', 1.0000538961271919), ('weak domain knowledge', 1.0000538941286883), ('representations', 1.000053891501083), ('entity type', 1.0000538876570033), ('small scale tasks', 1.000053883801239), ('particular learning task', 1.000053870220725), ('particular feature selection', 1.000053865552095), ('model enables', 1.0000538504481433), ('minimize errors', 1.0000538496953986), ('stochastic optimization', 1.0000538222124946), ('high quality data', 1.0000538189102441), ('norm constrained', 1.0000538158598355), ('simulations', 1.0000538117822044), ('computational expense', 1.0000537741263407), ('visual reasoning answering', 1.000053769733337), ('standard machine', 1.0000537666527305), ('interesting problem', 1.0000537543370283), ('end method', 1.000053749517447), ('practical scenarios', 1.0000537388624637), ('similar performance', 1.0000537340280735), ('other domains', 1.0000537336828756), ('collaborative image', 1.000053731022608), ('unary position', 1.0000537301588988), ('shift estimation', 1.0000537288688889), ('primitive actions', 1.000053717363929), ('network increases', 1.000053708491742), ('prior information', 1.000053698213062), ('abstract representation', 1.0000536726830893), ('forward pass', 1.000053665833261), ('token', 1.0000536606632486), ('accessibility', 1.0000536508004274), ('target domain', 1.0000536486735376), ('syntactical', 1.0000536453734468), ('recurrent attention', 1.0000535810489883), ('generate predictions', 1.0000535665928816), ('random weights', 1.0000535652285343), ('fundamental machine', 1.0000535281911667), ('word deleting', 1.0000535151899965), ('continuous learning', 1.0000535127685806), ('candidate dependency', 1.0000535050363037), ('multilayer', 1.0000534899817324), ('tighter approximation', 1.0000534873407914), ('different levels', 1.0000534841796536), ('networks remains', 1.000053472347026), ('competitive scenarios', 1.0000534601585123), ('layers', 1.0000534531714758), ('inverse problems', 1.0000534448767586), ('end machine', 1.0000534307024567), ('mapping make', 1.0000534300929327), ('hyperparameter choices', 1.0000534274446482), ('different training methods', 1.0000534030912924), ('features make', 1.000053390738463), ('multi world', 1.0000533729344387), ('real time classification', 1.0000533281030672), ('problems demonstrate', 1.0000532981998644), ('simplify sentences', 1.0000532857874946), ('mnist dataset show', 1.0000532770348554), ('segment objects', 1.0000532769959594), ('sequential training', 1.0000532745122552), ('low resolution', 1.000053262525156), ('multiple layer', 1.0000532569121694), ('multiplicative backpropagation', 1.000053250835031), ('linear time', 1.000053240404894), ('attention networks', 1.000053238488094), ('multi stream', 1.0000532264512978), ('noisy speech', 1.0000532241521833), ('vqa models', 1.0000532220992842), ('english translation task', 1.0000532210920767), ('human face', 1.000053214804969), ('feature extractors', 1.0000532095860237), ('3d rotations translations', 1.0000531873953278), ('shortest dependency', 1.0000531803690131), ('improve convergence', 1.0000531669967019), ('additional regularization', 1.00005316316482), ('represent data', 1.0000531630420917), ('learning makes', 1.0000531610564873), ('augmented lagrange', 1.0000531498842993), ('original problem', 1.0000531476606103), ('represent text', 1.0000531454867831), ('specific problem', 1.0000531348652681), ('segmentation techniques', 1.0000531318795045), ('virtual reference', 1.000053131422935), ('explicit model adaptation', 1.000053123055085), ('memorization capability', 1.0000531201566463), ('novel quantization', 1.0000531072780678), ('nmf', 1.0000530738263156), ('challenging subspace', 1.0000530722431424), ('underlying recognition', 1.0000530695989076), ('benchmark analogy', 1.0000530687873934), ('network designed', 1.0000530521885767), ('real world settings', 1.0000530512399308), ('many perception tasks', 1.0000530487232637), ('covariance functions', 1.0000530318646816), ('mapping', 1.0000530061480968), ('real world machine', 1.0000529912213496), ('annotation rules', 1.0000529808803826), ('black box machine', 1.0000529799916615), ('information represented', 1.0000529717412134), ('deterministic estimate', 1.000052967207608), ('holy grail solution', 1.000052963373055), ('method performed', 1.0000529628463855), ('exact learning', 1.0000529625939143), ('associated optimisation', 1.0000529565480425), ('alignment based', 1.00005293892492), ('machine responses', 1.0000529353475636), ('general open', 1.0000529350859337), ('weight matrix', 1.0000529274857484), ('images bypasses', 1.0000529244765017), ('appealing features', 1.0000529231685942), ('general classifiers', 1.0000528993989708), ('residual network', 1.0000528927614014), ('results translate', 1.000052890489782), ('visual understanding', 1.0000528827797885), ('embedding space', 1.0000528762113077), ('wall street', 1.0000528655295315), ('apply batch', 1.0000528620848734), ('method proves', 1.000052857806142), ('labeled examples', 1.0000528505931725), ('implicit estimation', 1.0000528462350862), ('pre training approach', 1.0000528443151993), ('various baselines', 1.0000528440968273), ('make data', 1.0000528247826541), ('few shot regression', 1.0000528058698381), ('view', 1.0000527952431415), ('network contributes', 1.0000527851497993), ('environments', 1.0000527739595129), ('encoder decoders', 1.0000527546941436), ('high complexity', 1.0000527281897142), ('instance', 1.0000527109562143), ('network decisions', 1.0000527106952766), ('simple setup', 1.000052703997946), ('data processing', 1.000052693605528), ('directional wavelet domain', 1.0000526549201043), ('symmetric skip', 1.0000526543769654), ('explicit collection', 1.0000526450243503), ('patient phenotyping', 1.000052626220781), ('continuous approximation', 1.000052623503616), ('generalization bounds', 1.000052618801258), ('regression problem', 1.0000526163558265), ('minimization', 1.0000526029719712), ('multiple restarts', 1.0000525981374138), ('open response', 1.0000525856457514), ('fuzzy particle', 1.0000525846988302), ('tokens', 1.0000525745515911), ('generate answers', 1.0000525448500823), ('logistic sigmoid', 1.0000525392343897), ('item content', 1.000052538993993), ('descent', 1.0000525278125993), ('hard attention', 1.000052518191119), ('online viewer', 1.0000525155471427), ('geometric framework', 1.0000525119923889), ('security trust', 1.0000525092292145), ('successful matching', 1.0000524935789044), ('models perform', 1.000052491265154), ('different environments', 1.0000524850635928), ('words representation', 1.0000524490013045), ('copy mechanism', 1.0000524456313418), ('neuroimaging data', 1.0000524325608857), ('propose tasks', 1.0000524270312303), ('gradients', 1.0000524253434555), ('unlabeled', 1.0000524064105842), ('basic units', 1.00005240351476), ('translation using', 1.000052391660176), ('scenarios', 1.0000523885667958), ('interior point', 1.0000523850858178), ('captioning tagging', 1.0000523614278969), ('probabilistic spiking', 1.000052350837099), ('database', 1.0000523497224656), ('arbitrary length', 1.000052343489509), ('suitable representations', 1.0000523310510765), ('multiclass', 1.0000523280794618), ('feedforward parser', 1.0000523197974938), ('other objectives', 1.0000522821268647), ('segmentations resulting', 1.0000522622625239), ('visual reasoning tasks', 1.000052257135716), ('third degree markov', 1.0000522533146343), ('information can', 1.0000522521111261), ('lasso type penalty', 1.0000522501708453), ('visual sentiment', 1.0000522470721362), ('several classifiers', 1.0000522465895736), ('generate target', 1.0000522441918573), ('small perturbation norms', 1.0000522395653388), ('learning leveraging', 1.000052226475648), ('activation maximization', 1.0000522183214138), ('layer specific', 1.0000522179568592), ('simulated tasks', 1.000052211251399), ('visual information', 1.0000522102867027), ('best networks', 1.0000522069945588), ('baseline methods', 1.0000521957498043), ('class', 1.0000521930704058), ('new setting', 1.000052188312177), ('linear system dynamics', 1.0000521832415818), ('approximate', 1.000052158069882), ('other approaches', 1.0000521461554202), ('network assembly', 1.0000521438099523), ('sort', 1.0000521277936292), ('complex environments', 1.000052124884134), ('traditional search', 1.0000521227431336), ('random location', 1.0000521196725127), ('regularizer', 1.0000521184864986), ('heuristics', 1.0000521161796556), ('similarity', 1.0000521045238397), ('classification decisions', 1.0000520956729757), ('enabling sharing', 1.0000520914019324), ('terms', 1.0000520746509693), ('domain rendered', 1.0000520644057889), ('real system', 1.0000520622050793), ('source learning', 1.0000520577722198), ('syntactic', 1.0000520559414292), ('efficient architecture', 1.000052055023543), ('semantically appropriate', 1.0000520546056855), ('widespread deployment', 1.0000520346038677), ('continuous latent variables', 1.0000520286425287), ('other machine', 1.0000520208106434), ('attention layer', 1.0000520110730595), ('speech system', 1.0000520090049163), ('information carried', 1.00005198509052), ('image representations', 1.0000519813444664), ('real life setting', 1.0000519706230195), ('central hidden layer', 1.0000519589976846), ('set languages', 1.0000519364801064), ('deterministic policy', 1.0000519270209636), ('learnable parameters', 1.0000519251358078), ('vision based', 1.0000519233087855), ('machines require', 1.0000519225719435), ('goal', 1.0000519146223468), ('popular approach', 1.000051911068012), ('single layer', 1.0000518838271106), ('training points', 1.0000518784262362), ('joint probability models', 1.0000518537127803), ('discrete action', 1.0000518518371195), ('shared response', 1.0000518511819914), ('generative control', 1.0000518440455146), ('using information', 1.0000518376902547), ('generate corresponding', 1.0000518326928811), ('perfect reconstruction', 1.0000518294968435), ('style transfer', 1.000051822245857), ('best practices', 1.000051810325434), ('weights connecting', 1.000051809896585), ('dynamic integration', 1.0000518076110823), ('data coming', 1.0000517968571048), ('learning transition', 1.0000517714338073), ('connectivity information', 1.0000517706024337), ('complicated domains', 1.0000517655789052), ('german translation task', 1.0000517655090635), ('simpler instances', 1.0000517543455412), ('disjoint latent', 1.0000517365499846), ('previous learning', 1.0000517194456608), ('ordinal regression', 1.000051693513005), ('different source', 1.0000516858861748), ('binary subset', 1.0000516858587873), ('rewards sampled', 1.0000516845718308), ('academic reinforcement', 1.0000516681720972), ('performance prediction', 1.0000516497170757), ('asr system', 1.0000516481534696), ('multi hop', 1.000051645377792), ('single directions', 1.000051640630869), ('bit', 1.0000516275528855), ('many task', 1.0000515960932266), ('sparse view ct', 1.0000515489768382), ('previous methods', 1.0000515474062583), ('network design', 1.000051545900225), ('total', 1.0000515447992195), ('particular data', 1.0000515371919696), ('semantically meaningful', 1.0000515292772199), ('matching process', 1.000051515726957), ('core model', 1.0000515099408172), ('hebbian plasticity', 1.0000515013704239), ('semantic experiences', 1.0000514797636761), ('visualizing explaining', 1.0000514698093415), ('residual learning approach', 1.000051461531413), ('efficient large', 1.0000514361090995), ('optimal', 1.000051428064242), ('suboptimal points', 1.0000514261935942), ('larger data', 1.0000513984774622), ('space', 1.000051387257381), ('long range dependency', 1.0000513678472904), ('decoder', 1.0000513595676688), ('deep transition functions', 1.0000513553441868), ('empirical efficiency calculations', 1.0000513546285474), ('infer facts', 1.0000513535738609), ('interpret dependencies', 1.000051336620117), ('model classes', 1.0000513082683231), ('predicates', 1.0000513036218042), ('human evaluators', 1.0000513008297358), ('learn models', 1.0000512730436373), ('dense vector representations', 1.0000512651649192), ('key requirement', 1.000051261575643), ('cascading prediction', 1.0000512588448636), ('hochreiter', 1.000051240445423), ('logistic loss', 1.000051236507132), ('natural data', 1.0000512290735464), ('visual context', 1.0000512257124907), ('parametric model', 1.0000512190448374), ('richer set', 1.0000512162389865), ('successful policy optimisation', 1.0000511987925713), ('sample points', 1.0000511877507308), ('super resolution', 1.0000511743279445), ('conversational telephone', 1.0000511705243724), ('puzzle using', 1.0000511704255513), ('hierarchical', 1.0000511657066236), ('class constraints', 1.0000511539758599), ('textual description', 1.0000511442020543), ('information gained', 1.0000511326351094), ('associative memory', 1.0000511240328416), ('conventional machine', 1.0000511170819086), ('visual writing', 1.0000511061104567), ('total performance', 1.0000510759621808), ('large scale analysis', 1.0000510701188294), ('models can', 1.0000510129978084), ('separating hyperplane', 1.000051012982668), ('recurrent regularization', 1.0000510074040527), ('control problem', 1.000051002221506), ('multimodal multilingual', 1.000050976020739), ('art systems', 1.0000509704356844), ('text domain', 1.0000509464879073), ('facilitate developing', 1.0000509424040525), ('submodular', 1.0000509400112174), ('rl methods', 1.000050936130726), ('adaptive sampling', 1.0000509130664106), ('timit', 1.000050912814079), ('mel log', 1.0000509114849376), ('regularizer pioneered', 1.0000509064839935), ('linear regression problem', 1.0000508910566397), ('detection', 1.000050889071889), ('help reinforcement', 1.0000508842446263), ('other words', 1.0000508767632954), ('target distribution', 1.0000508641180086), ('semeval', 1.0000508579305993), ('novel architecture', 1.0000508422064707), ('benchmark databases', 1.0000508164009796), ('dependency', 1.0000508139797815), ('difficult simulated', 1.0000508133824895), ('n tuples', 1.0000508039221312), ('networks alleviate', 1.0000508021292647), ('pipeline achieves', 1.000050801235922), ('perform document', 1.0000508009376572), ('sgd depends', 1.0000507851748124), ('analogical reasoning', 1.000050762842613), ('visualize attention', 1.0000507472339573), ('large learning', 1.0000507372405618), ('increase dependencies', 1.0000507262692213), ('solve sequence', 1.0000507092572972), ('comprehensive data', 1.0000507075885101), ('distribution matching', 1.0000507065432023), ('identify', 1.0000506913214005), ('structural annotations', 1.000050680324031), ('non gaussian', 1.0000506665860676), ('question generator', 1.0000506643628202), ('sparse view', 1.0000506503961597), ('abstract invariant', 1.0000506478253495), ('imaging', 1.0000506374520186), ('human qualia', 1.0000506327307717), ('scoring function', 1.000050632021846), ('translation pair', 1.0000506245666607), ('appropriate value approximations', 1.0000506222904155), ('variational inference method', 1.0000506081526572), ('content sequences', 1.00005059146091), ('approach outperforms', 1.0000505890415778), ('bidirectional lstm', 1.0000505715725578), ('clustering', 1.0000505639458064), ('acoustic features', 1.0000505381645426), ('dynamical models', 1.0000505214731703), ('fine attention layer', 1.000050501831745), ('inference using', 1.0000504923801), ('generalization', 1.0000504809559494), ('multi argument', 1.0000504795660314), ('texture', 1.0000504602562281), ('first dnn', 1.0000504595359407), ('data used', 1.00005044898992), ('collaborative human', 1.000050430706943), ('enabling models', 1.0000504199925349), ('resilient propagation', 1.0000504016848084), ('patterns', 1.0000504000679797), ('efficient techniques', 1.0000503944570396), ('level model', 1.0000503831277499), ('dimensionality', 1.0000503758996382), ('matching relations', 1.000050374089539), ('challenges involve', 1.000050372370106), ('video data', 1.0000503655200232), ('constrained', 1.0000503571281616), ('account task', 1.000050350778663), ('phrase representations', 1.0000503474848768), ('redundancy', 1.0000503435517758), ('generative decoder', 1.0000503401837093), ('relevant baselines', 1.0000503067342128), ('method using', 1.000050301829042), ('knowledge base question', 1.000050290049204), ('gated autoencoders', 1.0000502888976874), ('cnn features', 1.0000502596203689), ('generalized data', 1.0000502500921038), ('linear classification', 1.0000502472987065), ('mapping leads', 1.0000502190560425), ('weak labels', 1.000050218823766), ('gated units', 1.0000501942991462), ('arbitrary mapping', 1.0000501916339823), ('black box classifiers', 1.0000501793426821), ('many content words', 1.0000501706618348), ('images obtained', 1.0000501574854554), ('targeted robustness', 1.0000501555726893), ('forward pass cannot', 1.0000501474481456), ('peak performance', 1.0000501311495587), ('large data', 1.0000501280018699), ('sequence length', 1.000050108516143), ('chaos', 1.0000501073441996), ('frame stacking', 1.0000500850135683), ('rank approximation', 1.000050084631827), ('show regularized', 1.0000500750620027), ('facial landmark', 1.0000500685063767), ('implicit regularization', 1.0000500665071772), ('empirical evaluations', 1.0000500634068827), ('template', 1.0000500539771764), ('learned probability', 1.0000500376859522), ('progressive learning technique', 1.0000500288032574), ('final decoding', 1.0000500279184839), ('sentence matching', 1.0000500244737707), ('model performance', 1.0000500182811511), ('datasets covering', 1.0000500128819687), ('basic building', 1.000049993083723), ('temporal features', 1.0000499746175777), ('numerous real', 1.0000499687847118), ('approach features', 1.0000499541994121), ('open domain dialogue', 1.000049943697968), ('target features', 1.000049930394739), ('regret minimization', 1.0000499285889792), ('model design', 1.000049920311621), ('capturing similarity', 1.0000499092292225), ('decoding method', 1.0000498943242926), ('attributes', 1.0000498905553687), ('sequence trained', 1.0000498681597512), ('target function', 1.0000498667250899), ('better modeling', 1.0000498552111874), ('considered alignment', 1.0000498524532346), ('deep methods', 1.0000498435875405), ('functional gene ontology', 1.0000498284843806), ('problems include', 1.0000498248009149), ('execute', 1.000049822463081), ('tasks defined', 1.0000498201054133), ('unbiased features', 1.0000497843544534), ('approach achieves', 1.0000497504293842), ('popular machine', 1.000049738005812), ('close approximations', 1.0000497345549793), ('art accuracy', 1.0000497335409264), ('error specific', 1.0000497321029362), ('high quality candidate', 1.0000497303492815), ('different languages', 1.0000497281639456), ('manual annotation', 1.0000497245417592), ('new language', 1.0000497221635631), ('decoding beam', 1.0000497065405878), ('functional layers', 1.0000496978816265), ('class samples', 1.0000496952654423), ('method yields', 1.000049687742115), ('adversarial loss', 1.000049666732046), ('visual madlibs', 1.0000496508731784), ('various forms viewed', 1.0000496416484013), ('neural baseline', 1.0000496315191871), ('same document', 1.0000496195509687), ('first step', 1.0000496185383585), ('model initialization', 1.0000496019102008), ('evolving vector', 1.000049600249147), ('existing information', 1.0000495910043787), ('contrastive divergence cd', 1.00004957031074), ('simplified attention mechanism', 1.0000495565150223), ('generated samples', 1.0000495543653365), ('detailed analysis', 1.0000495514812922), ('minimal parameter tuning', 1.0000495355107957), ('recent methods', 1.0000495248974433), ('maps', 1.0000495220832037), ('learning control', 1.0000495189041427), ('hand crafting', 1.000049509466933), ('limited set', 1.0000494955333936), ('add', 1.0000494873300723), ('tracker', 1.0000494792214814), ('target answers', 1.0000494765690158), ('initialize', 1.0000494672034608), ('complex models', 1.0000494577800143), ('learning policies', 1.0000494575902223), ('imdb movie review', 1.0000494569505443), ('stochastic depth', 1.0000494473094068), ('raw signals alleviating', 1.000049441947645), ('datapoints', 1.0000494342080843), ('reasoning', 1.0000494250543348), ('real time smm', 1.0000494234719632), ('developing representations', 1.0000494216867655), ('unlabeled target', 1.0000494073655113), ('reasoning answering', 1.000049393887809), ('generate responses', 1.0000493870050347), ('structural target information', 1.0000493814048073), ('model interpretability', 1.0000493748435217), ('many task setting', 1.000049357318008), ('novel communication strategy', 1.0000493514989348), ('high performance', 1.000049346659282), ('other systems', 1.0000493339825909), ('cnns', 1.000049291981768), ('visual inspection', 1.0000492790876538), ('partition labels', 1.0000492505494514), ('underlying data', 1.0000492357839414), ('wordnet', 1.0000492321567496), ('learning opens', 1.0000492290549003), ('alternative inference', 1.0000492208214704), ('multiple choice based', 1.0000492192900914), ('semantic manifold', 1.0000492175268765), ('recurrent modules', 1.0000492141157484), ('automate', 1.0000492122404077), ('play chess', 1.000049211714452), ('multiple domains', 1.0000492100454532), ('such learning', 1.0000492011387756), ('black boxes', 1.0000491950204322), ('concave optimization', 1.0000491932095181), ('random manner', 1.000049190257283), ('existing metrics', 1.0000491856995406), ('discretization', 1.0000491488707248), ('generate candidates', 1.0000491454826208), ('deep generator', 1.000049144742855), ('new pairwise ranking', 1.0000491441670443), ('facial action unit', 1.0000491412393258), ('large language', 1.0000491287618447), ('path level', 1.0000490966330602), ('documents', 1.0000490878454353), ('availability', 1.0000490818472494), ('novel input', 1.0000490528403119), ('starting point', 1.0000490333935552), ('principle provides', 1.0000490314626944), ('novel online', 1.0000490256442478), ('instructions', 1.0000490226376326), ('training corpus', 1.0000490220360179), ('autonomous information', 1.00004901854356), ('semantic roles', 1.0000490075361725), ('such programs', 1.000048999284877), ('motion synthesis', 1.0000489986945624), ('simple task', 1.000048974137849), ('complex dynamic', 1.0000489609399243), ('enable', 1.0000489596542825), ('continuous policies', 1.0000489594677024), ('such devices', 1.0000489589859378), ('analysis', 1.0000489521804212), ('powerful deep', 1.0000489299298458), ('analytical learning theory', 1.0000489252853835), ('previous sparse', 1.0000489236516408), ('minimal effort', 1.00004892262701), ('simple gradient', 1.0000488970418517), ('promising paradigm', 1.0000488774829244), ('original text', 1.000048867779788), ('many information', 1.000048867096786), ('new copying', 1.0000488575300837), ('brain inspired', 1.0000488494348194), ('output values', 1.0000488435738264), ('unlabeled set', 1.0000488383133468), ('visual representation', 1.000048836740586), ('layout', 1.0000488263876701), ('standard domain', 1.0000488185621117), ('hebbian', 1.0000488152169515), ('shot detection', 1.0000488046272877), ('various ir tasks', 1.0000487959536273), ('basic problems', 1.0000487935937095), ('joint model', 1.0000487823532442), ('character', 1.0000487432032399), ('local minimum', 1.0000487354017744), ('basic utility technologies', 1.000048724003468), ('available data', 1.0000487194357486), ('universality formalizing', 1.0000487063044845), ('gradient calculation', 1.0000487029686254), ('word extracted', 1.0000487003288174), ('spectral factorization', 1.000048689227982), ('training instances', 1.0000486871252365), ('simulated tasks locomotion', 1.000048684143659), ('k centroids', 1.0000486765743932), ('examples', 1.0000486756248976), ('tuning parameter', 1.00004866522961), ('humans', 1.000048664913637), ('fundamental building block', 1.0000486591749982), ('continual learning', 1.000048634774036), ('prediction accuracy', 1.0000486318619974), ('solution found', 1.0000486117110146), ('real time tens', 1.0000486112842908), ('most tasks', 1.0000485948582847), ('test error', 1.0000485944706397), ('asr training', 1.000048590239498), ('independent component', 1.0000485869632414), ('other regression methods', 1.0000485711443694), ('decision', 1.0000485548408795), ('improving accuracy', 1.0000485499781913), ('slot value', 1.0000485218076465), ('customize', 1.0000485084703272), ('perform parameter', 1.0000484847128), ('new images', 1.0000484681282589), ('methods show', 1.0000484595050394), ('segmentation performance', 1.0000484585526834), ('policy', 1.0000484562300667), ('previous systems', 1.0000484315826388), ('traditional text', 1.0000484303696082), ('level interactions', 1.0000484192331789), ('weights', 1.000048415822479), ('systems can', 1.0000484032563461), ('individual input', 1.0000484009543902), ('results indicate', 1.0000483997646088), ('sequence prediction', 1.000048398807974), ('speech processing', 1.0000483927393522), ('different resolutions', 1.0000483914442677), ('feature flow', 1.0000483827065636), ('new lru models', 1.0000483480620679), ('text sequence', 1.0000483373191273), ('powerful tool', 1.0000483352519867), ('generate samples', 1.0000483328873655), ('data weights', 1.0000483234835669), ('k digit', 1.0000483126552473), ('capture context', 1.0000482991190824), ('directional wavelet', 1.0000482899905627), ('remaining errors', 1.0000482820444245), ('correction network', 1.000048274496055), ('biomedical question', 1.000048274142219), ('deep residual', 1.000048259446794), ('rough set theory', 1.0000482554183496), ('model development', 1.0000482526433965), ('corresponding feature', 1.000048243938613), ('dropping probabilities', 1.0000482409668263), ('state action', 1.0000482400202548), ('objects', 1.0000482313900605), ('mobile', 1.000048229102754), ('second order representations', 1.0000482285886412), ('real images', 1.0000482275649945), ('memory bi', 1.000048205194426), ('specific task', 1.0000482012722587), ('evaluation', 1.0000481755179804), ('understanding', 1.0000481718623324), ('larger representation size', 1.000048162164997), ('subcomponent initialized', 1.0000481595167336), ('training time', 1.0000481327894206), ('smaller subcomponent', 1.0000481291140506), ('biomedical word', 1.000048123978458), ('english language tweets', 1.0000481092169213), ('future frames', 1.0000481075537664), ('network internal', 1.000048099518748), ('commercial speech', 1.000048080033387), ('new adaptive', 1.0000480798858968), ('neuronal networks', 1.0000480677106296), ('target images', 1.0000480673035614), ('predict answers', 1.0000480254008732), ('implement improves', 1.0000480213202503), ('meta learner', 1.0000480196212522), ('metrics analyzed', 1.0000480164872851), ('conversational', 1.000048013056198), ('independent attribute', 1.0000480082202776), ('structured dnn', 1.0000480042130198), ('hierarchical structure', 1.0000479966041158), ('program', 1.000047996179558), ('learning power', 1.0000479950862533), ('several public', 1.000047971576811), ('human actions based', 1.0000479624618084), ('single learning', 1.000047955933516), ('human vision science', 1.000047954826038), ('end trained', 1.0000479525715873), ('projection network', 1.000047946317346), ('formal guarantees', 1.0000479175875003), ('gender detection', 1.0000479147153578), ('invariant classifiers', 1.0000479095371864), ('rough set', 1.0000479077794235), ('previous step', 1.000047903330133), ('solve tasks', 1.0000478977950793), ('different hidden', 1.0000478939117368), ('linguistic input', 1.0000478878829113), ('manner designed', 1.000047875349686), ('noisy observations', 1.0000478741344587), ('image speech', 1.0000478523245873), ('rnn store', 1.000047847845833), ('most data', 1.0000478450404864), ('500d problems', 1.000047830372356), ('benchmark sets', 1.000047821744926), ('supervised separation', 1.0000478170040845), ('rapid learning', 1.0000478147591425), ('rigorous guarantee', 1.0000478072310102), ('spoken language', 1.0000478030084698), ('spoken term detection', 1.0000477972147626), ('same data', 1.0000477941652222), ('use supervised', 1.000047778440005), ('robots', 1.0000477705876827), ('parameter choices', 1.0000477668380898), ('model relevance', 1.000047765854388), ('high', 1.0000477617286165), ('asr transcriptions', 1.000047728605873), ('simulation', 1.0000477284256408), ('words representations', 1.0000477250567674), ('completion tasks', 1.0000477163848438), ('factorization matrices', 1.000047715136894), ('deep rl use', 1.0000477103766663), ('structure', 1.0000477026175358), ('path', 1.0000477006816304), ('trained discriminators', 1.0000476913001237), ('nonlinear dynamics', 1.0000476837000698), ('reduced dimension', 1.0000476803444536), ('extract uncertainty', 1.0000476778710672), ('class imbalance', 1.0000476581644269), ('language comprehension', 1.0000476532693487), ('recurrent feedback', 1.000047652729408), ('boosting', 1.0000476216293583), ('many benchmarks', 1.0000476204052113), ('biggest challenges', 1.0000476160769851), ('deep many', 1.0000476159778973), ('network uses', 1.0000476149689594), ('exhibit embedded', 1.000047608338358), ('nearest centroids', 1.000047606513344), ('generic technique', 1.0000475993871705), ('hierarchical planning', 1.0000475775548283), ('model called', 1.0000475662098391), ('feedback policies', 1.0000475278987389), ('access', 1.000047527594546), ('novel data', 1.000047518060488), ('testing', 1.0000474871848142), ('results showing', 1.0000474550458616), ('new lru', 1.0000474525984213), ('probabilistic theory', 1.0000474441006322), ('art bits', 1.000047442385711), ('external factors', 1.0000474416431426), ('represent weights', 1.0000474389485652), ('reasoning process', 1.0000474359981075), ('categorize existing', 1.0000474251562659), ('annotate', 1.0000474144000453), ('alexnet', 1.000047409896695), ('art extensions', 1.0000474025548427), ('rival feature', 1.000047394643862), ('various levels', 1.0000473943159982), ('geometric method', 1.0000473931149463), ('random mappings', 1.0000473929238685), ('similarity network', 1.0000473867721633), ('bouncing balls', 1.0000473848968643), ('speech tasks', 1.0000473749545953), ('story dialogs', 1.0000473745958656), ('forward propagation', 1.0000473491320037), ('finite depth', 1.0000473413052653), ('circumvent', 1.0000473368107246), ('data group', 1.0000473346804006), ('contrast latent', 1.0000473346608325), ('create challenging', 1.0000473280313782), ('arbitrary orientations', 1.0000473245672108), ('current frame', 1.0000473124221847), ('make', 1.0000473062049553), ('timit phoneme recognition', 1.000047300484542), ('new units', 1.00004729720044), ('noisy acquisition', 1.0000472937594607), ('coarse tokens', 1.0000472853715088), ('map', 1.0000472852138038), ('specific adversary', 1.0000472777243536), ('meta learning proposes', 1.0000472769107225), ('latex generation', 1.0000472760217305), ('collective inference', 1.0000472756613044), ('successful learning characterize', 1.0000472738185517), ('connectivity', 1.000047263679591), ('different contexts', 1.0000472424016362), ('test problems', 1.000047220879684), ('scenarios presented', 1.000047212962769), ('task performance', 1.0000472022743871), ('discretized values', 1.0000471803865938), ('context representation', 1.0000471796075232), ('deep relu nets', 1.0000471768548578), ('same task', 1.0000471688623327), ('complicated reward engineering', 1.0000471615662962), ('dnn acoustic', 1.0000471602023706), ('solve supervised', 1.0000471589631164), ('subcomponents can', 1.0000471564254756), ('matching score', 1.000047155956324), ('refinement', 1.0000471477256585), ('classes minimizing', 1.0000471476204287), ('explicit relationships predicting', 1.0000471446783847), ('similarity calculation', 1.0000471324902624), ('error reduction', 1.0000471285955022), ('large memories', 1.0000471230193793), ('tracking scene', 1.0000471216530713), ('representative parametric', 1.0000471183761208), ('learning solve', 1.000047111689594), ('feedback connections', 1.0000471108453193), ('stochastic estimates', 1.0000471088444283), ('microphone array', 1.000047094970716), ('mapping reviews', 1.000047089911019), ('structured', 1.000047085370811), ('audio image', 1.000047080216184), ('dual sequence', 1.0000470701547373), ('learnable pooling scheme', 1.0000470636756889), ('different networks', 1.0000470608481349), ('design', 1.0000470597425672), ('sampling strategy', 1.0000470544571929), ('conditional information', 1.0000470537347477), ('classification method', 1.000047048468141), ('human intelligence', 1.0000470478384145), ('mlp training', 1.0000470473537877), ('matching news', 1.0000470333328266), ('news articles', 1.000047032983879), ('abstract states', 1.0000470252558493), ('parameterise', 1.0000470222529758), ('art chess', 1.000047020216395), ('dynamical model', 1.000047019308185), ('current approaches', 1.000046985906996), ('base space', 1.0000469828083745), ('stanford natural', 1.000046982718203), ('previous time steps', 1.0000469771585883), ('early search', 1.0000469736081377), ('translation', 1.0000469679048318), ('continuous time', 1.0000469676431178), ('process', 1.0000469611220273), ('unseen datasets', 1.000046954481254), ('images audio', 1.0000469540510382), ('object dynamics', 1.0000469495152833), ('intermediate results', 1.0000469438356758), ('accuracy obtained', 1.0000469331025017), ('network agent', 1.0000469265697463), ('principle allowing', 1.0000469200820947), ('huge availability', 1.0000469138112609), ('ann output', 1.000046909994818), ('produce', 1.000046900902554), ('instantiation', 1.000046890047349), ('3d cnns', 1.0000468659864021), ('networks come', 1.0000468639157987), ('incoming words', 1.0000468626111485), ('real image', 1.000046860644061), ('analyze generalization', 1.0000468547099257), ('unseen data', 1.0000468226626997), ('agents learn', 1.000046816559915), ('many real', 1.0000468161425708), ('heavy augmentation', 1.000046785571334), ('logic', 1.0000467551653458), ('control', 1.0000467401110378), ('many paths', 1.0000467389516285), ('memristor', 1.0000467362869065), ('activation policies', 1.0000467360617364), ('storage', 1.0000467354449927), ('prediction function', 1.0000467353025246), ('normalize phone', 1.000046734202765), ('weak supervised', 1.0000467202940113), ('network properties', 1.0000467182671837), ('word generation', 1.0000467132982205), ('non linearity', 1.0000467107195299), ('different settings', 1.000046707389458), ('knowledge distillation', 1.0000467056373936), ('constant time', 1.000046699195078), ('temporal feature', 1.0000466968133594), ('kind system', 1.0000466856784511), ('solutions assign', 1.000046683232078), ('evaluating sentiment', 1.000046673772284), ('real time lip', 1.0000466665155412), ('sensors growing', 1.0000466566503259), ('produce output', 1.0000466434648465), ('public benchmark', 1.0000466340960845), ('novel data synthesis', 1.0000466321712767), ('new mapping', 1.000046630110553), ('key aspect', 1.000046626793207), ('set membership', 1.0000465978350614), ('correct solutions', 1.0000465969004537), ('finite samples', 1.0000465778053806), ('local normalization', 1.0000465768245836), ('engineered features', 1.000046571243031), ('wikipedia based', 1.000046570017253), ('separate feature', 1.0000465613209142), ('average crash', 1.0000465536937653), ('direct models', 1.0000465535514407), ('dense prediction', 1.0000465530458336), ('box constrained', 1.0000465472037499), ('chemical property prediction', 1.0000465423920593), ('visual qa', 1.0000465361620332), ('synchronization', 1.000046524897471), ('minimize', 1.0000465084709131), ('unique ground truth', 1.0000465070799682), ('problem structure', 1.0000465050338412), ('constraints', 1.0000465038608588), ('noisy observations produced', 1.000046497630582), ('important word', 1.0000464589229732), ('depth', 1.000046438270942), ('key sequence', 1.0000464278007484), ('discriminative sentence', 1.0000464131101043), ('o n', 1.0000464115079917), ('dnns lstms', 1.000046408584117), ('flow model', 1.0000464020307747), ('quest', 1.0000463989893447), ('rich set', 1.0000463964219943), ('recurrent extension', 1.0000463961987307), ('random cluster', 1.0000463842776275), ('modification criterion', 1.0000463795280534), ('simple extraction', 1.0000463711504397), ('atis jobs', 1.0000463648780102), ('corresponding target', 1.0000463576290421), ('control structure', 1.0000463418925611), ('visual madlibs task', 1.0000463130148167), ('model consists', 1.0000463069231649), ('same setting', 1.0000462992422483), ('textual descriptions', 1.000046295570691), ('functional representation', 1.0000462805875467), ('event sequences', 1.0000462767230633), ('cnns can', 1.0000462586052963), ('successive generations', 1.0000462498284453), ('subsequent network', 1.0000462260609455), ('technique', 1.00004621270668), ('extracting paragraph', 1.000046210339788), ('sim', 1.0000462085712811), ('basic', 1.0000462016941325), ('views rewiring', 1.000046190158474), ('spatial map', 1.0000461781166439), ('update rules', 1.0000461677704062), ('summarization', 1.0000461647318386), ('exhaustive benchmarks', 1.0000461579989732), ('such methods', 1.000046146550211), ('overall data', 1.0000461459571086), ('continuous state action', 1.0000461414845607), ('more tools', 1.0000461410811696), ('source modalities', 1.0000461339557227), ('real time remains', 1.0000461314812348), ('such information', 1.000046130171656), ('dataset lecun', 1.0000461271367447), ('samples', 1.0000461193962618), ('sequential', 1.0000461115360488), ('text comprehension', 1.000046103413471), ('full test set', 1.0000460874275798), ('cross task', 1.0000460824299926), ('time enabled', 1.0000460697083111), ('high error', 1.0000460672547247), ('large cnns', 1.0000460646338865), ('mfcc', 1.000046050120763), ('quantum', 1.000046036985986), ('proposed technique', 1.0000460326931537), ('supervised digit', 1.0000460292310425), ('optimisers', 1.0000460175705057), ('classify', 1.0000460149057766), ('more discriminative', 1.0000460073480177), ('domain generalization', 1.0000459989553228), ('statistical approaches', 1.0000459931224612), ('staggering sim', 1.0000459834983562), ('train mlp', 1.000045983038242), ('proposed models', 1.0000459731487783), ('single input', 1.0000459718508665), ('intrusion', 1.0000459598964466), ('different domain', 1.0000459562711896), ('method compared', 1.0000459559142607), ('various scenarios', 1.0000459523428804), ('sparse reward', 1.0000459452776727), ('communicate', 1.0000459397683559), ('given target', 1.000045937977113), ('plausible answer space', 1.0000459357027562), ('statistical dialogue management', 1.0000459322132595), ('same environment', 1.0000458978263267), ('information delivered', 1.000045894510059), ('dialog act classification', 1.0000458870809614), ('particular architectural', 1.000045882245621), ('new metric', 1.0000458784522905), ('speech scaling', 1.0000458663818494), ('medical domain based', 1.0000458640458392), ('good performance', 1.0000458634744893), ('discrete reasoning', 1.0000458591307528), ('different weights achieving', 1.0000458538732075), ('unlabeled speech data', 1.0000458486222332), ('discretized', 1.0000458452300354), ('general affine transformation', 1.0000458319437746), ('models achieves', 1.0000458236330345), ('dnns believe', 1.0000458188264079), ('model using', 1.000045817565415), ('such patterns', 1.000045814053325), ('link prediction', 1.0000458063827873), ('initial conditions', 1.000045793245538), ('modelling performance', 1.000045789355415), ('scenario', 1.0000457683680366), ('lstm decoders', 1.0000457667145843), ('apis', 1.0000457644855876), ('shift reduce', 1.0000457504541076), ('traditional data', 1.0000457450553328), ('dense representations', 1.0000457153918407), ('art spam', 1.0000456818541354), ('effective numerical', 1.0000456785267453), ('language information', 1.0000456777206774), ('deep domain adaptation', 1.0000456696789939), ('standard activations', 1.0000456574901604), ('advanced pattern', 1.0000456562728364), ('cnn models', 1.000045653681592), ('lvcsr tasks', 1.000045632089144), ('visual saliency', 1.0000456289337123), ('multiple', 1.0000456167482257), ('second methods', 1.0000456131700324), ('discover patterns', 1.000045612028792), ('final model decision', 1.0000456101712476), ('multi dimensional', 1.0000456014236927), ('clear trade', 1.0000455963161377), ('write', 1.000045565301422), ('discriminative loss', 1.0000455523060066), ('method may', 1.0000455500597611), ('dialogue', 1.000045548823787), ('benchmark genomics', 1.0000455446862118), ('precision', 1.0000455254497391), ('paths', 1.0000455221166444), ('maximize', 1.0000455156521988), ('sophisticated regularization methods', 1.000045499122359), ('analytical learning', 1.0000454988266811), ('factorization', 1.0000454876142877), ('many recommendation based', 1.0000454690556744), ('explored', 1.0000454631474405), ('mnist cifar', 1.0000454612535246), ('useful representations', 1.0000454604683988), ('starcraft', 1.0000454351297696), ('standard training methods', 1.0000454204796267), ('faces using', 1.0000454171061908), ('mnist classifiers', 1.0000453938975244), ('trained word', 1.0000453849547781), ('vision models', 1.0000453824044593), ('transfer knowledge', 1.000045377327188), ('model prediction', 1.000045372684646), ('joint word', 1.0000453567860552), ('token history', 1.000045356680261), ('considerable improvements', 1.0000453496367394), ('large scale service', 1.000045333650622), ('distributed', 1.0000453224314332), ('basic set', 1.0000453220520242), ('1.2m dialog', 1.0000453142248036), ('sub goal', 1.0000453012156167), ('answer image', 1.0000452912302902), ('method increases', 1.0000452855207922), ('clinical decision support', 1.000045279320231), ('general video classification', 1.0000452778398976), ('sub spaces', 1.0000452751740154), ('multilayer feed', 1.000045272458461), ('temporal pattern', 1.000045269821767), ('transfer', 1.0000452602582741), ('original space', 1.0000452533693955), ('labels corresponding', 1.0000452479562023), ('generation tasks', 1.000045247237643), ('solving', 1.0000452316060764), ('free form', 1.0000452235168271), ('maximum entropy', 1.0000452174590537), ('paragraph level', 1.000045211614689), ('unstructured twitter conversations', 1.0000452070615256), ('learning curves', 1.0000451979422678), ('warm restart', 1.000045193123159), ('latent target', 1.0000451904190826), ('loss metric', 1.0000451882375407), ('simple baseline', 1.0000451801497954), ('proposed mapping', 1.000045160118339), ('residual networks showing', 1.0000451568480644), ('pso p', 1.0000451541574245), ('small set', 1.0000451518823774), ('state spaces', 1.0000451486542845), ('new way', 1.0000451334510954), ('nn', 1.0000451186603103), ('class label', 1.0000451115885407), ('systems obtained', 1.0000451110181152), ('future work', 1.0000451026638508), ('competitive multimodal', 1.0000450995463839), ('analogy detection', 1.0000450797630054), ('utterances extracted', 1.0000450773747898), ('leverage annotated', 1.0000450761663489), ('tasks having', 1.0000450707413124), ('noise', 1.000045068652139), ('only word', 1.0000450564060819), ('nonnegative matrix', 1.000045055246686), ('extended mnist', 1.0000450552078115), ('predictive model', 1.0000450473716653), ('relevant parts', 1.0000450380967063), ('contrastive divergence', 1.0000450379360937), ('feature construction', 1.000045017713175), ('common task', 1.000045013750963), ('deep memory', 1.00004498663375), ('different locations using', 1.0000449834924645), ('deployment', 1.0000449758699175), ('large domains', 1.0000449750832596), ('human speech', 1.0000449721659914), ('discriminative loss functions', 1.0000449685288169), ('top level value', 1.0000449489834444), ('continuous', 1.000044941082739), ('promising solutions', 1.0000449410278311), ('visual cause', 1.0000449314542676), ('mnist benchmark', 1.000044926426864), ('detecting anomalies', 1.0000449234516964), ('task oriented', 1.0000449226016987), ('differentiable operations', 1.0000449210581717), ('pruning connections', 1.0000449191627205), ('linear functions', 1.0000449181240108), ('ensemble formulations', 1.0000449169631709), ('further performance', 1.0000449169375947), ('base model', 1.000044911458587), ('neural transducer', 1.000044899806636), ('predictions using', 1.0000448848537515), ('strided', 1.0000448847602996), ('long outputs', 1.0000448348561533), ('simple technique called', 1.0000448254786907), ('important issue', 1.0000447918827489), ('similar problems', 1.0000447865613236), ('novel dataset', 1.0000447757216953), ('fixed context', 1.0000447678932924), ('phrase based', 1.0000447603164624), ('nonlinear transformations', 1.0000447555885243), ('detecting answer', 1.0000447538621247), ('practical applications', 1.0000447511059576), ('late hidden', 1.0000447501788823), ('interaction time', 1.0000447328101434), ('insufficient training', 1.0000447298724655), ('spike timing', 1.000044727111674), ('source target', 1.0000447197757367), ('systems lvcsr', 1.00004471559127), ('existing clustering', 1.0000447136105304), ('simple models', 1.0000447076910288), ('answer list', 1.000044691789466), ('solve analogy', 1.000044679812917), ('comparisons', 1.0000446777018148), ('contrastive divergence minimization', 1.00004467737451), ('binary questions', 1.0000446750916963), ('dialog', 1.0000446666865548), ('imdb movie', 1.0000446611557945), ('blending physics', 1.0000446295746994), ('bayesian models', 1.000044628624044), ('e commerce', 1.0000446197311694), ('methods help', 1.0000446187971375), ('approach decomposes', 1.000044616508087), ('automatic video', 1.0000446161268053), ('disparate label', 1.0000445902961381), ('matlab keras', 1.000044578057106), ('class can', 1.0000445738875612), ('bleu score', 1.0000445695780515), ('big data era', 1.000044557630164), ('original vqa', 1.0000445536521105), ('description', 1.0000445309185424), ('manual grid', 1.0000445245783496), ('scores computed', 1.0000444979675605), ('contextual rnn', 1.0000444978598662), ('identify spatio', 1.000044495555078), ('explicit density', 1.0000444721217097), ('primary feature extractor', 1.0000444690391184), ('particular word', 1.000044458296678), ('dialogue corpora', 1.0000444541258968), ('abstractive sentence summarisation', 1.0000444483171131), ('small subset', 1.0000444459136657), ('beat character', 1.0000444377241504), ('accelerometer', 1.0000444316334258), ('many pattern', 1.000044431134059), ('generalized haar filter', 1.000044429921638), ('soft rnn alignments', 1.0000444120294332), ('real word', 1.0000444104891921), ('f1 score', 1.0000444073378096), ('complex', 1.0000444062083154), ('side exploring', 1.0000444045934613), ('standard computer', 1.000044402192346), ('second dialog state', 1.0000444007934433), ('sprites', 1.0000443981995637), ('natural language transduction', 1.0000443862647121), ('hierarchical fashion', 1.0000443851340675), ('adversarial settings', 1.000044368462551), ('nonparametric regression datasets', 1.000044344057638), ('methodologies provide', 1.0000443379636883), ('images answer', 1.0000443116735327), ('unaligned text style', 1.0000443083240091), ('simple dnn', 1.00004430349424), ('sophisticated baselines', 1.0000443009957811), ('spoken dialogue', 1.000044288933524), ('model provides', 1.0000442781102317), ('many different', 1.0000442644259946), ('vector', 1.000044262900349), ('synaptic cluster driven', 1.0000442440008668), ('classification object', 1.0000442127358713), ('sharing', 1.0000442068529245), ('quantization scheme', 1.0000441895757874), ('self supervised', 1.0000441763473658), ('art machine', 1.0000441741611474), ('molecular drawings', 1.0000441703557374), ('original ancestor', 1.0000441685423491), ('cnns showing', 1.0000441670567877), ('varied data', 1.0000441632007833), ('learn exploration', 1.00004415905365), ('fitted neural', 1.0000441590194324), ('art clustering', 1.0000441574107755), ('data size', 1.0000441424388296), ('temporal attention performs', 1.0000440942989193), ('new loss function', 1.0000440940952142), ('interpretable model', 1.0000440922443345), ('constrained sequence', 1.0000440899778205), ('information recorded', 1.000044089369757), ('unstructured nature', 1.000044089000057), ('semantic decoder', 1.00004408328237), ('accelerator', 1.000044082635876), ('form encoding', 1.0000440759456617), ('exploration strategies', 1.0000440682194416), ('multi layers', 1.0000440629764644), ('large storage', 1.0000440516481053), ('initialization', 1.000044042617381), ('fine attention mechanism', 1.0000440393939227), ('documents extended', 1.0000440204262218), ('simulated data', 1.0000440160158308), ('method helps', 1.0000440131836892), ('entailment rewards', 1.000043994056435), ('medical domain', 1.000043989271385), ('e2e asr', 1.0000439796037297), ('warm restart learning', 1.0000439776289765), ('generating quality', 1.0000439772910337), ('provide adversary', 1.0000439545335131), ('handle signals', 1.000043953557452), ('soft alignments', 1.0000439435497963), ('unified way', 1.0000439414365014), ('full batch', 1.0000439392402634), ('depth using', 1.0000439352156711), ('grid cells', 1.0000439194215265), ('accurate feature', 1.0000439192743946), ('databases', 1.0000439175927893), ('syntactic information', 1.00004391246414), ('remove', 1.0000439074660212), ('human language', 1.0000438995795613), ('balanced network', 1.0000438986244733), ('dgn', 1.0000438977931614), ('sketch program', 1.00004389726778), ('regression problems', 1.0000438713901414), ('adversarial perturbation', 1.000043870609319), ('discrete activations', 1.0000438304263672), ('grid lstm', 1.0000438265641014), ('methods suffer', 1.0000437885063116), ('creative catalyst', 1.000043780303423), ('evaluation methods', 1.0000437789732555), ('such deep', 1.0000437589189504), ('monotonic chain', 1.0000437412288705), ('selected languages', 1.0000437387387409), ('candidate answer', 1.0000437336636048), ('common random', 1.0000437241064803), ('mfccs', 1.0000437191125913), ('local context similarity', 1.0000437051571853), ('good alignments', 1.0000436922047529), ('encoder output', 1.0000436921939988), ('virtual world', 1.000043690551646), ('label space', 1.0000436902285332), ('respect', 1.000043686097574), ('gan objective', 1.000043677113298), ('supervised', 1.00004367226716), ('generalize', 1.000043662599925), ('common benchmarking', 1.0000436553917722), ('rank function', 1.000043637288176), ('visual saliency demonstrated', 1.0000436091181755), ('sequence labelling', 1.0000436077248736), ('interact', 1.0000436073869274), ('explicit decoupling', 1.0000435963268526), ('new reading architecture', 1.000043583287985), ('leveraging', 1.0000435823258074), ('default', 1.000043577820035), ('type', 1.0000435675290507), ('target variable', 1.000043553201337), ('multilinear filters', 1.0000435331879491), ('new texts', 1.0000435276809851), ('unwanted bias e', 1.000043526353442), ('agent consists', 1.0000435107817331), ('generator outputs', 1.0000435052900778), ('certain age group', 1.0000434987566378), ('multiple entities', 1.000043495376583), ('label', 1.0000434811527643), ('practical video based', 1.0000434797846571), ('unlimited vocabulary', 1.0000434745886184), ('spectral variations characteristic', 1.0000434678294365), ('concept based', 1.0000434672202239), ('sample', 1.0000434320019247), ('several lvcsr tasks', 1.000043423354388), ('log probability', 1.0000434220878407), ('correct set', 1.0000433992299695), ('shallow layers', 1.0000433943137244), ('hard attention mechanisms', 1.0000433905016062), ('determined database', 1.0000433639997721), ('input signal', 1.0000433488904301), ('allow', 1.0000433389405228), ('edge', 1.0000433350004083), ('most approaches', 1.0000433212959063), ('promising solutions lead', 1.000043320961464), ('key idea', 1.0000433129155948), ('mapping acoustics', 1.0000432998617503), ('text conversation', 1.0000432722666037), ('different vision', 1.0000432633689222), ('raw', 1.0000432620963704), ('training model', 1.0000432467533127), ('subword', 1.0000432358630724), ('component', 1.0000432278490365), ('apply', 1.0000432266417594), ('non negativity', 1.0000432234632084), ('necessary gradient', 1.00004321228585), ('few shot learning', 1.0000431940427275), ('intrinsic motivation', 1.0000431903095852), ('merge', 1.0000431855844247), ('particular generative', 1.0000431794732911), ('face clustering', 1.0000431787696216), ('long inputs', 1.0000431751051098), ('fine attention', 1.0000431711396216), ('networks synthesized', 1.0000431639230463), ('significant compression', 1.0000431557153988), ('approach based', 1.0000431515853003), ('small context', 1.0000431459989958), ('multiple feature', 1.0000431326730568), ('lower dimension', 1.0000431233377798), ('total performance gain', 1.0000431067482891), ('parallel text aligned', 1.0000430942207927), ('proposed network', 1.0000430908041538), ('performance accuracy', 1.0000430864619447), ('cache', 1.0000430774260751), ('video description', 1.0000430728582326), ('learned model', 1.0000430651487657), ('frame level', 1.0000430630523902), ('modify', 1.0000430559096152), ('6x reduction', 1.0000430544799455), ('hierarchical softmax', 1.0000430529198223), ('numerous word', 1.0000430529036939), ('hand written', 1.0000430521635835), ('dataset examined', 1.0000430074552247), ('neural response', 1.0000430023937272), ('model used', 1.0000429989023754), ('standard speech', 1.0000429902021752), ('collaborative recurrent autoencoder', 1.0000429899275989), ('full training code', 1.0000429770650574), ('local features', 1.0000429691654156), ('gray level', 1.0000429689869903), ('complex learning tasks', 1.0000429595293254), ('supervised learner', 1.0000429572945497), ('architecture design', 1.0000429543347233), ('end tracking', 1.0000429542251112), ('efficient', 1.0000429188453044), ('fine tune', 1.0000429154768302), ('parallelization', 1.0000429154401957), ('redundant robots', 1.0000429087499418), ('answer', 1.0000429042143129), ('capabilities', 1.0000429000624946), ('word context', 1.0000428955930885), ('support learning', 1.0000428916696367), ('additional input', 1.0000428892242434), ('adversarial', 1.0000428878336496), ('test data', 1.0000428729694024), ('predictive models', 1.0000428672345074), ('art supervised', 1.0000428654457079), ('dnn optimization', 1.0000428619839437), ('effective approach', 1.0000428590918862), ('facilitate pairwise', 1.0000428402988917), ('entropy', 1.0000428374234183), ('intermediate data', 1.0000428301416677), ('catastrophic forgetting', 1.0000428073443277), ('accurate compression', 1.0000428012314686), ('entire sequences', 1.0000427946587342), ('traditional machine', 1.000042764288555), ('system consists', 1.0000427614654108), ('human vision', 1.0000427531296359), ('represent', 1.000042744677401), ('classifier scheme', 1.0000427385470174), ('filtering fusing', 1.0000427293925287), ('such connectivities', 1.0000427279737678), ('uncertain input', 1.0000427219611259), ('target prediction', 1.0000427189101557), ('videos requires', 1.000042718169468), ('art models', 1.0000427164333394), ('random choice', 1.0000427065931978), ('grid', 1.0000426993316498), ('analyze', 1.000042689150088), ('stack', 1.0000426851823279), ('authorship attribution', 1.000042683895089), ('automatic procedures', 1.0000426824124118), ('novel word embedding', 1.0000426807140534), ('bits', 1.0000426732938377), ('depth gated', 1.0000426647992107), ('speech separation', 1.0000426561871705), ('action components', 1.0000426544807477), ('phone', 1.0000426502761715), ('different distributions', 1.000042643515155), ('time series data', 1.0000426151607698), ('entropy loss', 1.0000426094551098), ('blackout requires', 1.0000426009392358), ('art go', 1.0000425951736351), ('prediction model', 1.0000425867430143), ('sophisticated regularization', 1.0000425721403423), ('synthetic data demonstrates', 1.0000425631117915), ('question features', 1.000042544400685), ('input dropout', 1.0000425360969318), ('data mining', 1.0000425312931336), ('infer digits', 1.00004251570537), ('joint visual', 1.0000425099031778), ('nearest', 1.0000425027484277), ('general nonconvex', 1.0000424963926262), ('method works', 1.0000424962386463), ('incorporate knowledge', 1.0000424599068314), ('simple word', 1.0000424597453514), ('linear models', 1.0000424393704068), ('weight matrices', 1.0000424359188955), ('final performance measure', 1.0000424321779646), ('non experts', 1.0000424236256766), ('detected features associated', 1.0000424181202723), ('given task', 1.0000424174567606), ('dual stream', 1.000042375525146), ('long term predictions', 1.000042344458818), ('open domains', 1.0000423387391577), ('labeled source', 1.000042325336861), ('text samples', 1.0000423237006346), ('question representation', 1.0000423077416138), ('boolean', 1.0000423063952764), ('decoding', 1.000042302719007), ('optimality', 1.000042285954414), ('timit database', 1.0000422792462342), ('model perspective', 1.0000422770768609), ('task information', 1.0000422767568518), ('subsequent tasks', 1.0000422718788071), ('remote', 1.0000422703011778), ('least number', 1.000042267624963), ('environment', 1.0000422616630178), ('consistency', 1.0000422592001557), ('intelligent', 1.0000422423515074), ('recurrent batch normalization', 1.0000422130163413), ('attention layers', 1.0000422003387173), ('learnt features', 1.0000421982146268), ('store', 1.000042191885219), ('emotion classifier', 1.0000421862843778), ('dnn classifiers', 1.0000421694908088), ('subtract', 1.0000421668457673), ('vision sensors', 1.0000421572925835), ('many cases representation', 1.0000421479158372), ('visual scenes', 1.000042139951932), ('state update', 1.000042137782109), ('transparency makes', 1.0000421296095572), ('context vector', 1.0000421079630728), ('measuring machine', 1.0000421042861367), ('approximate model', 1.0000421036294869), ('dense vector', 1.0000421029894908), ('ensemble systems', 1.0000420616374583), ('encode', 1.000042056511617), ('years machine', 1.000042016291695), ('mnist compared', 1.0000419988809992), ('potential tool', 1.0000419976750605), ('cognitive databases using', 1.0000419917080943), ('high resolution', 1.0000419915100605), ('networks studies', 1.0000419797956475), ('convergence', 1.0000419752997307), ('different models', 1.0000419722105682), ('math formulas', 1.0000419636613265), ('named entity', 1.000041961856394), ('constrained mixture', 1.0000419573177368), ('learning can', 1.0000419521021946), ('sparse pathway encoding', 1.0000419489615309), ('map score', 1.0000419453333926), ('language sentences', 1.0000419314771751), ('group sparsity', 1.000041918851761), ('real videos', 1.0000419151923763), ('reverse time order', 1.0000419113574814), ('academic benchmarks', 1.0000419098891988), ('numerous applicative', 1.000041899972181), ('significant weakness', 1.0000418912425022), ('sequence using', 1.0000418670080535), ('main aim', 1.0000418381761875), ('important nlp', 1.000041825891498), ('can optimise', 1.0000418225574672), ('encode representative', 1.000041818692547), ('flexible activation functions', 1.0000418178865427), ('bayesian methods', 1.0000418158546407), ('many approaches', 1.0000418135852103), ('new control', 1.000041809443557), ('defining options', 1.0000418051605386), ('individual data', 1.0000417966281219), ('common ir metrics', 1.000041784300278), ('generic end', 1.0000417705208684), ('logical grammar', 1.0000417702544613), ('item preferences', 1.0000417614764499), ('temporal motion characteristics', 1.0000417459196482), ('crucial design factor', 1.000041740339063), ('understand', 1.000041739869395), ('promising approach', 1.0000417341188126), ('conditioning information', 1.0000417197192313), ('spatial diffuseness', 1.0000417122361238), ('method gives', 1.0000417047803116), ('french translation', 1.0000416986646492), ('understand language', 1.000041692825639), ('actual fitness evaluations', 1.0000416917843775), ('noisy signals', 1.000041690968317), ('raw motion', 1.0000416715606342), ('network synthesis', 1.0000416646187673), ('networks snns', 1.0000416605739648), ('cyclical learning', 1.0000416578979356), ('linear nature', 1.0000416527415565), ('previous approaches', 1.000041647524114), ('lasso screening', 1.0000416439258173), ('multimedia', 1.0000416418323483), ('multi sensor accelerometer', 1.0000416416562916), ('simplify', 1.0000416333893523), ('general approach', 1.0000416310678384), ('topic categorization', 1.0000416182888991), ('additional filters', 1.0000416113544834), ('slow reinforcement', 1.0000416080430234), ('various test', 1.0000416042294962), ('noisy time series', 1.0000415991760978), ('ts networks', 1.000041590301849), ('realistic samples', 1.0000415893013872), ('holistic face processing', 1.000041564629426), ('noisy time', 1.0000415310706932), ('novel', 1.0000415216200047), ('sentiment', 1.000041519896633), ('non expert', 1.0000415017933446), ('many recommender', 1.0000414962700028), ('learning goal', 1.0000414942146685), ('isotropic variance', 1.0000414923438103), ('previous work help', 1.0000414767997958), ('good fitness estimates', 1.00004146229432), ('phoneme classification', 1.0000414580669066), ('information processing', 1.0000414531409454), ('unified solution', 1.0000414210561213), ('projection views', 1.000041418585569), ('other network', 1.0000414086501788), ('multiple scales', 1.0000414039231607), ('specify', 1.000041387586072), ('explicit background knowledge', 1.0000413866529934), ('unsegmented speech', 1.0000413728999114), ('highly redundant', 1.0000413717952037), ('such domain', 1.0000413714256196), ('multiple levels', 1.0000413588889014), ('temporal correlation', 1.0000413536308863), ('standard knowledge', 1.0000413504058172), ('new formulation called', 1.0000413427644155), ('regional modeling', 1.0000413376010453), ('optimal results', 1.0000413347007622), ('spatiotemporal brain data', 1.0000413289813868), ('evolutionary product unit', 1.0000413276749722), ('model decision', 1.0000413262814605), ('better models', 1.000041324529392), ('other classifies', 1.000041322432084), ('enhance', 1.000041308287772), ('multivariate probabilistic', 1.00004130728942), ('digital documents', 1.0000413009577704), ('sentence pairs', 1.0000412960340033), ('standard approaches', 1.000041286075536), ('imagenet classifier', 1.000041280300498), ('art word', 1.0000412747786092), ('microblog', 1.000041271916104), ('latent factor', 1.0000412647355035), ('true multilingual', 1.000041259732732), ('hierarchical levels', 1.0000412458758623), ('approach compared', 1.000041224633581), ('tag prediction', 1.0000412240260523), ('discriminative one', 1.0000412054077186), ('network making', 1.0000412000294687), ('large action spaces', 1.000041199455156), ('turn decoded', 1.0000411949621661), ('key space', 1.0000411865235659), ('temporal', 1.0000411835950387), ('core', 1.0000411792975723), ('blackbox', 1.0000411777711282), ('bayesian', 1.000041176071385), ('substantial boost', 1.0000411629088537), ('original cbt test', 1.0000411347595546), ('approximate alternatives', 1.0000411177171618), ('generalized haar', 1.0000411125158515), ('low rank bilinear', 1.000041110717403), ('hidden states', 1.0000411037605406), ('learning allow', 1.0000411029498182), ('short texts', 1.0000410960580661), ('sampled based', 1.0000410958826327), ('future', 1.0000410931755328), ('addressing class', 1.0000410697585662), ('art image', 1.0000410599869067), ('neurons', 1.0000410470231214), ('processes speeds', 1.0000410340481178), ('paq', 1.0000410244260052), ('representation impacts', 1.000041018634972), ('same class', 1.000041015664254), ('expected wer', 1.0000410131583968), ('art learning', 1.0000410125714865), ('method determines', 1.0000410111927232), ('identifying statements', 1.0000410031171942), ('messages', 1.0000409807685273), ('connectives', 1.000040970440746), ('novel way', 1.0000409702324156), ('model initializations', 1.000040969821113), ('model benefits', 1.0000409591331698), ('end attention', 1.0000409555773468), ('prediction models', 1.0000409534774328), ('class enhanced', 1.0000409440730214), ('additional domain', 1.0000409440373657), ('evolve', 1.0000409428014074), ('bayesian inference', 1.0000409421780219), ('position evaluation', 1.0000409420632526), ('classification methods', 1.000040940825935), ('provide guarantees', 1.0000409301483995), ('add noise', 1.0000409288291976), ('limited adaptation data', 1.000040926370062), ('method compares', 1.0000409130397678), ('long short', 1.0000409092644698), ('mnist benchmark classification', 1.0000409059323254), ('informative features', 1.0000408945861134), ('human experts nature', 1.0000408930930753), ('benchmarking', 1.00004088373241), ('online convex', 1.0000408647177803), ('paths show', 1.0000408608121178), ('encoders', 1.0000408575789013), ('neural reordering model', 1.0000408563810208), ('approaches', 1.000040854030637), ('temporal domain', 1.0000408363929703), ('new metric called', 1.0000408272987324), ('document question', 1.0000408247871462), ('complex error', 1.0000408010924238), ('most real', 1.0000407954066164), ('meaningful way', 1.000040780967437), ('original ones', 1.0000407802376379), ('proposed pso', 1.0000407653097425), ('speech segments', 1.0000407641063036), ('hard attention mask', 1.0000407637894604), ('decision based', 1.0000407616730418), ('principle', 1.0000407588598796), ('regularizers', 1.0000407459452696), ('standard feed', 1.0000407452589475), ('machines', 1.000040743223819), ('cluster centers', 1.0000407284889483), ('learned features', 1.0000407240604066), ('related tasks', 1.0000407237959563), ('cnn based', 1.0000407203530606), ('many output', 1.0000407174077857), ('atomic actions', 1.0000407036506713), ('inverse models', 1.000040665282311), ('equivalence classes', 1.0000406617991004), ('multiple settings', 1.0000406569685598), ('timit dataset', 1.0000406318320658), ('generative aspects', 1.0000406258009278), ('given output', 1.0000406177637098), ('modern system', 1.0000406021288664), ('dynamic boltzmann', 1.0000405968869377), ('safe reinforcement', 1.000040592282726), ('high speed streaming', 1.0000405917105848), ('detect salient', 1.0000405911521295), ('photon migration', 1.0000405908528112), ('acoustic tokens', 1.0000405862218664), ('causal learning', 1.0000405763510996), ('observed data', 1.0000405689086234), ('spatial knowledge', 1.000040564271186), ('neural circuits', 1.0000405633261054), ('take existing', 1.0000405629414575), ('make inference', 1.0000405437350846), ('controlling components', 1.0000405416989477), ('network decides', 1.0000405342773306), ('novel recurrent', 1.000040525511605), ('sensor noise', 1.0000405241486823), ('specialized architecture', 1.0000405166522603), ('competitor models', 1.0000405108574677), ('conventional layer', 1.0000405061665532), ('deep domain', 1.000040504689203), ('fixed point', 1.0000405006161148), ('independent components', 1.0000404999185952), ('base line', 1.0000404984531934), ('sentence embedding', 1.000040497586801), ('fixed dropout', 1.0000404939310978), ('qualitative analysis', 1.0000404936295266), ('dialogue generation', 1.0000404910180694), ('dnn structure', 1.0000404799523752), ('possible solution', 1.000040478228585), ('random', 1.0000404777893992), ('recommendation domains', 1.0000404421415239), ('analysis highlights', 1.0000404413303636), ('relu activations', 1.0000404236042746), ('hidden', 1.000040420132532), ('invariant representations', 1.000040413861618), ('measure data', 1.0000404127340257), ('classification module', 1.0000404023994252), ('word must', 1.0000404020783817), ('current learning', 1.0000404007309265), ('common scenario', 1.0000404006682158), ('least document', 1.0000403974681302), ('discriminator', 1.000040394119531), ('gaussian covariance', 1.0000403859063363), ('first order', 1.0000403835413474), ('limited training', 1.000040376736602), ('non parametric', 1.000040363968245), ('visual questions', 1.0000403627896728), ('term detection', 1.000040360832216), ('specific domains', 1.000040353608287), ('such perturbations', 1.0000403444718828), ('model simplification', 1.0000403368797564), ('suboptimal choice', 1.000040334940101), ('simple physics', 1.0000403347521178), ('key challenges', 1.0000403311004946), ('end system', 1.0000403305786119), ('train model', 1.00004032275979), ('ordering performance', 1.000040320272158), ('compression', 1.0000403169262453), ('solvable', 1.0000403064912506), ('encode data', 1.0000403032721943), ('settings', 1.0000402931485868), ('cultural learning inspired', 1.000040289895938), ('representation comes', 1.0000402858480386), ('sensor based', 1.0000402702740725), ('brain activity', 1.0000402698280733), ('cortex', 1.0000402672341606), ('pseudoinverse matrix', 1.0000402665458452), ('spatial response patterns', 1.0000402632126901), ('translation nmt', 1.0000402616431314), ('visual concepts', 1.0000402551483782), ('art model', 1.0000402543076525), ('semantic coherence attention', 1.000040235247848), ('base tables', 1.0000402349138506), ('general recurrent', 1.000040223949795), ('class probabilities', 1.000040207153627), ('acoustic utterance', 1.0000401934464942), ('visual stimuli', 1.0000401920271016), ('networks area', 1.0000401875711606), ('test target', 1.0000401764768099), ('weight parameters', 1.0000401571258313), ('soccer', 1.0000401321699792), ('robocup', 1.0000401162663035), ('current scheduling', 1.0000401148085878), ('different sequence labeling', 1.0000401134395638), ('different go', 1.0000401048850296), ('different examples', 1.0000400886289267), ('representing space', 1.0000400862956418), ('predict target', 1.0000400785243588), ('main limitations', 1.0000400765422643), ('complicated environments', 1.000040074072908), ('neural activity', 1.000040073467957), ('particular learning', 1.000040073171933), ('generalization make', 1.000040068929384), ('powerful approach', 1.0000400528526352), ('advanced chemical knowledge', 1.0000400452373026), ('standard way', 1.0000400377651015), ('authors knowledge', 1.0000400377568606), ('compact circuit module', 1.000040026919489), ('outperform others', 1.000040018108152), ('sparsity', 1.0000400158248013), ('activation maps', 1.0000400069210142), ('more efficient', 1.0000400013121284), ('decode', 1.0000399999631504), ('text representation', 1.0000399962766513), ('generator', 1.000039975011285), ('more actions', 1.0000399735707646), ('galaxy morphology', 1.0000399688874833), ('non stationary', 1.0000399667825706), ('speaker adaptation', 1.000039964445448), ('soft attention allows', 1.0000399572751004), ('advanced solution', 1.000039950781691), ('ctc models', 1.00003994224396), ('relu', 1.0000399416844787), ('full evaluation', 1.0000399361471901), ('better identification', 1.0000399349323148), ('constructive representations', 1.0000399341498085), ('novel learning', 1.0000399173405918), ('progressive learning', 1.0000399029872726), ('imagine testing', 1.0000399023771023), ('tree', 1.0000398800737837), ('unimodal learning', 1.0000398700309063), ('parallel computing', 1.0000398694074626), ('human subjects using', 1.000039868931937), ('powerful alternative', 1.000039858591174), ('weighted sum', 1.0000398568092739), ('preexisting features', 1.0000398527428733), ('further statistical', 1.0000398457825845), ('detecting objects', 1.0000398208395074), ('setup', 1.0000398148634948), ('tasks thanks', 1.000039807066343), ('wavenet', 1.0000398009492997), ('standard sensitivity analysis', 1.0000397933814413), ('squared loss', 1.0000397838733173), ('multiple word meanings', 1.0000397815758526), ('feature sample', 1.00003977208075), ('game reward', 1.000039768463881), ('help model', 1.0000397493503288), ('term proximity', 1.0000397435862407), ('generation', 1.0000397289916099), ('sparsification', 1.0000397270341475), ('inductive bias', 1.0000397245068264), ('word opening', 1.0000397160745103), ('such generators', 1.0000397117458963), ('achieve accuracies', 1.0000397088308122), ('decision process', 1.000039708480135), ('general nonconvex objectives', 1.0000397064562623), ('primary components', 1.0000396970299203), ('parameter selection', 1.000039695615818), ('deep components', 1.000039652992761), ('feature quality', 1.0000396466721362), ('arbitrary elements', 1.0000396202807467), ('fmri datasets', 1.0000396182423748), ('surrogate objective', 1.0000396066308663), ('weighted feature', 1.000039585847251), ('metaphor processing', 1.0000395828774868), ('internal hidden', 1.0000395815747405), ('developing cnns', 1.0000395813686747), ('medical text domain', 1.000039580986443), ('invariant classifier', 1.0000395753677844), ('various walking', 1.0000395706947538), ('line planning', 1.0000395683880374), ('transform', 1.0000395681481302), ('single output', 1.0000395649348681), ('pipe lined', 1.000039552925943), ('main objective', 1.0000395528905643), ('end using', 1.0000395213314222), ('level representations', 1.0000395198241432), ('different components', 1.0000395114476368), ('latency', 1.0000395081320972), ('new information', 1.000039500597608), ('sentence similarity', 1.0000394887062447), ('transparency can', 1.0000394752591806), ('special regularization', 1.000039466148405), ('3d rotations', 1.0000394519575875), ('streaming', 1.0000394384290532), ('fundamental prerequisite', 1.0000394302980478), ('9x', 1.0000394285947076), ('gan training', 1.000039425839071), ('experienced qualia', 1.000039422654277), ('knowledge provided', 1.0000394201684282), ('question representations', 1.0000394027644837), ('alternative approaches', 1.000039399638287), ('small data', 1.0000393987699518), ('method targeting', 1.0000393921936495), ('audio processing', 1.0000393857018772), ('clinical electroencephalograms', 1.0000393851071325), ('overall objective', 1.000039383278), ('human learning', 1.000039371708566), ('classical nlp approaches', 1.0000393692352), ('solutions discovered', 1.0000393684297597), ('previous conversion', 1.000039367491364), ('human motion prediction', 1.0000393562954788), ('ctc trained', 1.0000393465792057), ('bioinformatics', 1.0000393427591159), ('architectures studies', 1.0000393369859355), ('projection can', 1.0000393280614155), ('good generalization', 1.0000393261734577), ('architecture results', 1.000039312842611), ('parameters must', 1.0000393073679692), ('end fashion', 1.0000393067691309), ('linear nonlinear', 1.0000393048634504), ('achieve integrated', 1.0000392692885032), ('holistic information', 1.0000392604129944), ('suitable parameter', 1.0000392594401386), ('cognitive databases', 1.000039257160039), ('parameterization', 1.0000392486565892), ('use gated', 1.0000392469669197), ('reproducible method', 1.0000392053110616), ('take advantage', 1.0000392029244938), ('present generated', 1.000039181217939), ('function taking', 1.0000391707448533), ('temporal attention mechanism', 1.0000391562402104), ('medical data', 1.0000391365013381), ('more decoders', 1.0000391237710504), ('acquire control', 1.0000391142364724), ('multi microphone techniques', 1.000039111204421), ('extract', 1.000039111135916), ('earlier layer', 1.0000390996401816), ('rise', 1.0000390975110478), ('specific dimensions', 1.0000390868813356), ('fewer target classes', 1.000039086462414), ('networks produce', 1.000039086450487), ('physical hexapod', 1.0000390714704799), ('previous', 1.0000390704962068), ('result accuracy', 1.000039066218585), ('mapping function', 1.000039035000163), ('real transduction problems', 1.0000390310033216), ('different paths', 1.0000390285489706), ('hybrid strategy', 1.0000390282754525), ('output results', 1.0000390266802206), ('gaussian fields', 1.000039024426048), ('model yields', 1.000039021558604), ('face photographs', 1.000039012986426), ('lower error', 1.0000390050562122), ('translate', 1.0000389942641652), ('network snn', 1.0000389859225094), ('unseen combinations', 1.0000389788791857), ('previous move', 1.0000389750720873), ('other state', 1.0000389714944027), ('target sequence', 1.0000389652625643), ('multi step', 1.0000389550051303), ('domain condition', 1.0000389528435194), ('solve dialogue', 1.0000389505018183), ('dense transformer', 1.0000389458049541), ('high multiplicity assignments', 1.0000389335975062), ('eda mcc', 1.0000389243440224), ('vocabulary oov', 1.0000389155110359), ('few classifiers', 1.0000389136369299), ('addition evolution', 1.0000389134886116), ('global sequence', 1.0000389068307276), ('multi target', 1.0000389053290135), ('produce results', 1.000038898276682), ('turing machines', 1.0000388957581066), ('deleting perturbation', 1.0000388878031645), ('new examples', 1.0000388864059413), ('compress', 1.0000388850664805), ('detected objects', 1.0000388813882115), ('components', 1.0000388790373091), ('adaptation layers', 1.0000388729327128), ('skills deciding', 1.0000388691842854), ('content invariance', 1.0000388690219557), ('data e', 1.0000388613080744), ('detailed model', 1.000038860759948), ('various types', 1.000038855123051), ('prior experience', 1.0000388534844415), ('networks focusing', 1.0000388528429835), ('input signals', 1.0000388500554969), ('busy road', 1.0000388469671608), ('term vectors', 1.0000388460184668), ('visitors identify', 1.0000388393691393), ('animal images', 1.0000388376696814), ('usage', 1.000038832369411), ('topic inference', 1.0000388303406664), ('real time produces', 1.0000388286049542), ('deploy', 1.0000388255549861), ('word ctc', 1.0000388239295979), ('learning using', 1.000038823201896), ('methods available', 1.000038811018662), ('challenging research', 1.0000388090567756), ('structure based', 1.0000388080648988), ('crucial pieces required', 1.0000388076887494), ('youtube face', 1.0000387997708338), ('dnn parameters', 1.0000387985605197), ('response', 1.000038785474123), ('np complete', 1.0000387736322467), ('multiple signal', 1.0000387693426975), ('novel data samples', 1.0000387609185266), ('merge architecture', 1.000038758140459), ('lattices used', 1.000038749099861), ('understand text', 1.00003874311551), ('available', 1.0000387406653748), ('original tanh', 1.000038738149328), ('similar task', 1.0000387369154788), ('linguistic processing', 1.0000387350365967), ('results obtained', 1.0000387290864292), ('cooperative segmentation', 1.0000387260364552), ('competitive mnist', 1.0000387033483065), ('disentangled representation', 1.000038691997947), ('model uncertainty', 1.0000386895361524), ('maximum likelihood estimation', 1.00003868811398), ('learning objective', 1.0000386879477976), ('carnage', 1.0000386857323804), ('weak domain', 1.0000386834580743), ('video speech', 1.000038662473922), ('logical reasoning', 1.000038660325182), ('sentence encoders', 1.0000386566862363), ('models results', 1.000038648139237), ('entire source sentence', 1.0000386452700938), ('particular task', 1.0000386370747527), ('conceptual issues including', 1.000038628181107), ('general filters', 1.000038625131342), ('temporal task', 1.0000386246342785), ('tanh activation functions', 1.0000386127752092), ('extract answers', 1.000038603294654), ('approach consists', 1.0000385993961316), ('voice translation', 1.0000385969418328), ('schema', 1.0000385929754927), ('reading comprehension', 1.0000385914603498), ('stacked layers', 1.0000385830680172), ('transition system', 1.0000385789304351), ('missing data', 1.0000385783241048), ('fast rl', 1.0000385615674419), ('seq2seq learning', 1.0000385594069914), ('multiple points', 1.0000385581383437), ('previous works', 1.0000385546585275), ('singular values', 1.0000385529263425), ('hardware', 1.0000385421547375), ('gaussian', 1.000038539923078), ('noise conditions', 1.0000385349652066), ('cluster membership', 1.0000385271155792), ('prototype', 1.0000385139141788), ('recent qa datasets', 1.0000385103931453), ('memory cells', 1.0000385024845806), ('art speech', 1.0000384964781626), ('small source', 1.0000384785176453), ('phone based', 1.00003847469936), ('predict advertisement', 1.000038471293501), ('message', 1.0000384555863913), ('specific requirements', 1.0000384512277352), ('underlying model', 1.0000384494402559), ('better accuracy', 1.0000384427615279), ('improved accuracy', 1.0000384418386337), ('cool networks can', 1.000038440639949), ('associate objects', 1.0000384362719958), ('models leverage', 1.0000384233161306), ('nist', 1.000038422809458), ('large recurrent', 1.0000384139044391), ('real world math', 1.0000384059462422), ('face verification', 1.0000383935790087), ('traditional speech', 1.0000383935529642), ('snn uses', 1.0000383918328535), ('layer types', 1.0000383887314523), ('linear functions acting', 1.0000383883249555), ('english asr', 1.0000383840901828), ('tracker gives', 1.000038372477819), ('direct language', 1.0000383620088846), ('core idea', 1.0000383475025685), ('parameter space', 1.0000383455417075), ('search task', 1.000038340885186), ('perceptual tasks', 1.0000383351130064), ('adversarial networks', 1.0000383276830038), ('nonlinear transition', 1.000038321976617), ('manipulate', 1.0000383206665524), ('variable term', 1.0000383196498372), ('several', 1.000038310844232), ('completion models', 1.0000383087780311), ('redundant', 1.0000383043593508), ('pose point', 1.0000383031166076), ('consistent performance', 1.000038287597308), ('first part', 1.0000382856636298), ('several solutions', 1.0000382791470415), ('simple word hypotheses', 1.0000382752990082), ('tiny yolo', 1.0000382735388125), ('half spaces', 1.000038262295746), ('various re scalings', 1.000038261106975), ('fine tuning', 1.0000382547759399), ('differing types', 1.0000382532404657), ('transition matrices', 1.0000382519796138), ('method aims', 1.0000382470778797), ('model builds', 1.0000382442094642), ('interpretable way', 1.0000382417609601), ('function', 1.0000382352539552), ('network dqn', 1.0000382334423057), ('task pairs', 1.0000382224262105), ('way', 1.0000382218599326), ('common cnn', 1.0000382186306016), ('similarity comparisons', 1.0000381992625507), ('basic model', 1.0000381884976153), ('spatial normalization', 1.000038176930984), ('automobile gps', 1.0000381686102648), ('clinical domain experts', 1.0000381649926766), ('challenging character', 1.0000381633763704), ('synthesize source', 1.0000381481354927), ('humans must', 1.000038147850015), ('different types', 1.0000381279058836), ('activations', 1.0000381265974214), ('linear regression', 1.0000381039002584), ('noise ratio', 1.0000380999722507), ('collection', 1.0000380904192874), ('new activation function', 1.0000380863015705), ('controller', 1.0000380853980808), ('d vector', 1.0000380760384868), ('classification technique', 1.0000380687064405), ('spatial role', 1.0000380546000196), ('overfit', 1.0000380509205156), ('data manifold', 1.0000380377196811), ('relu nets', 1.0000380334677819), ('human representations', 1.00003802013785), ('composite representation', 1.0000380170970775), ('tasks requiring', 1.0000380144234902), ('transfer based', 1.0000380032140177), ('shared representations', 1.0000380014560983), ('bayesian method', 1.0000379957188958), ('nodes', 1.0000379926495746), ('post edits', 1.0000379907918762), ('standard relu', 1.0000379904832934), ('source data', 1.0000379832405908), ('improved strength pareto', 1.000037976373938), ('human tool use', 1.0000379614921777), ('outputs', 1.0000379313395924), ('snn simulation', 1.000037916991138), ('group theory', 1.0000379136401552), ('vector product', 1.000037907303941), ('dark knowledge transfer', 1.0000379054962885), ('main result', 1.0000378804633636), ('covariance function', 1.0000378776540677), ('submitted text', 1.0000378645220207), ('human judges', 1.0000378637898868), ('results can', 1.0000378620541452), ('proposed methods', 1.0000378508859382), ('optimal behavior', 1.000037850399162), ('given word', 1.0000378445932019), ('acquisition function', 1.0000378353132682), ('internet', 1.0000378338432647), ('accelerate learning', 1.000037831501004), ('original samples', 1.000037825445919), ('scale data', 1.0000378135778958), ('symbolic executor', 1.0000378084426502), ('traditional rl methods', 1.0000378054729604), ('arbitrary subgoals', 1.0000378031678079), ('open', 1.000037801023186), ('art fixed', 1.0000377811712367), ('test accuracy', 1.0000377730949608), ('bio informatics', 1.0000377669579508), ('annotated resources', 1.0000377627722128), ('such network', 1.0000377609053726), ('layer residuals', 1.000037742829565), ('architectures defy', 1.0000377387708657), ('latent discourse', 1.0000377381142043), ('answer words', 1.000037732121263), ('memory capacity', 1.000037729578781), ('bayesian model', 1.0000377191409848), ('observed examples', 1.000037716634879), ('deep spiking', 1.0000377153954987), ('human perception', 1.0000377125490332), ('vqa matter', 1.0000377117936923), ('adaptive locomotion generation', 1.0000377114477943), ('language nl', 1.000037701509407), ('non overlapping', 1.0000376965895086), ('individual test points', 1.0000376807960274), ('theoretical results', 1.0000376710858863), ('develop task', 1.0000376587966995), ('generative topic', 1.000037653460768), ('new sampling', 1.000037652523682), ('several evaluation campaigns', 1.0000376292828042), ('dependencies', 1.0000376278526397), ('cross compare', 1.0000376268750835), ('new structure termed', 1.0000376267010715), ('conventional dnns', 1.0000376252738299), ('next move', 1.000037618356886), ('results using', 1.0000376167599372), ('buffer', 1.0000376008550398), ('policy optimisation', 1.000037596109771), ('tested failed', 1.0000375940967803), ('abstractive sentence', 1.0000375839725772), ('question layer', 1.0000375773707963), ('spam', 1.0000375566002702), ('spatial attention architecture', 1.000037551478189), ('penalty term', 1.0000375130554384), ('refine', 1.0000375114123934), ('many existing', 1.00003750904147), ('task considered', 1.0000375089708935), ('investigate redundancies', 1.0000375088562004), ('human would', 1.0000374834273067), ('nonlinear', 1.0000374750246341), ('promising alternative', 1.000037467303568), ('depth brings', 1.0000374530785991), ('sparse pathways', 1.0000374419192983), ('sequence question', 1.0000374369832667), ('linear readout', 1.0000374369609815), ('web search', 1.0000374236178529), ('previous timestep', 1.0000374134708565), ('simplest settings', 1.0000374075301683), ('primary feature', 1.000037403609373), ('visual scene', 1.0000373966103866), ('unmodified labels', 1.0000373918195178), ('weight pruning', 1.0000373908430593), ('human similarity', 1.0000373870860364), ('surpass', 1.000037384693693), ('gated architectures', 1.0000373804700253), ('learnability', 1.0000373573170753), ('simpler projection', 1.0000373380970586), ('clusters showed', 1.000037332580302), ('data samples', 1.000037327344122), ('unsegmented speech signals', 1.0000373192257164), ('minimal hand crafted', 1.0000373153168312), ('pairwise ranking', 1.000037312501333), ('improve prediction', 1.0000373106256013), ('only word labels', 1.0000372874955379), ('repeat entity', 1.0000372867848368), ('structured behaviors', 1.0000372663768289), ('perturbation norms', 1.00003726581626), ('loss', 1.0000372620117088), ('memory characteristic', 1.0000372474667365), ('polygon vertices', 1.00003724256427), ('dbn using', 1.0000372412808614), ('different sequence', 1.000037234095178), ('quantization', 1.0000372139625546), ('building machines', 1.000037211006019), ('agents develop', 1.0000371989175734), ('detecting multivariate', 1.0000371982767555), ('observed signal', 1.0000371946313191), ('analysis technique', 1.000037193422782), ('ai', 1.0000371917710664), ('sequence data', 1.0000371842471343), ('final dnn', 1.0000371761069355), ('represent dnns', 1.0000371757262734), ('current dnns', 1.0000371674785307), ('network supporting', 1.0000371637727892), ('cyclical learning rate', 1.0000371526975584), ('lexical', 1.0000371514077784), ('art techniques', 1.0000371497454283), ('more accurate', 1.0000371413476759), ('flexible activation', 1.0000371361436728), ('understanding analyzing', 1.0000371228969613), ('overall accuracy', 1.0000371201078933), ('bigger dnn', 1.0000371155084316), ('x3 times', 1.0000371082470008), ('classical connectionist', 1.000037105065487), ('move predictor', 1.000037098904089), ('label shift', 1.000037087399424), ('simulated stock', 1.0000370862593304), ('invariance grows', 1.000037080286024), ('major drawback', 1.0000370782759709), ('guide agent', 1.0000370700061985), ('low dose', 1.0000370621715906), ('guiding signals', 1.0000370326675234), ('other class', 1.0000370315919676), ('using', 1.0000370294654484), ('similarities expressed', 1.000037012997718), ('link', 1.0000370114560755), ('simulated', 1.0000370020576392), ('novel gradient', 1.0000369974033712), ('acoustic source separation', 1.0000369939156686), ('pairwise sequence', 1.0000369872567245), ('particular ordering', 1.0000369857807305), ('traditional auto', 1.0000369731475458), ('parameterized motor', 1.0000369611811055), ('constant probability', 1.0000369581863011), ('novel approach based', 1.0000369525213775), ('will release', 1.000036944129623), ('deconvolution', 1.0000369414501935), ('dnn obtains', 1.000036938662888), ('storytelling dataset', 1.0000369363833783), ('first layer', 1.0000369360444255), ('random vectors', 1.0000369297977163), ('full batch training', 1.0000369291622406), ('eigenvectors', 1.0000369256938195), ('perspective', 1.0000369231226796), ('method results', 1.000036922406002), ('candidate answers', 1.0000369165630552), ('continuous word', 1.0000369122594448), ('commonsense', 1.000036904580027), ('different evaluation', 1.0000369020005728), ('dragan enables', 1.0000369007208398), ('available antithesis', 1.0000368986949486), ('learn concepts', 1.0000368971718487), ('allow step', 1.000036892944325), ('complex hand crafted', 1.0000368926364693), ('external knowledge', 1.0000368809526674), ('noise realization', 1.0000368650392244), ('take knowledge', 1.0000368646729318), ('traditional reinforcement', 1.0000368633845225), ('audio data', 1.0000368558297945), ('emotion classifiers', 1.0000368446917525), ('methodologies', 1.0000368383692697), ('fixed decomposition', 1.0000368353025608), ('major challenge', 1.000036831979143), ('non', 1.000036826018237), ('model results', 1.0000368233403176), ('intermediate layers', 1.0000368166414495), ('several language', 1.0000368049394053), ('new activation', 1.0000367949277247), ('objective', 1.0000367794469815), ('linear systems', 1.000036769344052), ('spectral variations', 1.0000367641093764), ('improve classification', 1.0000367600395064), ('scalable alternative', 1.000036757686357), ('speed thanks', 1.0000367542145678), ('data sources', 1.0000367487105983), ('possible failures', 1.000036748688568), ('art error', 1.000036740550375), ('support', 1.000036739679116), ('unseen signals', 1.0000367353887498), ('discourse relations', 1.0000367275108348), ('connectivities', 1.0000367264251078), ('ability', 1.0000367145910032), ('scientific consistency', 1.0000367138638302), ('neuronal spike', 1.0000367111054027), ('predictions', 1.0000367003222685), ('time usage', 1.0000366956751379), ('descriptors', 1.0000366896260011), ('confusing classes', 1.0000366860833847), ('m cnns', 1.0000366840850747), ('construct evaluate', 1.0000366819349769), ('threshold based', 1.00003668079489), ('extended long', 1.000036678181859), ('improve memorization', 1.0000366674646182), ('experiments using', 1.0000366627480177), ('diverse environments', 1.0000366601418138), ('tools', 1.000036659087475), ('diverse set', 1.000036635829551), ('single video', 1.0000366355919037), ('physical metaphor', 1.000036627757765), ('temporal stream', 1.0000365990806679), ('standard evaluation', 1.0000365837646739), ('words assumption', 1.000036575278791), ('learning behaviors', 1.000036572822005), ('digital mammography images', 1.0000365670460722), ('generic coupling', 1.0000365663528918), ('suggestions', 1.0000365606314126), ('recent advances', 1.0000365601492933), ('full boltzmann', 1.000036546945273), ('neighboring frames', 1.0000365439141958), ('classification using', 1.0000365408671084), ('games', 1.0000365392305322), ('new classes', 1.0000365381604857), ('fuzzification', 1.0000365372710271), ('use self', 1.0000365295995566), ('replace tanh', 1.0000364953106837), ('limited sensor data', 1.0000364845959164), ('sentence pair', 1.0000364786619091), ('actual memories', 1.0000364758992157), ('cnns n', 1.0000364732594054), ('diagram question', 1.0000364712371212), ('subsequent clustering', 1.0000364687027845), ('generator consists', 1.00003646838827), ('explicit', 1.0000364541260311), ('standard deep', 1.0000364486548474), ('continuous markov', 1.0000364472442314), ('suboptimal weights', 1.000036446190872), ('different time scales', 1.0000364382604523), ('supervised setting', 1.0000364371895303), ('incorrect ones', 1.0000364305890104), ('box method', 1.0000364109568354), ('uncertain inputs', 1.0000363956830527), ('art perplexity', 1.000036390712847), ('audio visual', 1.0000363869380586), ('relaxed version', 1.0000363792894726), ('low level sensor', 1.0000363687244966), ('infer context', 1.000036361225465), ('study', 1.0000363518714168), ('strong network', 1.0000363516614341), ('dialogue policy', 1.0000363458241643), ('question generation', 1.0000363374849284), ('inform', 1.0000363250738475), ('distribute', 1.0000363225938287), ('abstractions', 1.0000363176878433), ('ensemble model', 1.000036309784011), ('synaptic cluster', 1.0000362973573897), ('present', 1.0000362913822067), ('local context', 1.0000362830578875), ('daily social', 1.000036272793653), ('network conversation', 1.0000362703654304), ('classical machine', 1.0000362658723434), ('mathematical characterization', 1.0000362564358933), ('output spikes', 1.0000362504351041), ('curved components requires', 1.0000362393695914), ('such domains', 1.0000362346859022), ('capture relevance', 1.0000362121950785), ('true end', 1.00003621089099), ('input switched', 1.0000362106301006), ('discourse framework', 1.0000362092064692), ('estimate', 1.0000362075637483), ('maximization', 1.0000361993735478), ('agent', 1.0000361894694045), ('natural language stories', 1.0000361839098453), ('mathematical framework', 1.0000361807120273), ('sparse reward signals', 1.0000361726308329), ('diagnosis capabilities', 1.0000361688500574), ('traditional classifier', 1.0000361667240727), ('self supervise', 1.0000361664880126), ('different target words', 1.0000361611096629), ('network expressivity', 1.0000361560175524), ('similar patterns', 1.0000361370413493), ('distal reward changes', 1.000036124799567), ('bringing reinforcement', 1.0000361215436326), ('cumbersome infrastructure', 1.000036108132319), ('other modalities', 1.0000361066060548), ('meaningful features', 1.0000361021880748), ('key', 1.000036100648913), ('trained sentence', 1.0000360931504804), ('end reasoning', 1.0000360852904098), ('similar accuracy', 1.0000360702901878), ('simulated experience', 1.0000360666691248), ('fast adaptation', 1.000036053367958), ('many areas', 1.000036053160637), ('several classes', 1.0000360433707127), ('scenario associated', 1.0000360368123795), ('use choose', 1.0000360344307755), ('various candidate answer', 1.000036031483731), ('semantic drifts can', 1.0000360132237252), ('detect stopping', 1.000036010589981), ('attention weights', 1.0000360022075252), ('analysis applies', 1.000035994171961), ('cumbersome substitute', 1.0000359827920742), ('extraction', 1.0000359587404875), ('numerical values', 1.0000359532872132), ('noisy labels', 1.0000359456277386), ('lvcsr speech', 1.0000359392899483), ('different subset', 1.000035935013223), ('saliency map', 1.000035925715695), ('methods work', 1.000035922796722), ('architecture evolved', 1.000035920901704), ('retaining neurons', 1.0000359148657731), ('entire environment', 1.0000358956840891), ('links', 1.000035886165396), ('biomedical literature', 1.0000358852902889), ('single parametrization', 1.000035883997624), ('prototypical sequences', 1.0000358812411343), ('academic research purposes', 1.0000358796550166), ('edges', 1.0000358515890468), ('gru design', 1.0000358468047248), ('sensorimotor concepts', 1.0000358343774396), ('configuration', 1.0000358157054807), ('intrinsic motivation curiosity', 1.0000358076248475), ('strong baselines trained', 1.0000358049760083), ('agents', 1.0000357851519819), ('line', 1.000035778469389), ('dbm', 1.0000357736704837), ('websites', 1.0000357723942868), ('extensive evaluations', 1.000035764243814), ('universal approximators', 1.0000357595396498), ('black box predictors', 1.0000357546883443), ('online stream', 1.0000357540389218), ('theorem provides', 1.0000357462724287), ('prior disambiguation', 1.0000357449584374), ('several existing', 1.0000357440206546), ('novel dialogue management', 1.0000357392957484), ('widespread applications', 1.0000357343800228), ('compelling results showing', 1.000035729059807), ('mathematical rigor', 1.0000357228560621), ('novel technique', 1.0000357204576575), ('training gp', 1.0000357179146815), ('standard gru', 1.000035713666999), ('same rescaling', 1.000035709316854), ('perturbations achieve', 1.0000357022865396), ('spikes implement', 1.000035694142478), ('different forms', 1.0000356935871875), ('approach leverages', 1.0000356922689884), ('dedicated feature', 1.0000356766261078), ('inception score', 1.0000356718868206), ('long distance correlations', 1.0000356603787506), ('asr', 1.0000356588636468), ('actions', 1.0000356505281738), ('anticipate', 1.0000356463574063), ('representation space', 1.0000356404529687), ('adult content', 1.0000356359063785), ('label entropy', 1.000035623058024), ('driver identification', 1.0000356222816928), ('vectors belonging', 1.000035621196391), ('limited transmission rate', 1.000035611528864), ('hebbian plasticity offers', 1.0000356093340834), ('remarkable margins', 1.0000355974494157), ('case study', 1.0000355893113828), ('location determined', 1.0000355857089267), ('random spiking', 1.0000355839315973), ('original one', 1.0000355763297686), ('linear combinations', 1.0000355752950423), ('optimal mutation', 1.0000355733667168), ('different scripts', 1.0000355681294228), ('human demonstrator', 1.0000355532399234), ('dense transformer modules', 1.000035551194232), ('performing cross', 1.0000355423809644), ('remote sensing imagery', 1.0000355175657827), ('descriptor', 1.000035509512493), ('speech speakers', 1.0000354955193524), ('practical interest', 1.0000354941057608), ('ask questions', 1.0000354894517522), ('largest dataset', 1.0000354821403024), ('tractable densities', 1.0000354772781082), ('new pairwise', 1.0000354595926095), ('human cognition', 1.0000354574956893), ('logical inference', 1.000035450830743), ('caption generation', 1.0000354479194549), ('models geared', 1.000035434903981), ('neural lid', 1.0000354295870288), ('dynamic neurons', 1.0000354104158184), ('use vae', 1.000035403578393), ('recalculate', 1.0000353968731892), ('account', 1.0000353929161303), ('enquirer learning', 1.0000353827818649), ('few shot', 1.0000353823323453), ('competitive multimodal embedding', 1.0000353651112246), ('copying', 1.0000353609214132), ('segmentations', 1.000035357339627), ('dissimilarity', 1.000035352214211), ('novel element', 1.0000353356190652), ('framewise classification', 1.0000353275782294), ('wide adoption', 1.0000353275692868), ('bandit task', 1.0000353215982212), ('large design', 1.0000353197327283), ('sequential screening targets', 1.0000353178097006), ('individual neurons', 1.0000353161718842), ('isolate patterns', 1.000035315646584), ('paradigm', 1.0000353103237103), ('interactive learning', 1.000035308256289), ('types', 1.0000353080055235), ('detailed cost analysis', 1.0000353019566106), ('learn underlying', 1.0000353002175149), ('strided pooling', 1.0000352990311314), ('approach named', 1.00003528531209), ('tanh activation', 1.0000352835154107), ('primary generation component', 1.0000352689046215), ('representations produced', 1.0000352675126611), ('same amount', 1.0000352616389816), ('multistep solution', 1.0000352607756515), ('several methods', 1.0000352480947112), ('database collected', 1.000035247992322), ('closed loop control', 1.000035242076569), ('effective regularizer', 1.0000352367735905), ('propagate credit', 1.0000352271561586), ('spatial inference', 1.0000352106448238), ('given test', 1.000035201223211), ('independent dynamics', 1.0000351897034379), ('final loss metric', 1.0000351874113724), ('higher accuracy', 1.000035185377868), ('technique allows', 1.0000351833020464), ('psnr', 1.0000351804612657), ('existing dnn', 1.0000351801247827), ('new test', 1.0000351746663372), ('subset', 1.0000351664245755), ('different guiding signals', 1.000035163024082), ('decode brain', 1.0000351476805343), ('achieve move', 1.0000351468535984), ('single directions defined', 1.0000351459972456), ('raw signals', 1.0000351403240617), ('end phoneme', 1.0000351354939756), ('self organized', 1.0000351191031627), ('interactive', 1.0000351118508686), ('knowledge dynamics', 1.0000351088097315), ('cognitive plausibility', 1.0000351051400949), ('regular autoencoders', 1.000035102269588), ('n variables', 1.0000351005154713), ('existing systems', 1.0000350926548431), ('torcs car', 1.00003509129072), ('identifying relationships', 1.0000350898613188), ('spectrograms state', 1.0000350825060504), ('gaussians', 1.0000350770903863), ('hyperspectral images', 1.0000350762320862), ('arbitrary firing', 1.0000350674432885), ('recurrent loop', 1.0000350633546007), ('common household chores', 1.0000350558894489), ('high attention weights', 1.0000350349899705), ('continuous flow model', 1.0000350307819048), ('powerful representations', 1.0000350299783898), ('architectural modifications', 1.000035027370374), ('existing', 1.0000350187719926), ('wide variety', 1.0000350103966795), ('global machine', 1.0000350096756638), ('principle applicable', 1.0000350066296653), ('spectral representations', 1.000035004817134), ('mnist credit card', 1.000034995605613), ('adapt', 1.000034995341957), ('label sequence', 1.00003499043146), ('google voice', 1.0000349850281391), ('interest roi', 1.000034980309962), ('different language', 1.000034979918498), ('nonstationary data', 1.0000349703710036), ('spatial relation', 1.000034966300114), ('attacker', 1.000034960027596), ('multiplicative backpropagation style', 1.0000349499945973), ('play', 1.00003494810707), ('cluster', 1.0000349229732362), ('instances', 1.0000349056061915), ('many cases', 1.0000348967372898), ('tags', 1.0000348951624238), ('global interaction', 1.0000348951359401), ('such cases curiosity', 1.000034881602911), ('universal classifier', 1.000034879442463), ('relevant tasks', 1.0000348767794716), ('traditional rl', 1.00003486859311), ('training loss', 1.0000348660053087), ('policy shaping', 1.0000348608181118), ('many classification', 1.0000348556154839), ('perform speech', 1.0000348552526352), ('concept', 1.0000348514686686), ('dsr task', 1.0000348476700642), ('max correlation', 1.0000348398478895), ('target classes', 1.000034823451408), ('model state', 1.0000348182663314), ('sequence transformation', 1.000034811025835), ('errors', 1.0000348093606852), ('value based', 1.000034796374495), ('mappings', 1.0000347923949668), ('known entities', 1.0000347675375083), ('acquire language', 1.000034760170648), ('new learning', 1.000034756305867), ('polygon', 1.0000347540730052), ('step transition', 1.0000347511625476), ('domain remains', 1.0000347450226863), ('search algorithm', 1.0000347360222315), ('text compounds', 1.00003473586434), ('possible results', 1.0000347257409874), ('classification performances', 1.000034725004001), ('professional go', 1.0000347218745904), ('simulations show', 1.0000347205966595), ('limited access', 1.0000347191243237), ('learn policies', 1.0000347180662943), ('compressed sensing', 1.0000347097224966), ('bottleneck', 1.0000347075675358), ('long', 1.0000347072174691), ('using rule', 1.0000347069187978), ('generation networks', 1.0000347027386347), ('speaker mixtures', 1.000034699633307), ('empirical loss', 1.0000346803267788), ('quality', 1.0000346787753278), ('key property', 1.0000346763078498), ('world', 1.0000346625665009), ('call', 1.000034655947048), ('video games', 1.0000346516420155), ('representations become', 1.0000346443060695), ('standard data', 1.0000346385630319), ('deeper implications', 1.0000346346950548), ('better understanding', 1.000034632244959), ('generators', 1.0000346291468418), ('manipulation', 1.0000346287654602), ('attention models', 1.0000346223257024), ('lvcsr', 1.0000346219447622), ('dqn algorithm', 1.0000346078389668), ('universal perturbations reveals', 1.0000346052849747), ('better speech', 1.0000345964042272), ('input compensating', 1.000034596245442), ('evaluation shows', 1.0000345898090826), ('representations change', 1.0000345866151967), ('extensions train', 1.0000345702333944), ('planning system', 1.0000345506331592), ('high nuisance inference', 1.0000345500733145), ('physical world', 1.00003454820702), ('popular small', 1.0000345340854744), ('take actions', 1.0000345322032616), ('traditional aco techniques', 1.0000345275481382), ('dialog act prediction', 1.0000345273646547), ('intrinsic motivation might', 1.000034527170055), ('similar cnn', 1.0000345253592455), ('high performances', 1.0000345125156769), ('other networks', 1.0000344987282355), ('gp trees', 1.0000344830363324), ('time scale', 1.0000344722507568), ('visual inspection inception', 1.0000344705822994), ('method allows', 1.0000344664029277), ('propositional', 1.0000344655376407), ('documents given', 1.0000344563398789), ('produce vectors', 1.0000344514602486), ('ilsvrc', 1.000034422686787), ('hand', 1.0000344152009417), ('predicting chemical', 1.000034406089329), ('transition based', 1.0000343993781515), ('make decision', 1.0000343886943794), ('unaligned text', 1.0000343877463205), ('calibrating existing', 1.0000343857537664), ('second dialog', 1.0000343740161695), ('feedback', 1.0000343715465505), ('research', 1.0000343651520085), ('crl', 1.0000343508960423), ('function approaching', 1.0000343486379428), ('novel applications', 1.0000343467798638), ('complex questions', 1.0000343419803122), ('causal regularizer', 1.0000343397358522), ('time evaluate', 1.0000343340678453), ('composable', 1.0000343337319397), ('whole entities', 1.0000343271184322), ('similar model', 1.0000343212059504), ('distinct clusters', 1.0000343205195672), ('spatio', 1.000034314647198), ('agent can', 1.0000343137609062), ('other hand topic', 1.0000343128839857), ('medical corpora', 1.0000343113896826), ('focus', 1.000034305754815), ('augment', 1.0000343055848882), ('layer structure', 1.0000343055381813), ('pos', 1.0000342951293955), ('small hardware', 1.0000342834882983), ('maximum margin framework', 1.0000342823696262), ('neighbor model', 1.0000342735820944), ('recurrent highway networks', 1.0000342704326), ('several dialogue domains', 1.0000342674821199), ('different parameter', 1.0000342671200726), ('noisy', 1.0000342643007751), ('devices', 1.0000342581157273), ('propositional rules', 1.000034249335539), ('vocabulary atoms', 1.0000342390986567), ('end domain', 1.0000342382613463), ('structured self', 1.0000342358770036), ('uncertain knowledge', 1.0000342299515044), ('translation involving', 1.0000342276648257), ('navigational instructions', 1.0000342238937965), ('technique can', 1.0000342015234573), ('lru', 1.0000341960256296), ('approach using', 1.0000341909747401), ('original vectors', 1.0000341899232355), ('visual attention', 1.0000341888856068), ('lossless cnns', 1.000034182119021), ('discover models', 1.0000341783159157), ('clinical domain', 1.0000341725750055), ('fitness evaluations', 1.0000341700111652), ('random action', 1.0000341589821506), ('spectral based', 1.0000341530270658), ('word pair', 1.0000341498407195), ('cognitive economy', 1.000034145562575), ('challenging tasks', 1.0000341160108155), ('story', 1.000034107836278), ('obtain segments', 1.0000341027929252), ('performance measure', 1.000034098020963), ('meta learning experiments', 1.0000340939979753), ('successive layers', 1.0000340915141148), ('simple analysis', 1.00003408808893), ('unrecognizable images', 1.000034085875177), ('level clock', 1.0000340853894603), ('storage posses', 1.000034073487142), ('spatial configuration', 1.0000340687991052), ('whole sentence', 1.0000340682839906), ('expensive softmax computation', 1.0000340662600746), ('learn delta', 1.0000340616687307), ('additional depth', 1.0000340539528512), ('downstream language understanding', 1.0000340498906115), ('cyclical learning rates', 1.0000340422657448), ('skip connection', 1.0000340291803536), ('data distribution', 1.0000340222665345), ('static neurons', 1.0000340206208045), ('continuous parameters', 1.0000340202410893), ('key factor', 1.0000340072417904), ('evolutionary strategies', 1.0000339792688222), ('find speech', 1.0000339771289413), ('topology preservation', 1.0000339752510399), ('standard nonlinearities', 1.0000339701992422), ('linear system', 1.000033967707342), ('variational', 1.0000339583600095), ('deeper layers', 1.0000339542806034), ('exploratory data', 1.000033950088374), ('different learning', 1.0000339458704546), ('poor generalization', 1.0000339297949767), ('nlg technology', 1.000033919968517), ('checking', 1.0000339118401849), ('grand challenge', 1.000033909012573), ('approach lies', 1.0000339068552762), ('produce affinity', 1.0000339059702172), ('different categories', 1.0000338972463079), ('intention network', 1.0000338911522215), ('produce spectrogram', 1.0000338662325365), ('such generalization', 1.0000338643521425), ('particular transformations', 1.000033862079317), ('raw signal', 1.0000338603169598), ('conventional models', 1.000033855809398), ('boost', 1.000033848808949), ('pose limits', 1.000033839478849), ('distance', 1.0000338383652092), ('predict based', 1.0000338275295144), ('various baseline', 1.0000338225279914), ('make progress', 1.0000338199992787), ('high level coarse', 1.000033809531705), ('testing show', 1.0000338087410992), ('similar topic', 1.0000337975873308), ('cifar10', 1.00003379230184), ('generative machine comprehension', 1.0000337842207296), ('forms used', 1.000033776049523), ('analysis results', 1.0000337605380762), ('predicting outcomes', 1.0000337596366387), ('research addresses', 1.0000337563616044), ('fpga', 1.0000337478249246), ('list questions', 1.0000337474399743), ('control spiking', 1.0000337472288168), ('common man made', 1.0000337447028524), ('filters', 1.0000337376169464), ('such wide', 1.000033725005235), ('current input', 1.0000337178235728), ('markov', 1.0000337157299837), ('silicon chips', 1.0000337112090094), ('weight', 1.0000337013798264), ('scientist performing', 1.0000336973007735), ('approach makes', 1.000033696021217), ('accelerometer signal', 1.0000336719749001), ('simulated robocup soccer', 1.0000336658234537), ('function increasing', 1.0000336631230575), ('explore sequence', 1.0000336410642794), ('spiking', 1.0000336388532125), ('basic attention', 1.0000336257960527), ('modern attempt', 1.0000336067421793), ('perform physics', 1.0000335900041604), ('moderate author set', 1.0000335833162999), ('logical deduction', 1.0000335778389504), ('handwriting recognition', 1.0000335654930517), ('layer composition', 1.0000335587803726), ('true labels', 1.0000335535197094), ('larger text constituents', 1.0000335452772078), ('factoid question', 1.0000335345929936), ('word acquisition', 1.0000335128460043), ('current methods', 1.000033487390289), ('models yield', 1.000033484614934), ('intermediate results consisting', 1.0000334840417557), ('atis dataset', 1.0000334745448403), ('regularize', 1.0000334724613533), ('formulation called', 1.0000334656288314), ('character composition', 1.0000334641447546), ('more interpretability', 1.000033461761882), ('gp based', 1.0000334614358712), ('progression property', 1.0000334608427348), ('lru model', 1.0000334505548603), ('offspring networks', 1.0000334348007984), ('expectation maximisation', 1.0000334317541757), ('common ir', 1.0000334254808427), ('discover', 1.000033418208478), ('loop setting', 1.0000334179527401), ('novel eda framework', 1.0000334173634808), ('proposed methodology', 1.0000334134073159), ('scratch', 1.000033411430527), ('case', 1.0000334072757382), ('most feature', 1.0000334049352781), ('set generalization', 1.000033381948386), ('task will', 1.0000333705958064), ('reading architecture', 1.0000333439789502), ('promising solution', 1.0000333422214134), ('severe information loss', 1.000033340610992), ('spatial templates', 1.000033323952799), ('labels', 1.0000333226217715), ('disentangled latent concepts', 1.0000333125397436), ('worlds described', 1.0000333070954517), ('visual explanations', 1.0000332920438497), ('approach applicable', 1.0000332797850517), ('arbitrary differentiable', 1.0000332649884263), ('particular target', 1.000033262160147), ('remote sensing technologies', 1.0000332466435269), ('subject identities', 1.0000332454137513), ('correctness', 1.0000332347196963), ('future research', 1.0000332293408825), ('new training procedure', 1.0000332274853967), ('hidden facts', 1.0000332250282729), ('gated end', 1.0000332123131306), ('differentiable system', 1.0000332123068967), ('determine entailment', 1.000033208922055), ('minimal parameter', 1.0000332082358607), ('spectral subtraction', 1.0000331917674299), ('openai gym', 1.0000331912498885), ('genetic encoding', 1.0000331882085758), ('medical event detection', 1.000033178151241), ('policy methods', 1.0000331773013078), ('detect shift', 1.000033175794729), ('latter case', 1.0000331643610885), ('tasks presented', 1.0000331604268013), ('negative pairs', 1.0000331495723185), ('fine aligner', 1.0000331366174848), ('flexible krylov subspace', 1.000033135059504), ('timit phoneme', 1.0000331260875168), ('central importance', 1.0000331238824993), ('earlier approach', 1.0000331100901412), ('impressive results', 1.0000331066864672), ('linear regions change', 1.0000331054438425), ('popular office', 1.0000331035790246), ('multivariate model', 1.0000331009747097), ('simple effective', 1.000033095543496), ('multiple sets', 1.000033094583874), ('reasonable dimension', 1.000033084934358), ('action sequences', 1.0000330840426641), ('shortening input', 1.0000330817128467), ('new address', 1.0000330743840322), ('captioning', 1.000033070036075), ('absorb information', 1.0000330697749713), ('bayesian approach', 1.000033066433856), ('target task', 1.0000330263348596), ('seed points', 1.00003302269782), ('intermediate levels', 1.0000330203870038), ('combination', 1.0000330172631873), ('environment affordance', 1.0000330168839149), ('requirement', 1.000033011052443), ('shift correction', 1.000033008779592), ('task provides', 1.000033006879753), ('last point', 1.0000330048993809), ('alignments', 1.000033001554197), ('sequence transduction', 1.000032999058798), ('significant amount', 1.0000329915246216), ('encourage development', 1.0000329891030706), ('model demonstrated', 1.0000329872772045), ('standard inference', 1.0000329798323178), ('established neuron', 1.0000329782308734), ('art approaches', 1.0000329686954492), ('finer fusion resolution', 1.0000329619972923), ('molecular biology show', 1.0000329578453222), ('world models', 1.0000329403946249), ('rendering mixture', 1.0000329284272704), ('outperform', 1.0000329226845799), ('stochastic variables', 1.0000329205604315), ('ancestor networks', 1.0000329139218502), ('classify sentences', 1.0000329137145954), ('combine knowledge', 1.0000329032574042), ('fact', 1.0000329029296096), ('differentiable proving', 1.0000329002733312), ('greedy', 1.0000328975069), ('translation performance', 1.0000328911255176), ('different hierarchies', 1.0000328838372519), ('gps records', 1.0000328683814128), ('geometric gan', 1.0000328611914584), ('subnetworks', 1.0000328469858122), ('consistency decreased', 1.0000328461630146), ('interest', 1.0000328397826297), ('video captioning', 1.0000328336825843), ('distance based', 1.000032831256577), ('obtain', 1.0000328297218484), ('feedback relevance', 1.0000328268277205), ('strong baselines', 1.0000328261428941), ('competitive feature', 1.0000328248303163), ('standard test', 1.0000328111192214), ('new model called', 1.0000328099101505), ('other purposes', 1.0000328085867547), ('nmt system', 1.0000327983566362), ('pairwise term', 1.000032793424433), ('empirical studies', 1.0000327763952626), ('practical video', 1.0000327604336865), ('auxiliary character', 1.000032752861204), ('integrate', 1.0000327432219684), ('convert acoustics', 1.0000327324367784), ('few assumptions', 1.0000326986697643), ('mathematical perspective', 1.000032698296161), ('compared', 1.0000326950263767), ('gathering information', 1.0000326849781633), ('highest accuracy', 1.0000326774317096), ('main advantage', 1.0000326664447203), ('class aware', 1.0000326637599395), ('scale instances', 1.0000326539733035), ('world model', 1.0000326522450471), ('analysis techniques', 1.0000326344706425), ('priors corresponding', 1.0000326315366639), ('allowed activation', 1.0000326311856276), ('question words', 1.0000326286162677), ('question encodings', 1.0000326267104487), ('meaningful regions according', 1.0000326240841788), ('nlu models', 1.0000326124105416), ('continuous stream', 1.000032603073259), ('resource', 1.0000325969854287), ('layer depth', 1.0000325914883794), ('k allows', 1.0000325772910719), ('tying weights', 1.0000325757383466), ('hemodynamic response function', 1.0000325732056063), ('cnn', 1.0000325637636331), ('most games', 1.0000325584703753), ('novel chemical properties', 1.0000325471467275), ('minimal supervision', 1.000032543583685), ('challenging', 1.000032540054493), ('intrinsic reward', 1.0000325398335659), ('target response', 1.000032535409689), ('empirical study', 1.0000325301749167), ('unseen goals', 1.0000325240295667), ('neighbourhood size', 1.0000325185895649), ('adaptive', 1.0000325167700825), ('traditional dnn', 1.0000325142434212), ('final prediction', 1.0000325017705392), ('problems scale', 1.0000325011066893), ('metaphor detection', 1.0000324998015806), ('security', 1.000032494024446), ('preliminary experiments', 1.0000324922568433), ('device', 1.0000324863240408), ('discriminative', 1.0000324846214854), ('handle changes', 1.000032460526561), ('spatial correlates including', 1.0000324563801288), ('capability', 1.00003245232643), ('parallel labels', 1.000032449414485), ('source sentences', 1.0000324491997221), ('small detector', 1.0000324477713467), ('prediction represents', 1.0000324448115991), ('key contribution', 1.000032432509101), ('recent output', 1.0000324135992134), ('textit', 1.0000324075873122), ('paired video', 1.0000324064544062), ('memristive devices', 1.0000323981453207), ('previous time', 1.0000323830323383), ('spectrograms', 1.00003238127379), ('dynamics', 1.000032363155175), ('manual labeling', 1.0000323628920973), ('weight decay', 1.0000323561302675), ('successful learning', 1.0000323549425745), ('expanded representations', 1.0000323547707926), ('effective designs', 1.0000323485583043), ('learning dialogue', 1.0000323426267204), ('methodology', 1.0000323412843333), ('scale', 1.0000323380716885), ('given corpus', 1.0000323202627504), ('filter', 1.0000323197295387), ('multiple solution mechanisms', 1.0000323193468446), ('international conferences', 1.0000323126602373), ('frame labels', 1.0000323109876739), ('basis', 1.0000323061722098), ('interpretability', 1.000032290532027), ('additional parameters', 1.000032286584856), ('document classification', 1.0000322835719868), ('image caption', 1.0000322813705087), ('key phrase', 1.0000322700068147), ('adapted dnn', 1.0000322690691743), ('analysis comparing', 1.0000322615464257), ('most', 1.0000322559648263), ('matrix', 1.0000322435047764), ('pcg techniques', 1.000032242223326), ('brain based', 1.0000322223917357), ('engineering applications', 1.0000322028454947), ('response properties', 1.0000322006308902), ('minimal interruption', 1.000032193544466), ('end approach', 1.0000321914970816), ('manipulations', 1.000032188997534), ('new terms addition', 1.000032178630311), ('hierarchical priors', 1.0000321752276078), ('french treebank', 1.0000321657523135), ('learned exploration', 1.0000321631109372), ('dialogue domain', 1.0000321612999268), ('fewer assumptions', 1.000032154866525), ('separate signals', 1.0000321518193753), ('pre training environment', 1.000032131483216), ('feature costs', 1.0000321261303813), ('successor', 1.000032126031653), ('fundamental building', 1.0000321209813592), ('pipelines', 1.0000321180177039), ('phoneme conversion', 1.0000321167028745), ('categorical cross', 1.0000321065826225), ('controllers', 1.0000321057029251), ('next response', 1.0000320974892194), ('dnns placed', 1.000032097399209), ('exhibit phenomena', 1.0000320875438893), ('discourse semantics', 1.0000320855271523), ('approximate steepest', 1.0000320680210877), ('sample creation', 1.0000320652517587), ('simple classification', 1.000032063969562), ('regression', 1.0000320525389184), ('training code', 1.0000320515115166), ('latency suggested', 1.0000320467638428), ('other settings', 1.0000320449221027), ('human annotated', 1.0000320290779499), ('network reservoirs', 1.000032020307355), ('domain shift', 1.0000320197879884), ('neural reordering', 1.0000320171289738), ('extension', 1.00003200996552), ('highest identification', 1.0000320096084125), ('single label', 1.0000320071534383), ('reward predictor', 1.0000320060393506), ('deep learning textit', 1.0000319980526038), ('learning evaluation', 1.0000319943818676), ('seq2seq model', 1.0000319931508526), ('batch', 1.0000319912918951), ('sufficient conditions', 1.0000319888999658), ('circular fingerprints', 1.0000319870189065), ('generation message', 1.0000319837864062), ('fewer training views', 1.000031982837902), ('recommend fashion', 1.0000319726772688), ('such system yields', 1.000031950339217), ('spike domain', 1.0000319413696586), ('incoming', 1.0000319409204392), ('art classification', 1.0000319399833313), ('ctc loss', 1.0000319109006799), ('use intelligence', 1.0000319108536935), ('target label', 1.0000319022110236), ('modelling', 1.0000319017677461), ('segmental crf', 1.000031899196195), ('brain', 1.0000318949935676), ('clinical data sets', 1.0000318937856967), ('model distribution', 1.0000318899026606), ('open domain factoid', 1.000031883990765), ('experimental analysis', 1.0000318793917164), ('measure task', 1.0000318749976547), ('unpaired output data', 1.0000318734525766), ('predictive accuracy', 1.0000318718889356), ('multiplicative connections', 1.000031867414465), ('twitter', 1.000031863307259), ('explicit background', 1.0000318618150104), ('simulated robocup', 1.0000318493562106), ('sleeping newborns', 1.0000318437549744), ('proper conditioning can', 1.000031841026333), ('lower level', 1.0000318360926947), ('analysing results', 1.000031835855881), ('seq2seq models', 1.0000318165515503), ('humans learn', 1.0000318089414266), ('such similarities', 1.0000318054400146), ('sentences', 1.0000317859969374), ('vector sequence', 1.0000317771090548), ('raw laser measurements', 1.0000317767744993), ('pipeline', 1.0000317740044156), ('accuracy making', 1.0000317734719766), ('individual entities', 1.0000317698417702), ('models generalize', 1.0000317594398853), ('medical paper abstracts', 1.0000317525727238), ('traffic flow', 1.0000317525115185), ('key sequence motifs', 1.0000317514421093), ('object relation', 1.0000317419513296), ('previous task', 1.0000317388370854), ('driving style', 1.000031735479812), ('express changes', 1.0000317329131665), ('accuracy achieved', 1.0000317270914305), ('parameter', 1.0000317253168733), ('different policy', 1.0000317126972604), ('overcomplete dictionary', 1.000031710489898), ('ubiquitous computing', 1.0000317080724126), ('language speech', 1.0000317064848228), ('digital form', 1.000031704702056), ('low', 1.0000316869094308), ('data distributions', 1.0000316814764423), ('traditional nonparametric', 1.000031677515717), ('new statistical', 1.0000316769301905), ('loss correction', 1.0000316709131345), ('functional', 1.0000316703923013), ('novel combination', 1.0000316665322395), ('hierarchical fashion explaining', 1.0000316613000972), ('unknown amount leverage', 1.000031647416441), ('log linear', 1.0000316438459194), ('videos', 1.0000316393176478), ('individual weights increase', 1.0000316305122192), ('background knowledge', 1.0000316248527792), ('holistic architectures', 1.0000316190069143), ('major shortcoming', 1.000031618833458), ('box pushing', 1.000031611710649), ('target examples', 1.000031609073108), ('unlabeled speech', 1.0000316064711607), ('make recommendation', 1.000031593023768), ('perplexity', 1.0000315916194953), ('viable alternative', 1.0000315871557963), ('individual agents', 1.0000315859978455), ('experiments conducted', 1.000031585407755), ('accuracy demands', 1.0000315829870432), ('response generator', 1.0000315680646508), ('fine alignment', 1.000031559256793), ('overlapped region', 1.0000315578399164), ('slow learning', 1.000031557297015), ('main contributions', 1.0000315521744048), ('same subject', 1.0000315477083412), ('collaborative recurrent', 1.0000315300273506), ('behavior', 1.0000315269676574), ('traditional heart rate', 1.000031525648226), ('sampling', 1.0000315245047453), ('versatile cmos', 1.000031510193776), ('very deep', 1.0000315028432911), ('same classes', 1.000031497685837), ('primitives', 1.0000314803473922), ('new mdps', 1.0000314783251045), ('eigendecompositions', 1.0000314750974297), ('sensory motor interactions', 1.0000314645425776), ('estimate fitness', 1.0000314410743532), ('ehr databases', 1.000031440316208), ('entailment failed', 1.0000314358158235), ('perceptual inference', 1.0000314346985264), ('online sparsification', 1.0000314340257215), ('leg malfunction', 1.000031420847402), ('interpretable testbed', 1.000031419801943), ('patient', 1.000031413449654), ('nonparametric density estimator', 1.0000314100039625), ('abstraction', 1.0000314077479806), ('gp', 1.0000313960171676), ('potential shortcoming', 1.0000313577497664), ('specific combination', 1.0000313556611449), ('questions', 1.0000313401570922), ('direct language acquisition', 1.0000313370235279), ('regular deconvolution', 1.0000313352461454), ('flexible krylov', 1.000031334930848), ('higher dimensional', 1.0000313328543118), ('probability model', 1.0000313212995744), ('synthesizing transformed', 1.0000313190390542), ('abstract', 1.0000313124993327), ('simple representation', 1.0000313082916172), ('progress made', 1.0000313042588982), ('quadratic forms', 1.0000313035876005), ('noticeable accuracy', 1.0000313008746253), ('many examples', 1.000031300291338), ('scheme', 1.0000312975088848), ('network unraveling', 1.000031292019862), ('dropout extends', 1.000031284807498), ('generating dialogues', 1.0000312789408496), ('model construction', 1.000031277914411), ('temporal motion', 1.0000312740799342), ('specific goal', 1.0000312706468837), ('gan data', 1.0000312625306038), ('feed', 1.0000312602494075), ('dense prediction view', 1.000031259931551), ('target behavior', 1.000031241694025), ('mimic heredity', 1.000031238849066), ('modules', 1.0000312349710656), ('effective way', 1.000031231855868), ('identifying properties', 1.0000312204320465), ('variational objective', 1.0000312197995627), ('prediction time', 1.0000312195214438), ('predict gene', 1.0000312185817581), ('mitigate', 1.000031211403184), ('little error', 1.0000312038581536), ('effective', 1.0000312008241508), ('adaptation data', 1.000031191738905), ('specific prediction', 1.00003119004517), ('spatial', 1.000031189741233), ('several lvcsr', 1.0000311844420549), ('huge variety', 1.000031181192363), ('common cnn operations', 1.0000311782382492), ('existing models', 1.0000311626157465), ('move predictors', 1.0000311586300248), ('estimating fitness', 1.000031158441489), ('community question', 1.0000311567406748), ('noticeable accuracy loss', 1.0000311552067946), ('model involving', 1.0000311527782357), ('various', 1.0000311467231675), ('wide cnns', 1.0000311449431425), ('rich structures', 1.0000311437803189), ('phone ctc', 1.0000311379101383), ('identification', 1.0000311290393387), ('particular clear', 1.0000311247116913), ('randomization', 1.000031124106871), ('competitive character', 1.0000311226568466), ('artifacts', 1.0000311203526118), ('mimic', 1.0000311127436745), ('evolutionary compression', 1.0000311082174642), ('acquire', 1.00003110099887), ('glm based', 1.0000310979834517), ('alternative definitions', 1.0000310945638333), ('crucial problems', 1.000031094444127), ('speech sounds', 1.000031088791677), ('train state', 1.0000310886728607), ('retrieval', 1.0000310868220479), ('abstract reasoning', 1.0000310838529312), ('sequential screening', 1.0000310831988826), ('regulatory processes', 1.0000310704766249), ('weak', 1.0000310634525031), ('rl machines', 1.0000310543059279), ('various relation', 1.0000310479826133), ('spike based', 1.0000310465956725), ('foveal image sampling', 1.0000310365998737), ('nlg evaluation', 1.0000310346640404), ('general affine', 1.0000310338270626), ('dialogue manager', 1.0000310300932211), ('conditional loss', 1.000031008838684), ('words conditioned', 1.0000310057865134), ('multiple policies', 1.0000310039917906), ('end ctc', 1.0000310036676872), ('mixture approaches', 1.0000309956447644), ('same script', 1.0000309719650098), ('joint sequence', 1.0000309699139016), ('more general', 1.0000309687313964), ('assigned thinking', 1.0000309614788363), ('f measure', 1.0000309586251768), ('vector space', 1.0000309573801676), ('date rely', 1.0000309512272572), ('continual', 1.000030942666405), ('shallow architectures', 1.0000309413906496), ('model reached', 1.0000309405942946), ('n step', 1.0000309332967052), ('simple', 1.000030932585558), ('iss will', 1.000030925621862), ('weaker domain', 1.0000309212578065), ('micro', 1.0000309178504643), ('basic ideas', 1.0000309080635397), ('use state', 1.0000309057738563), ('key transformation', 1.0000308924995134), ('transition functions', 1.0000308920778989), ('scarce experience', 1.0000308893548804), ('constraint imposing', 1.0000308872518722), ('interesting question', 1.0000308858889304), ('exploit biases', 1.0000308833385645), ('end space', 1.0000308832234945), ('hamming loss', 1.0000308734973336), ('handle', 1.0000308724022624), ('modern dnns', 1.0000308700465355), ('action', 1.0000308662204669), ('o nlogn', 1.0000308486331153), ('perform saliency', 1.0000308415368924), ('direct links', 1.0000308226065695), ('linear form', 1.0000308159097566), ('lower robustness', 1.0000308133258828), ('wrong classification', 1.000030810252721), ('puzzle', 1.000030805214886), ('popularity', 1.000030797527576), ('weighted sampling', 1.000030794169509), ('explicit relationships', 1.0000307903464039), ('selection mechanism', 1.0000307809869824), ('sensible', 1.0000307804231614), ('architectures exhibit', 1.0000307730149607), ('massive label noise', 1.0000307692050334), ('existing work', 1.0000307680981348), ('popular used semeval', 1.000030763183877), ('using physics', 1.0000307594515065), ('sub goal detector', 1.000030747725455), ('learned patterns', 1.0000307434942166), ('many sources', 1.0000307412133789), ('technical program', 1.0000307350702549), ('texts', 1.0000307302177762), ('evaluation campaigns', 1.0000307287431514), ('standard dropout method', 1.000030724756287), ('simultaneous tactile', 1.0000307140955687), ('error term', 1.0000307029232924), ('argument reconstruction', 1.0000307000267585), ('static frame', 1.0000306861847714), ('train agents', 1.000030675844259), ('sequence classification', 1.0000306751736334), ('perturbation', 1.0000306476695702), ('sequential screening methods', 1.0000306380169806), ('particular feedback', 1.0000306369501828), ('select', 1.0000306360265931), ('multi microphone', 1.0000306316725893), ('neuronal spike initiation', 1.000030629984654), ('test targets', 1.0000306295603931), ('classification rate', 1.0000306217496548), ('trust gates', 1.0000306083830726), ('switchboard corpus', 1.0000305959412121), ('geometric sense', 1.0000305926210296), ('conversation model', 1.0000305920411943), ('tests performed', 1.000030591855318), ('extension set', 1.0000305901292728), ('clusterings', 1.0000305880055818), ('analog form', 1.0000305730113594), ('imbalanced data', 1.0000305725066374), ('different arm', 1.0000305559654754), ('individual', 1.0000305526353785), ('extension reaches', 1.0000305489221932), ('performance surpassed', 1.000030543484022), ('tiny ssd', 1.0000305426132685), ('position information', 1.0000305400268354), ('new design', 1.0000305361535138), ('incomplete knowledge', 1.0000305341057718), ('rprop', 1.000030532099619), ('important challenges', 1.0000305259107198), ('step supervision', 1.0000304906833544), ('high noise levels', 1.0000304611785462), ('unified perspective', 1.0000304543469867), ('different dropping', 1.0000304493424697), ('continuous relaxation', 1.0000304431719287), ('meaningful perturbation', 1.0000304323880227), ('human gestures', 1.0000304157125322), ('bidirectional lstm bilstm', 1.0000304090560428), ('group', 1.000030406309451), ('arguments will', 1.0000303982870198), ('low number', 1.0000303918600735), ('equilibrium distribution', 1.000030385004184), ('restaurant search', 1.0000303808080488), ('enhancement', 1.000030360589654), ('specific aspect', 1.000030359656923), ('primary generation', 1.0000303572745521), ('attention sum', 1.0000303571120366), ('functions can', 1.0000303566837936), ('designer', 1.0000303555217986), ('noisy conditions', 1.000030354003394), ('attack', 1.0000303503981025), ('probabilistic estimation', 1.000030337253656), ('unified ncr', 1.0000303286252932), ('additional information', 1.0000303277360971), ('credit assignment', 1.000030325230141), ('multi sensor', 1.0000303231074252), ('network produces', 1.0000303206362575), ('tnet', 1.0000303130722972), ('increase accuracy', 1.0000303111388076), ('transducer performs', 1.000030308671833), ('abstract e', 1.0000303062163418), ('identifiers', 1.000030304145468), ('interaction', 1.0000302775768626), ('high multiplicity', 1.000030258107916), ('generated offspring', 1.0000302577624798), ('automatic', 1.0000302549114977), ('condition selector', 1.0000302439663202), ('main challenges', 1.000030223082602), ('english conversational', 1.0000302163352954), ('technique enables', 1.0000302047519678), ('reliable evaluation', 1.00003020275138), ('computational intelligence', 1.0000301962297649), ('realm', 1.000030193201558), ('more training', 1.0000301901650934), ('event representations', 1.000030177500383), ('neighbor', 1.0000301751117324), ('continuous vector', 1.0000301736764199), ('cognitive science suggesting', 1.0000301689523692), ('overcomplete', 1.0000301648642482), ('principled route', 1.0000301606509883), ('architecture shows', 1.0000301601786616), ('math', 1.0000301526365505), ('black drops', 1.0000301424745162), ('objection detection', 1.000030142384638), ('hill task', 1.000030141018261), ('historical satellite images', 1.0000301373903124), ('group actions', 1.0000301201052475), ('low signal', 1.0000301183827223), ('particular feature', 1.0000301161088097), ('siamese discriminators', 1.0000301022206597), ('deep layers', 1.0000300971811371), ('handwritten', 1.0000300935750355), ('active interaction', 1.0000300855735222), ('promising concept', 1.0000300764246346), ('batch based', 1.0000300653010699), ('factor', 1.000030058760722), ('previous model', 1.000030058734683), ('noisy environments', 1.0000300532951756), ('visual grouping', 1.0000300513171398), ('synaptic clusters', 1.000030042152457), ('method perturb', 1.0000300392725012), ('enforce sparseness', 1.0000300241582203), ('detect polarity', 1.0000300195109557), ('top', 1.0000300043267007), ('several ways', 1.0000300001161764), ('acceptability', 1.0000299875125913), ('parameter estimates', 1.000029977584173), ('domains including', 1.0000299763707454), ('knowledgebase completion', 1.0000299762198526), ('disparate label spaces', 1.0000299727531325), ('measure', 1.000029969556752), ('robust policies', 1.0000299438619809), ('trainable weights', 1.000029943292327), ('art qa', 1.0000299429050998), ('network loses', 1.0000299429049846), ('challenges ranging', 1.0000299346789967), ('second one', 1.0000299336961587), ('sensible initialization', 1.0000299319138466), ('date', 1.0000299318813741), ('pairwise', 1.0000299302483853), ('internal state', 1.0000299291122348), ('principled criteria', 1.0000299276398639), ('reward weights', 1.0000299226051967), ('soft way using', 1.0000299163710056), ('continuous states', 1.0000299148837535), ('phones', 1.000029910217763), ('behavioral time', 1.0000299028380355), ('ensemble level named', 1.000029898162304), ('new ones', 1.0000298953295532), ('top5 accuracy', 1.000029892422576), ('limited contexts', 1.000029885670782), ('cardiac dynamics modified', 1.0000298837021833), ('techniques require', 1.0000298828936032), ('segment regions', 1.0000298819021274), ('non relevant', 1.0000298800961558), ('techniques', 1.0000298756070083), ('predict argument', 1.0000298748838863), ('inductive', 1.000029869200281), ('trainable goal', 1.0000298680724256), ('recommendation', 1.000029862933031), ('residual networks vary', 1.0000298595908361), ('morphological', 1.0000298578883282), ('perturbed images', 1.0000298532089655), ('giving accounts', 1.0000298514968593), ('retrain learning', 1.0000298456368144), ('transducer works', 1.0000298412712114), ('given transfer', 1.0000298411663158), ('statistical test', 1.000029836397317), ('ann weights', 1.0000298353146466), ('humans can', 1.000029834152741), ('local state changes', 1.000029830727013), ('few training', 1.000029823301824), ('common approaches', 1.0000298213610002), ('human subjects', 1.00002980897362), ('infinity', 1.0000298058759247), ('seen concepts', 1.000029799250098), ('sample quality', 1.0000297973392358), ('marginal likelihood', 1.0000297632074773), ('fly learning', 1.0000297519552526), ('hand tuned', 1.0000297452726525), ('log', 1.0000297429372795), ('word grouping', 1.0000297366189554), ('classification benchmarks', 1.0000297342168836), ('added efficiency', 1.000029731113139), ('metrics', 1.0000297252554986), ('novel explanation method', 1.000029723460122), ('estimate properties', 1.0000297164952776), ('various tweet', 1.0000297109761904), ('dynamic', 1.000029704168064), ('conclusive performance hierarchy', 1.0000297039834607), ('single probability', 1.0000297004582506), ('implicit learning', 1.0000296969493565), ('structured noise', 1.000029691685109), ('hybrid recommender', 1.0000296912196418), ('caption syntax', 1.00002967912856), ('key characteristics', 1.0000296765118037), ('key step', 1.000029673457498), ('alternate classifiers', 1.0000296706537615), ('end nmts', 1.0000296704475682), ('second order', 1.0000296659962655), ('sequential sentence', 1.0000296507164292), ('related domains', 1.0000296505432877), ('mr images', 1.000029645470432), ('training video', 1.0000296451274933), ('general test', 1.0000296437793095), ('substantial margin', 1.0000296432085845), ('maximum margin', 1.0000296339141426), ('planner', 1.000029632067239), ('generated molecules', 1.0000296242361593), ('models called', 1.0000296010621943), ('drawback', 1.0000295920557727), ('common set', 1.00002958646669), ('pso', 1.0000295740598577), ('experts', 1.0000295728474107), ('high level discourse', 1.0000295712103209), ('answer sentence', 1.0000295710811564), ('analysis leads', 1.0000295601412497), ('stochastic memoizers', 1.0000295535856472), ('transformation', 1.0000295436447821), ('reconstruction pipeline', 1.0000295336585137), ('quantitative results', 1.0000295325228012), ('main idea', 1.0000295311387328), ('standard classification', 1.0000295287825862), ('vector dimension', 1.0000295277552262), ('given time', 1.000029526311143), ('standard training', 1.0000295246649686), ('minimal orbits', 1.0000295038501752), ('different focuses', 1.000029501320502), ('geometry', 1.0000294998232861), ('locate', 1.0000294949475717), ('adjacent layers', 1.0000294892334045), ('larger sets', 1.0000294880344425), ('compact representation', 1.0000294825570577), ('streams', 1.0000294818740174), ('limited sensor', 1.0000294804067795), ('pruning', 1.0000294732693387), ('requirements', 1.0000294633647313), ('disambiguate', 1.0000294516179429), ('maximum control', 1.000029449576139), ('give answers', 1.000029447701872), ('variant', 1.0000294421802192), ('flexible goal', 1.0000294252358033), ('cdm approach', 1.0000294154121665), ('small scale', 1.000029409916314), ('approach showing', 1.0000294073266194), ('practical reach', 1.0000294068953532), ('multi condition', 1.0000294058850452), ('networks dqn', 1.0000294011520712), ('large state spaces', 1.0000293991707856), ('event realizations', 1.0000293983959063), ('factors associated', 1.0000293836735226), ('such representation', 1.0000293829256772), ('sequences', 1.0000293760442749), ('model adaptation', 1.000029375325649), ('driver', 1.000029373114174), ('planning module', 1.0000293723483988), ('satellite images', 1.0000293668909002), ('detailed cost', 1.0000293606723971), ('adaptation efficiency', 1.0000293526021418), ('phoneme sequence', 1.0000293487931957), ('deep r', 1.000029345971083), ('feedback negative', 1.0000293410523093), ('pose', 1.0000293282875563), ('fundamental capability', 1.0000293150523913), ('realistic scenes', 1.0000293149216501), ('accuracy compared', 1.0000293116499501), ('stimulation avoidance', 1.0000293115869079), ('tighter rank', 1.0000293006427328), ('dnn loss', 1.0000292916166538), ('dbn', 1.0000292784858291), ('self', 1.0000292784158793), ('lateral shortcut', 1.0000292730076479), ('low precision weights', 1.0000292715943242), ('misclassification loss', 1.0000292657992909), ('investigate strategies', 1.000029265190617), ('recent qa', 1.0000292641946666), ('submodular diversity functions', 1.000029252809941), ('attentive inference', 1.0000292453765323), ('competing template', 1.0000292397674149), ('face interaction', 1.0000292388430192), ('roles defined', 1.0000292377358881), ('scalar units', 1.0000292365190744), ('real numbers', 1.0000292312392407), ('residual propagation', 1.0000292243017894), ('largest skeleton datasets', 1.000029223972935), ('boltzmann', 1.0000292232754147), ('many such', 1.0000292202588077), ('dissimilarity kernel', 1.0000292181665462), ('other existing', 1.0000292066823666), ('combinatorial games', 1.0000292005469809), ('orthogonal networks', 1.0000291992349954), ('prior', 1.0000291964756844), ('clinical text', 1.000029183064273), ('novel strategy', 1.0000291800864194), ('other approaches circnn', 1.0000291754069188), ('new wikipedia', 1.0000291659543952), ('higher ratio', 1.0000291649670778), ('sequences e', 1.000029158847805), ('downstream language', 1.0000291415823659), ('patterns suggest', 1.0000291408347843), ('test language', 1.000029134822999), ('rl', 1.0000291344358512), ('important challenge', 1.0000291337874907), ('complex learning', 1.0000291335576184), ('conventional nmt systems', 1.0000291321018062), ('collaborative drawing', 1.0000291269256092), ('deriving sentence', 1.0000291177950675), ('interpretation appears', 1.00002910777692), ('end sequence', 1.0000291010531526), ('activations hurts', 1.0000290983842652), ('hard segment', 1.0000290885999754), ('crucial design', 1.0000290838204644), ('unseen objects e', 1.000029082338991), ('human judgments', 1.0000290769654214), ('dnns label', 1.0000290716339506), ('large scale side', 1.0000290584813578), ('motion plays', 1.0000290580522166), ('various re', 1.0000290577254891), ('comprehension', 1.0000290540397658), ('mlp', 1.0000290464134864), ('address today', 1.0000290462643773), ('meta', 1.0000290339386633), ('conventional classifiers', 1.0000290332753472), ('differing length', 1.000029023636806), ('large scale question', 1.0000290198909207), ('translational invariance', 1.000029013722385), ('preliminary examples', 1.0000290133372665), ('digital age', 1.0000290032613535), ('conditioning sequence', 1.0000289940192093), ('meaningful distributions', 1.000028989790727), ('learn correlated', 1.0000289824108723), ('large inaccuracies', 1.0000289815884205), ('rescaling', 1.0000289803126212), ('hybrid hidden', 1.0000289802705202), ('previous models', 1.0000289793201476), ('raw face', 1.0000289788673458), ('film layers', 1.0000289785216523), ('implicit discourse relation', 1.0000289722894136), ('similar techniques', 1.0000289716593913), ('larger class', 1.0000289705721288), ('classical registration approaches', 1.0000289644896114), ('synthesis unit', 1.0000289642406688), ('semisupervised approach', 1.0000289638402224), ('polyphonic music generation', 1.0000289564485831), ('small sets', 1.0000289530274864), ('memories', 1.0000289506493352), ('distributional patterns', 1.000028947347203), ('approach produces', 1.0000289363671364), ('pretraining', 1.0000289362655843), ('define', 1.0000289320507678), ('confidence scores', 1.000028930343239), ('last insensitivity', 1.0000289199454095), ('visual gmm', 1.0000289188778926), ('coherent sentence', 1.0000289173654433), ('pretrained word', 1.000028914907522), ('automatic model design', 1.0000289143960859), ('third feed', 1.0000289065658963), ('novel backward', 1.000028899576474), ('solutions based', 1.0000288983274332), ('image depicting', 1.0000288975868605), ('art dependency', 1.0000288765317615), ('inverse', 1.0000288675422324), ('tool', 1.0000288670271382), ('iii database', 1.000028860379731), ('unseen falls', 1.0000288544445406), ('platform', 1.0000288531936194), ('start states', 1.0000288465104943), ('diverse applications', 1.0000288396896757), ('spiking domain', 1.000028828883083), ('underlying structure', 1.0000288228357324), ('inverse dynamics', 1.0000288174136553), ('forgy s', 1.0000288140331426), ('many difficult', 1.0000288022096795), ('metric called', 1.0000287932896583), ('decision explanation', 1.0000287911178727), ('central pattern', 1.0000287908965888), ('new situations', 1.0000287835632744), ('mean vectors', 1.0000287736482465), ('q values', 1.0000287731331838), ('descriptions', 1.000028771242), ('evaluation time', 1.0000287710992228), ('standard rprop', 1.0000287649937576), ('seq2seq system', 1.000028764923923), ('complete', 1.0000287620835355), ('understanding dqns', 1.0000287446689924), ('textual story corpora', 1.0000287443805906), ('nonlinearity depth', 1.000028737267426), ('estimation', 1.000028734456262), ('sufficient quality', 1.0000287289196188), ('improve adaptation', 1.000028721040946), ('existing pcg', 1.0000287201311655), ('novel setup', 1.0000287092696474), ('other languages', 1.0000287087992876), ('gibbs sampling', 1.0000287000753447), ('reach', 1.00002869900427), ('standard knowledge distillation', 1.0000286950585249), ('author provided', 1.0000286812265828), ('navigation tasks', 1.0000286784621306), ('dropout method', 1.0000286718222766), ('understand phenomena', 1.0000286715987108), ('inoperative programs', 1.0000286617091383), ('approach requires', 1.0000286596547456), ('new models', 1.0000286595166852), ('model tackles', 1.0000286545971357), ('visual modalities', 1.0000286530462514), ('neuro gesture', 1.000028649406066), ('work focuses', 1.0000286471592326), ('reverb challenge', 1.0000286287754858), ('additive perturbations', 1.0000286185698735), ('latent intention', 1.0000286180203672), ('medical translator', 1.0000286148389073), ('autonomous development', 1.0000285957023338), ('nonparametric density', 1.000028593381281), ('industrial applications', 1.00002859110204), ('entailment', 1.0000285897931829), ('larger scale', 1.0000285885269298), ('spatial roles', 1.0000285629127033), ('environment state', 1.000028555107762), ('step', 1.0000285518066623), ('long term memories', 1.000028547920546), ('large entailment', 1.0000285460835752), ('adult neurogenesis', 1.0000285357495795), ('essential properties', 1.0000285304973997), ('ladder networks', 1.000028527642904), ('energy landscape', 1.00002851578897), ('hierarchy', 1.0000285020877457), ('results employing', 1.0000284988754624), ('only difference', 1.0000284942701667), ('medical', 1.000028481998051), ('solutions', 1.000028478267592), ('attention ground', 1.00002847630465), ('insufficient exploration', 1.000028470254221), ('large amount', 1.0000284639766253), ('training methods', 1.0000284589931694), ('distant speech', 1.0000284522438696), ('model generalizes', 1.0000284477024992), ('nonparametric regression', 1.0000284403303783), ('visual modality', 1.0000284227745442), ('extract relations', 1.0000284209492445), ('thresholding approach', 1.0000284203508243), ('interpret', 1.0000284142249547), ('robotic arm', 1.000028412956494), ('distinct classes', 1.000028412387032), ('gestures using', 1.0000284120216745), ('limited amount', 1.0000284071234191), ('interesting differences', 1.0000284042270997), ('optimal trading', 1.0000283974085804), ('capacity control', 1.0000283926947577), ('youtube videos', 1.000028391690022), ('character prediction', 1.0000283899742655), ('signal', 1.0000283744853053), ('recognizing dogs', 1.0000283702279813), ('replace', 1.0000283640346388), ('conditional probabilities varies', 1.0000283629729623), ('covariance', 1.000028359941734), ('magnitude', 1.0000283511885844), ('soft attention weights', 1.0000283507530727), ('vqa', 1.0000283476440832), ('new type', 1.0000283444918288), ('stochastic dnn', 1.000028331359493), ('normalize', 1.0000283217017545), ('restrict', 1.0000283172719688), ('pre', 1.0000283172430269), ('initial attempt', 1.00002831578707), ('integer', 1.0000283043156961), ('existing songs', 1.0000282949037285), ('holistic processing', 1.0000282900783544), ('solvation', 1.0000282880707467), ('simulated experiments', 1.0000282863293606), ('legged locomotion', 1.0000282766192492), ('beam', 1.0000282659584028), ('static corpora', 1.0000282600818895), ('extract bottleneck', 1.0000282556191302), ('spatial locations', 1.0000282495076065), ('inductive biases', 1.0000282460620815), ('several classification', 1.0000282426632603), ('approaches inspired', 1.0000282295076193), ('tied weight', 1.000028216447668), ('contrastive biclusters', 1.0000282081802903), ('disjoint', 1.0000281979166266), ('baseline', 1.0000281915964888), ('social media', 1.0000281900016346), ('overcomplete kernel dictionaries', 1.0000281854028685), ('full precision weights', 1.0000281769296795), ('arbitrary cnn', 1.0000281753127036), ('variant can', 1.0000281751742486), ('neurons activation', 1.0000281737101828), ('madlibs task', 1.0000281725147082), ('composition operations', 1.0000281723133626), ('recent years hints', 1.000028168073605), ('many disciplines e', 1.0000281411816148), ('only world question', 1.0000281325231237), ('large sets', 1.0000281318863558), ('decomposition', 1.000028129235563), ('continuous structures', 1.0000281220638318), ('larger corpus', 1.000028108641124), ('bayesian treatment', 1.0000281005074747), ('pop cd', 1.0000280991498431), ('spectral clustering parcellation', 1.0000280950679252), ('subcomponents', 1.0000280816315756), ('existing transfer', 1.0000280688321406), ('nmt architecture', 1.000028061208439), ('new domains', 1.0000280608195662), ('present work', 1.000028059468105), ('tool use', 1.0000280568085635), ('diffusion weighted', 1.0000280547156108), ('structural element', 1.0000280533443202), ('multi speaker', 1.000028051060984), ('fooling classification', 1.0000280509716264), ('extrinsic evaluations', 1.0000280488856368), ('vast amount', 1.0000280415187621), ('art performances', 1.0000280369101435), ('lidm shows', 1.0000280282757636), ('dnns continues', 1.000028020917102), ('negligible accuracy loss', 1.000028017958271), ('art approximate', 1.0000280157958008), ('top layers', 1.0000280087313944), ('cross', 1.000028003296523), ('short utterances', 1.0000280022926324), ('abundant training data', 1.0000279996993928), ('high impact', 1.0000279983278444), ('novel interpretation', 1.000027993078951), ('automatic training', 1.000027980701307), ('performing experiments', 1.000027975787711), ('limitations', 1.00002797559642), ('realistic', 1.0000279703778054), ('image qa', 1.0000279642794239), ('automatic population', 1.0000279582347322), ('various weather', 1.0000279553576306), ('physiological heuristics', 1.000027955012284), ('multilingual training', 1.0000279534162737), ('single left', 1.0000279485005408), ('brief survey', 1.0000279326735304), ('hindsight experience', 1.0000279266344683), ('outperforms', 1.000027922466246), ('instance presented', 1.0000279205060576), ('spatial relations', 1.0000279103341823), ('multi hop reasoning', 1.0000279039827182), ('network adaptation', 1.00002790176545), ('bahdanau et', 1.0000278990202247), ('original teacher model', 1.000027893488158), ('same hidden', 1.0000278922859474), ('varying relevance', 1.0000278917257823), ('population based', 1.0000278852292852), ('augmentations', 1.0000278829661253), ('sub', 1.0000278819527728), ('such knowledge', 1.0000278809670875), ('grammar', 1.0000278680214383), ('great challenge', 1.000027859158963), ('other efficiency enhancement', 1.0000278544208863), ('prior assumptions', 1.0000278543976535), ('infer rewards', 1.000027847249889), ('reduction', 1.0000278335093271), ('flawed assumptions', 1.0000278309225268), ('actual output', 1.000027829428672), ('deep compositional', 1.0000278196521506), ('construct', 1.0000278146694297), ('additional supervision', 1.0000277969236193), ('primitive based', 1.0000277895991516), ('novel evolutionary', 1.000027783984627), ('variable term mass', 1.0000277825038857), ('distribution shift', 1.000027780040888), ('predict chemical', 1.0000277777859485), ('mnist credit', 1.0000277692531387), ('evolutionary approach', 1.0000277643920006), ('framewise classification offers', 1.000027762373949), ('unknown', 1.0000277610271355), ('lipschitz coefficient', 1.0000277609252075), ('vector field', 1.0000277571246052), ('seq2seq', 1.0000277506727573), ('game development', 1.000027747442198), ('alexnet structure regularization', 1.0000277393601122), ('generalize desired', 1.0000277373811646), ('high order', 1.0000277340244015), ('vice', 1.0000277335076737), ('performance improvement', 1.0000277330729301), ('learn drivers', 1.0000277309785133), ('acer trains', 1.000027719301037), ('collaborative', 1.0000277157232327), ('oz framework', 1.0000277105009554), ('individual test', 1.0000277078351727), ('identify relationships', 1.0000277039845253), ('alleviate', 1.000027700469084), ('synaptic', 1.0000276986285643), ('sequence regime', 1.0000276964599577), ('variables', 1.0000276894140312), ('correcting exposure', 1.0000276838075708), ('fundamental mechanisms', 1.0000276831528616), ('term', 1.0000276828377874), ('excellent performance', 1.0000276786120894), ('robust leaning', 1.0000276742665433), ('affinity classifier', 1.0000276715743153), ('activation', 1.0000276680388585), ('worker cores', 1.0000276560583752), ('perform navigation', 1.0000276432354944), ('dual am', 1.0000276256007254), ('many physical', 1.0000276241963062), ('previous transition', 1.0000276144101363), ('expert', 1.000027613271464), ('potential regions', 1.0000276077165984), ('direct analysis', 1.0000276068970932), ('matrix product', 1.0000276046262384), ('filter activations', 1.0000275941307253), ('structure termed', 1.00002759308676), ('regression results', 1.0000275794082787), ('digit', 1.000027576921717), ('distribution', 1.000027567345728), ('general scope', 1.000027566184399), ('other event', 1.000027558571847), ('share', 1.0000275577650881), ('neural heart rate', 1.0000275503709555), ('sensory information processing', 1.000027542518209), ('compact network', 1.0000275407007304), ('art spiking', 1.0000275384036967), ('manufactured device', 1.0000275188175234), ('raw laser', 1.0000275145540671), ('shared factors', 1.0000275115496484), ('compare questions', 1.000027507296125), ('algorithms dqn', 1.0000275069385074), ('depth sensitivity', 1.000027501756596), ('example humans', 1.0000274944129033), ('embedded systems', 1.0000274914810479), ('avoid actions', 1.000027490123627), ('effectiveness', 1.0000274882564215), ('characters', 1.0000274800831794), ('interpretation provides', 1.0000274777308908), ('adjacent sentences', 1.0000274767497292), ('ambiguity faced', 1.0000274740207629), ('task importance', 1.0000274715991848), ('field', 1.0000274598477508), ('can learn', 1.0000274539538285), ('finite', 1.0000274386047414), ('further improvement', 1.0000274306097832), ('18fps', 1.0000274258466473), ('similarity judgments', 1.0000274254278785), ('simple k', 1.0000274251458372), ('speed', 1.0000274245686636), ('deep speaker', 1.0000274240131741), ('different time', 1.0000273937482804), ('common identity', 1.0000273931437973), ('traditional approaches', 1.0000273887344437), ('soft selection', 1.0000273832966025), ('noisy versions', 1.000027376300549), ('target sequences', 1.000027376234965), ('independent test', 1.0000273743513), ('methods policy', 1.0000273695039363), ('digits database', 1.0000273641302868), ('several analogies', 1.0000273529945407), ('substitute models', 1.000027344404804), ('unknown amount', 1.0000273428823625), ('many time', 1.0000273383507337), ('related approaches', 1.0000273371376602), ('other regression', 1.0000273304310376), ('surrogate alignment', 1.0000273245128188), ('learn sentence', 1.0000273211793065), ('same principle', 1.0000273180075134), ('art classifiers', 1.000027316760325), ('analysis indicates', 1.0000273073441919), ('negative pairs resulting', 1.0000272966769508), ('medical investigators can', 1.000027292643918), ('diagnostic problem', 1.000027280538483), ('bring learning', 1.0000272789119866), ('wine datasets', 1.0000272772455), ('tackle question', 1.0000272766366698), ('practical', 1.0000272631614495), ('robust', 1.0000272600059552), ('static', 1.0000272550466935), ('state value', 1.0000272532826404), ('entire process', 1.000027249045269), ('such cases', 1.0000272437484639), ('motor primitives', 1.0000272415595268), ('prove', 1.0000272318342098), ('training processes', 1.0000272267612214), ('finite sets', 1.0000272136125274), ('different usages', 1.0000272053119459), ('statistical regularities', 1.0000271921698698), ('triplet comparisons', 1.0000271901651576), ('extended', 1.0000271829534257), ('ms coco', 1.0000271790066286), ('gem', 1.0000271745276674), ('blocks', 1.000027172673077), ('patient notes', 1.0000271636380444), ('desired form', 1.000027161767359), ('simple feed', 1.0000271611059872), ('art baselines', 1.0000271583251816), ('mathematical theorems', 1.0000271556671883), ('initial estimations', 1.0000271546098927), ('maximum', 1.0000271520148991), ('intermediate level', 1.0000271491208756), ('term distances', 1.0000271482983512), ('condition', 1.000027143579621), ('technique termed', 1.0000271423317877), ('memristive networks', 1.000027139536062), ('individual humans', 1.0000271387216342), ('actuator space', 1.0000271363187778), ('high speed exhibited', 1.000027131602115), ('cortical neurons engaged', 1.000027120163247), ('multiscale', 1.0000271163871712), ('unit ball', 1.0000271162896957), ('specific propagation', 1.000027114903654), ('particle filter', 1.0000271123096194), ('classification based', 1.0000271115905839), ('viewpoint surroundings', 1.0000271036059407), ('such processes', 1.0000271022632108), ('first person actors', 1.00002709929813), ('sample trajectories', 1.0000270898536054), ('help estimate', 1.0000270878987014), ('highly accurate', 1.0000270843878118), ('useful skill', 1.0000270783394496), ('evaluations shows', 1.0000270773735769), ('chess', 1.000027073148291), ('accelerate training', 1.0000270704310235), ('weight shared', 1.0000270691735094), ('newtonian mechanics called', 1.0000270590629254), ('multiple child', 1.00002703592691), ('deception', 1.0000270339556088), ('annotate event', 1.000027033433335), ('advertisement videos', 1.0000270323671812), ('acoustic tokens carry', 1.000027030702511), ('target signer', 1.000027028398387), ('statistical models', 1.0000270119616697), ('current variants', 1.0000270107875273), ('protected health', 1.000027009192095), ('important parameters', 1.0000269951729177), ('coordinated interactions', 1.0000269925146208), ('art recurrent', 1.0000269847245646), ('experts moves', 1.0000269762374998), ('gans', 1.0000269744664279), ('links connecting', 1.000026969121581), ('re ranking', 1.000026960279993), ('greedy nature', 1.000026955091315), ('novel clustering', 1.0000269541900233), ('particular prediction', 1.0000269428169375), ('art dnns', 1.0000269327363138), ('full test', 1.0000269204565955), ('boundary attack', 1.0000269188379052), ('approaches involve', 1.0000269100183126), ('expensive softmax', 1.000026890988091), ('special cases', 1.0000268891308421), ('topic responses', 1.0000268850068061), ('structured attention', 1.0000268839287536), ('bloom embeddings', 1.0000268748962167), ('building end', 1.0000268716981222), ('compact form', 1.0000268669099939), ('experiments applying', 1.0000268664248477), ('best cnns', 1.0000268646051287), ('baseline results', 1.0000268636746688), ('different scales', 1.0000268595756294), ('new compact', 1.000026858299081), ('events actions', 1.0000268556012546), ('other candidate particles', 1.0000268549728788), ('multi core', 1.0000268506094991), ('large quantities', 1.0000268475064418), ('practice', 1.0000268462865807), ('medical text', 1.0000268331515036), ('neurons receive', 1.0000268312188447), ('topic', 1.0000268296189), ('outline differences', 1.0000268279720363), ('active learning', 1.0000268251060744), ('partial sampling', 1.000026824731388), ('structural target', 1.0000268192162223), ('predictive', 1.0000268087542687), ('candidate', 1.0000268079003296), ('introduce', 1.00002680746815), ('massive', 1.0000267925676047), ('human judgements', 1.0000267811590695), ('multiple exposures', 1.0000267810888914), ('words characters', 1.0000267807385654), ('different timescales', 1.0000267786677197), ('supervised adaptation', 1.0000267766233084), ('global optimization', 1.000026773352419), ('expected quality', 1.0000267697866827), ('past compared', 1.0000267659637536), ('representing phrase', 1.000026762245869), ('predicting drug', 1.0000267610267277), ('traditional systems', 1.000026759283231), ('art dnn', 1.0000267449390514), ('other efficiency', 1.0000267337029607), ('learn scale', 1.0000267325734784), ('cross modality', 1.000026728545787), ('sub models', 1.0000267237509677), ('accurate ground truth', 1.000026707536547), ('deep voice', 1.000026703379453), ('max norm', 1.0000266999675769), ('small scale side', 1.0000266993828977), ('fewer target', 1.0000266954410646), ('predictors', 1.00002666998699), ('topological structures', 1.0000266551537764), ('external rewards', 1.000026654928939), ('standard approach', 1.0000266515404719), ('several real', 1.0000266499780825), ('several evaluation', 1.0000266499466441), ('wikipedia articles', 1.000026638997672), ('multiple child cells', 1.0000266330292218), ('dialogue model', 1.0000266272001102), ('fuzzy xor', 1.0000266266616555), ('cut', 1.0000266216082274), ('art alternatives', 1.0000266054621136), ('adaptive exploration', 1.000026603895982), ('c', 1.000026601779327), ('demonstrate consumer', 1.000026586712752), ('interest reconstruction', 1.0000265707096334), ('long history', 1.0000265573920482), ('several use', 1.000026556085379), ('static rectified', 1.000026548412472), ('transfer top', 1.0000265460980056), ('wall avoidance', 1.0000265422855068), ('empirical efficiency', 1.0000265416426217), ('autonomous', 1.0000265393400751), ('raw sentence pairs', 1.0000265380897881), ('deeper comprehension', 1.0000265353094342), ('word region', 1.000026519403022), ('recommend appealing', 1.0000265186991892), ('locality principle', 1.000026515928598), ('squad dataset', 1.0000264984132599), ('models proposed', 1.000026494193266), ('biased estimate', 1.0000264885921895), ('auxiliary supervised', 1.0000264761061672), ('attain invariance', 1.0000264742534632), ('handwriting', 1.0000264668781422), ('natural fuzzification', 1.0000264628361015), ('viable solution', 1.000026462618333), ('138k messages', 1.000026455569221), ('pair', 1.0000264514709034), ('extract pre', 1.000026451436736), ('much effort', 1.0000264495677342), ('new compositions', 1.0000264429449481), ('mode', 1.0000264384295823), ('statistical parametric', 1.0000264320222576), ('improve training', 1.0000264290156722), ('supervised manner', 1.0000264192635346), ('overall quality', 1.0000264124842084), ('eclectic method', 1.0000264110364157), ('modern signal', 1.0000264065607218), ('human intervention', 1.0000264039300621), ('consumer grade', 1.0000263942594063), ('traditional count based', 1.000026391562433), ('other models', 1.0000263821793887), ('conventional whole', 1.0000263812315158), ('structural information', 1.000026378828671), ('logical', 1.000026375920797), ('executing', 1.0000263737887667), ('combine lines', 1.0000263701140217), ('workplace home', 1.000026365931911), ('new form', 1.0000263485725467), ('test question', 1.0000263441885064), ('evaluated', 1.0000263433003782), ('single factor', 1.000026342887053), ('disembodied models', 1.0000263385802026), ('forms', 1.000026321433205), ('prior class', 1.0000263168058845), ('fusion', 1.0000263058763739), ('conventional natural', 1.000026300180852), ('script scores', 1.0000262977631715), ('network growth', 1.000026286114166), ('provide counter', 1.0000262855753863), ('scan', 1.0000262826561896), ('constrained sentence', 1.0000262797359116), ('jacobian matrix', 1.0000262742566903), ('produce descriptions', 1.0000262610455848), ('molecular structures', 1.000026246286556), ('labels may', 1.000026243770473), ('learners scripts', 1.000026233035919), ('synthesis', 1.0000262178481962), ('incorporate', 1.0000262154284665), ('compositional solutions', 1.0000262131496844), ('entity', 1.0000262118360934), ('key elements', 1.0000262106344073), ('mean squared', 1.0000262070247221), ('analysis suggests', 1.000026194922557), ('cnns v', 1.0000261902352463), ('service', 1.0000261822420902), ('difficult parts', 1.0000261808120596), ('trials', 1.0000261767566305), ('long memory', 1.000026176263336), ('worlds', 1.0000261755766682), ('undesired', 1.0000261667725296), ('disciplines including', 1.0000261660343928), ('consumer generated', 1.0000261647594548), ('commercial advertisements', 1.000026163761696), ('activities recommendation', 1.000026163047123), ('single', 1.0000261626817044), ('correct', 1.000026156563281), ('internal model', 1.000026152991583), ('single frames', 1.0000261524439997), ('invalid lstm units', 1.0000261520535432), ('fitness', 1.0000261309705125), ('learnable pooling', 1.0000261168291424), ('many perception', 1.0000261096775225), ('learner', 1.0000261090572569), ('acquire estimates', 1.000026099337433), ('pnet learns', 1.0000260968658234), ('original resnet', 1.0000260942939911), ('previous poses', 1.0000260895152484), ('density models', 1.0000260784429746), ('system waves', 1.0000260763092543), ('positive samples', 1.0000260734534618), ('several state', 1.0000260696363181), ('modification alleviates', 1.000026063094097), ('human language communication', 1.000026061091895), ('single target', 1.0000260497540487), ('powerful principle', 1.0000260473161229), ('english language', 1.0000260463511057), ('standard dropout', 1.0000260338655298), ('project', 1.0000260308116034), ('express time', 1.00002602251196), ('human labor required', 1.0000260186413104), ('motor output', 1.0000259845572155), ('partition', 1.0000259834362637), ('parsimonious inference', 1.0000259819550106), ('hyperplane', 1.000025978064071), ('synaptic traits considers', 1.0000259753355194), ('important challenges remain', 1.0000259736234391), ('conditional probabilities', 1.0000259725070377), ('human insight', 1.0000259679929704), ('computational geometry', 1.0000259645778953), ('human subject', 1.0000259631523711), ('road polylines', 1.0000259628024748), ('causal models', 1.00002595481352), ('adjacent segments', 1.0000259361187986), ('counter', 1.0000259035159254), ('building systems', 1.00002590191074), ('first hop', 1.0000258879075616), ('overcome', 1.0000258780412197), ('central layer', 1.000025877756236), ('difficulty entailed', 1.0000258759774077), ('natural extensions', 1.000025875806723), ('lexical analysis', 1.0000258669399382), ('lake temperature', 1.0000258654048995), ('data poisoning', 1.0000258634332049), ('negligible accuracy', 1.0000258463250669), ('loss surface', 1.0000258384252854), ('useful technique', 1.0000258325114346), ('learned knowledge', 1.0000258317001527), ('long term motion', 1.0000258204940866), ('memory state', 1.000025820105012), ('training objective', 1.0000258192965643), ('shed light', 1.0000258185314634), ('good fitness', 1.0000258080164992), ('discrimination method', 1.0000258057439684), ('clinical outcomes characterization', 1.0000257948118485), ('smm patterns', 1.0000257928833451), ('type multiplicity', 1.0000257896736455), ('exact likelihood', 1.0000257781673367), ('spectral', 1.00002576876407), ('detect measure', 1.0000257678976614), ('accurate classification', 1.000025763575593), ('term space', 1.000025744009153), ('new training', 1.0000257439534468), ('varying quality', 1.0000257431672128), ('hand engineered', 1.0000257373536845), ('floating', 1.00002573634452), ('primary innovation', 1.000025728913314), ('evolutionary product', 1.0000257279928588), ('competitive performance', 1.0000257279863234), ('prior work', 1.0000257246229), ('trainable weighted', 1.0000257178806502), ('human performance', 1.0000257177201473), ('quantify', 1.000025702771487), ('long snake shaped', 1.000025692561095), ('semi', 1.0000256876282436), ('medical investigators', 1.0000256824710756), ('relevance', 1.0000256819486153), ('unsupervised pretraining', 1.0000256596218502), ('multilinear', 1.0000256506443848), ('different neurons', 1.0000256469048128), ('consistent estimate', 1.0000256443281506), ('conventional approach', 1.0000256427174388), ('auxiliary problems', 1.0000256400864782), ('character based', 1.000025639380341), ('multiple variations', 1.0000256378113446), ('principal axes', 1.0000256286205433), ('holistic perception', 1.0000256285516984), ('dialectical interactions', 1.0000256138610304), ('alternative formulation', 1.000025611540204), ('single frame', 1.000025610761736), ('end manner', 1.0000256097074498), ('scoring approach', 1.0000256073118936), ('architectures lenet', 1.0000256068104407), ('holistic face', 1.0000256062429416), ('prediction adaptation', 1.0000256039012128), ('use dropout', 1.0000256019306244), ('sentence length', 1.000025601716671), ('synthetic world', 1.000025601425298), ('average sum', 1.0000255947844152), ('conventional approaches', 1.0000255905524844), ('informative', 1.0000255882569518), ('vectors', 1.0000255868778831), ('many recent', 1.0000255791678863), ('vqa dataset', 1.0000255653295869), ('ease', 1.0000255480971767), ('derive', 1.0000255451092086), ('teacher network', 1.0000255422393154), ('initializations conducive', 1.0000255415525796), ('particular class', 1.0000255392433097), ('reusing', 1.0000255391968234), ('developed technique', 1.0000255351754204), ('recent success', 1.000025534813355), ('abstracted state', 1.0000255348122828), ('bilinear terms', 1.0000255280336612), ('part', 1.0000255231029347), ('paper using', 1.0000255224534964), ('previous end', 1.0000255158354818), ('current step', 1.0000255145511325), ('target information', 1.0000255124073532), ('sets', 1.0000255076319842), ('defensive distillation', 1.0000255055566558), ('side effect', 1.000025504986627), ('atis', 1.0000255007525034), ('training method', 1.0000255001930234), ('variety', 1.0000254831169513), ('unwanted bias', 1.0000254826545856), ('human actions', 1.0000254789147087), ('task would', 1.0000254780124602), ('vision', 1.0000254767666084), ('basic units grams', 1.0000254749120026), ('large scale energy', 1.0000254699065265), ('clinical electroencephalograms eegs', 1.000025469548548), ('making mistakes', 1.000025466159196), ('historical handwritten', 1.0000254661575732), ('supervised reading', 1.0000254649827127), ('object word', 1.0000254595873803), ('joint probability', 1.0000254591751645), ('growing synergies', 1.000025454406858), ('remarkable properties', 1.00002545144147), ('table', 1.0000254442609358), ('model size', 1.0000254413010912), ('key words', 1.0000254402518396), ('gru performs', 1.000025440202282), ('acoustic', 1.0000254400864996), ('background interference', 1.0000254377216313), ('novel techniques including', 1.0000254336208823), ('transferable chemical property', 1.000025425050813), ('better predictors', 1.0000254214379984), ('sequence taggers', 1.0000254179438979), ('multi modal', 1.0000254158780275), ('relevant invariances', 1.0000254134787108), ('long distance', 1.000025405269849), ('text sample', 1.000025404438552), ('vocabulary terms', 1.0000254019150292), ('dqn', 1.0000253946244653), ('game', 1.000025392260383), ('different sets', 1.000025390523414), ('numerous traffic scene', 1.0000253855893404), ('model incorporates', 1.0000253758691318), ('given training', 1.000025375580622), ('rough set reduct', 1.0000253738031808), ('conventional pattern', 1.0000253732509727), ('results provide', 1.0000253674436634), ('tracking desire', 1.0000253666386438), ('size', 1.0000253636639915), ('eye gaze', 1.000025363465072), ('diagnostic grading results', 1.0000253623882138), ('previous studies researchers', 1.000025360403513), ('challenges', 1.000025357988222), ('future testing', 1.0000253476818084), ('above challenges', 1.0000253370526069), ('individual spikes', 1.000025336866454), ('fewer training', 1.0000253268937689), ('leading approaches', 1.000025307983113), ('compositional way', 1.0000253052448624), ('selection generation', 1.0000252805762506), ('synapses', 1.000025277193265), ('flexibility', 1.0000252764461355), ('testbed', 1.0000252690222695), ('dynamic range', 1.0000252674385466), ('frame', 1.000025267399084), ('main arguments', 1.0000252633185256), ('early layers', 1.0000252598732742), ('single unit', 1.0000252586516187), ('traditional supervised', 1.0000252553004942), ('empirical results', 1.000025253354603), ('verified', 1.000025250726063), ('successful instance', 1.000025228644802), ('simple parts', 1.00002522845583), ('third party', 1.0000252266513605), ('viewpoint', 1.000025224268032), ('experiments validates', 1.0000252211887655), ('results according', 1.0000252138711454), ('practical goal', 1.0000252121259186), ('large population sizes', 1.0000252113476662), ('such system', 1.0000252111346866), ('null space', 1.0000252110639036), ('reading model', 1.000025209097965), ('novel layer', 1.0000252060122496), ('virtual environment', 1.0000251946041856), ('arbitrary subgoals enabling', 1.0000251922530468), ('evolutionary', 1.0000251916551424), ('modes', 1.0000251875461308), ('healthcare data', 1.000025175377171), ('dynamical', 1.0000251741928994), ('architectural traits', 1.0000251685926094), ('combined use', 1.0000251670565392), ('reversal learning', 1.0000251625021017), ('saliency response', 1.0000251597666217), ('idea', 1.0000251592021636), ('real world classification', 1.0000251575768735), ('release', 1.0000251563760043), ('new structure', 1.0000251453310716), ('symbols pre', 1.0000251433209606), ('sentence relation', 1.0000251411579715), ('actual relevance', 1.000025138536915), ('nonstationary', 1.0000251317243438), ('humans bring', 1.0000251236327302), ('terpret model', 1.0000251192381753), ('bio', 1.0000251177518222), ('ancestor', 1.0000251136383818), ('summarize', 1.0000251100146438), ('fool pre', 1.0000251039620653), ('successor reinforcement', 1.0000251035246916), ('target model', 1.000025099471591), ('accuracy loss', 1.000025095943158), ('critical aspect', 1.0000250938921167), ('low dose ct', 1.000025082090602), ('social interaction', 1.0000250797962082), ('facilitate research', 1.0000250788621243), ('little effort', 1.0000250740994472), ('imp', 1.000025055143683), ('recurrence frequency', 1.0000250533637411), ('neuroscience literature', 1.000025038146077), ('tnet given', 1.0000250304916067), ('metric exhibits', 1.000025025496252), ('predict event', 1.0000250152609658), ('effective regulariser', 1.000025009851928), ('fail', 1.0000250022664077), ('shadow', 1.0000249953003437), ('generalised bilinear', 1.0000249855707068), ('better task', 1.0000249720375334), ('patches', 1.0000249679453568), ('parallel', 1.000024965548744), ('module', 1.0000249605051235), ('randomized algorithm', 1.0000249571071382), ('rf data', 1.000024953523729), ('weights calculated', 1.0000249507687375), ('unseen objects', 1.0000249495372147), ('large negative', 1.000024949073184), ('other timing', 1.000024941949193), ('use pop', 1.000024938630202), ('other agents', 1.000024936234314), ('arbitrary sounds', 1.0000249290289445), ('several thousands candidate', 1.0000249286391754), ('interpret dnn', 1.000024922493058), ('natural parameters', 1.0000249118714488), ('multilingual', 1.000024911065717), ('raw occluded', 1.0000249078506498), ('learner writing', 1.0000248812649293), ('statuses comments', 1.0000248777824057), ('memorization', 1.000024874240876), ('multiple cpgs', 1.0000248695898553), ('movies recommendation', 1.0000248676234216), ('rf sub', 1.0000248671964493), ('sick data', 1.0000248639563047), ('online memoryless', 1.0000248528414997), ('main motivation', 1.0000248457288357), ('foveal image', 1.0000248403565837), ('parallel cells', 1.0000248379179866), ('closest prediction', 1.0000248378101808), ('cheap commodity', 1.00002483446816), ('attacks', 1.0000248325787886), ('entailment enhanced', 1.0000248309656867), ('similarities', 1.0000248283943791), ('milliseconds', 1.0000248146285398), ('word composition', 1.0000248105675718), ('policy estimate', 1.0000248087217776), ('action frequency', 1.0000248044240876), ('integration', 1.0000247985889466), ('patient sleep stage', 1.0000247956936417), ('recurrent ladder networks', 1.0000247846058525), ('imdb movie reviews', 1.0000247833723246), ('synaptic model', 1.0000247820724275), ('standard schedules', 1.0000247785934873), ('semantic drifts', 1.000024773401689), ('strengthen position sensitivity', 1.0000247654019254), ('missing links', 1.0000247509787699), ('paper concludes', 1.0000247461496756), ('movie booking', 1.000024743454409), ('labels improves', 1.0000247362621775), ('soccer players', 1.0000247348567015), ('fundamental assumption', 1.0000247279190553), ('relevant regions', 1.0000247124731962), ('complex domain', 1.0000247122652155), ('tested', 1.0000247096179307), ('accurate predictions', 1.0000247091411425), ('tweets', 1.000024688358637), ('speaker subspace', 1.0000246854104096), ('fresh interpretation', 1.00002468401403), ('compact circuit', 1.0000246825913064), ('illustrative example', 1.000024682281826), ('available training', 1.0000246749057937), ('lottery ticket', 1.0000246587009103), ('entailment show', 1.0000246583136594), ('entities', 1.0000246569625193), ('sampled', 1.0000246556691528), ('molecules active', 1.0000246552277492), ('careful choice', 1.0000246536094284), ('candidate words', 1.00002464987216), ('successive', 1.0000246486010498), ('such systems', 1.0000246442774519), ('sca can', 1.00002462997762), ('perturbed model', 1.0000246250085885), ('small fraction', 1.00002461856363), ('variants', 1.000024617234494), ('most natural', 1.000024601238293), ('descriptive sentences', 1.0000246008521751), ('state can', 1.0000246003233768), ('nest yields', 1.0000245956132887), ('rl models', 1.0000245776523171), ('substantial improvements', 1.0000245763760194), ('significant margins', 1.0000245747051042), ('training process', 1.0000245734473427), ('continuous variables', 1.0000245681109559), ('europarl english', 1.000024567093491), ('model capacity', 1.0000245593625157), ('detailed description', 1.0000245583731446), ('disciplines e', 1.0000245582449887), ('scaling', 1.0000245579690252), ('similar efforts', 1.0000245501086438), ('pretraining technique', 1.0000245381169481), ('previous words', 1.0000245321044985), ('developmental visuomotor learning', 1.0000245289480092), ('ask answer', 1.0000245288041711), ('sensor space', 1.000024528174535), ('clean labels', 1.0000245249240431), ('classes', 1.0000245168226172), ('challenging driver', 1.0000245120900046), ('fingerspelling recognition', 1.0000245038298785), ('different modalities', 1.0000245026691605), ('linguistic tasks', 1.0000244963679366), ('event successor', 1.0000244937799403), ('further progress', 1.0000244835266836), ('different order', 1.0000244829080573), ('specific co', 1.0000244711074817), ('learner essays', 1.0000244662981277), ('further manual', 1.0000244646334475), ('stereotypical motor movement', 1.0000244571214958), ('units provide', 1.0000244535572098), ('distill state', 1.0000244502195532), ('train task', 1.000024446801423), ('art rl', 1.0000244455131597), ('consistent improvement', 1.000024442317517), ('scalar values', 1.0000244389691788), ('multiple action', 1.0000244381051306), ('model employs', 1.0000244373872573), ('execution', 1.0000244360559976), ('small perturbation', 1.0000244279533046), ('new one', 1.0000244277785681), ('advertisement designers', 1.000024417951058), ('ranking component', 1.0000244162913698), ('mobile device', 1.0000244108956868), ('primary objective', 1.000024404812169), ('hybrid analog', 1.0000244036705683), ('best student', 1.0000243988170339), ('analytical results', 1.0000243962156212), ('solutions exhibit', 1.000024390575943), ('new', 1.000024389644521), ('collecting dialogue', 1.0000243892297884), ('facilitate learning', 1.0000243779393134), ('tables', 1.000024376757534), ('phonetic transcription senone', 1.000024363068738), ('monolingual baseline', 1.0000243513772866), ('rich environments', 1.0000243486256877), ('dropout training', 1.0000243455570155), ('pseudo', 1.0000243430243678), ('improving', 1.0000243430150682), ('different notions', 1.0000243358218357), ('practical solutions', 1.0000243341760513), ('turn expose', 1.0000243334568648), ('classification rules', 1.0000243328637162), ('pursuit', 1.0000243314155561), ('geometric intuition', 1.0000243197573164), ('observable world', 1.000024311318135), ('ctc', 1.0000243027816724), ('rapid training', 1.0000242950293365), ('maxout networks', 1.000024291771881), ('emotions age', 1.000024290926143), ('velocity inputs', 1.0000242865896944), ('head pose', 1.00002427745781), ('target classification', 1.0000242716469099), ('novel image', 1.0000242685694853), ('sensory information', 1.0000242568902609), ('multipliers', 1.0000242536646247), ('such modifications', 1.0000242512410924), ('faces', 1.0000242300073152), ('body representations', 1.000024226056488), ('quantitative analysis', 1.0000242258966614), ('small minibatch size', 1.0000242215665613), ('transparency', 1.000024217293594), ('small vocabulary', 1.0000242137362085), ('novel molecules', 1.0000242136842825), ('rewards', 1.0000242119308722), ('particular variation', 1.0000242066387381), ('professional translators', 1.0000241616276664), ('central hidden', 1.0000241601596853), ('large dialogue', 1.0000241573961177), ('work nsfw', 1.000024151386975), ('approach brings', 1.000024150801895), ('researchers can', 1.0000241504043907), ('situ hybridization images', 1.0000241349746797), ('convert', 1.0000241201023903), ('few noise', 1.0000241139447306), ('principles used', 1.0000241017516107), ('intention process', 1.0000240988645035), ('distinguishable classes', 1.0000240815087968), ('biomedical qa', 1.000024073965462), ('frequent mistakes', 1.0000240732113694), ('observed training', 1.0000240700072909), ('same number', 1.0000240697713676), ('medicine network', 1.00002406809563), ('crucial ingredients', 1.0000240524281143), ('audio', 1.0000240444901833), ('multiple microphone signals', 1.0000240444088668), ('accelerate', 1.000024040215899), ('ensemble', 1.0000240277797983), ('imitate behaviors', 1.0000240260739879), ('subspace', 1.0000240243215213), ('ensemble level', 1.0000240181333089), ('past experience', 1.0000240090946955), ('art baseline', 1.000024008515723), ('agents grows', 1.0000240073334936), ('results including', 1.000023997241618), ('stored', 1.000023994422623), ('digital', 1.0000239943037506), ('many aspects', 1.000023992018566), ('gaps can', 1.0000239867244514), ('hankel matrix', 1.0000239671007312), ('main evaluation', 1.0000239597006728), ('suitability', 1.0000239586164505), ('goal directed', 1.0000239540062155), ('compositional sub', 1.0000239421067938), ('separating target', 1.0000239331604273), ('improve diagnosis', 1.0000239297052043), ('difference', 1.0000239291724624), ('batches', 1.000023909824184), ('clinical decision', 1.0000239072200916), ('linguistic interactions', 1.0000239049509676), ('measure theoretic', 1.0000239018818866), ('online sparsification criteria', 1.0000238993535882), ('manner achieve', 1.0000238964948165), ('corpora', 1.000023891256668), ('other distribution', 1.000023890365295), ('help', 1.0000238900163778), ('higher levels', 1.0000238896486768), ('complex combinations', 1.0000238869159102), ('reference system', 1.0000238819222649), ('interpretable', 1.0000238817497187), ('novel latent', 1.0000238782203446), ('unsegmented', 1.000023873679886), ('learning channels', 1.0000238723652233), ('seed architecture', 1.000023868668574), ('simple questions', 1.000023867893514), ('recent years lacking', 1.0000238658583254), ('lucky random', 1.0000238614125214), ('linguistic units', 1.0000238611543033), ('same spirit', 1.000023858625698), ('art solutions', 1.000023856450046), ('memristor crossbar', 1.0000238555944816), ('larger representation', 1.0000238551349667), ('approach combines', 1.0000238527416192), ('learning strategies', 1.0000238488629043), ('vanilla rnns', 1.0000238402221708), ('theory applies', 1.0000238375050126), ('meaningful categories', 1.000023834918052), ('parsec', 1.0000238240173196), ('psychological phenomena', 1.000023818161366), ('handle missing', 1.0000238110815736), ('results derived', 1.0000238098340133), ('understand blackout', 1.0000238080199373), ('reveal', 1.0000238029832775), ('individual weights', 1.0000237984982319), ('subsequent symbol', 1.0000237941422794), ('such mnns can', 1.0000237913651686), ('biased estimates', 1.0000237891836785), ('projection', 1.000023786645003), ('feature imitation', 1.000023784764911), ('open question', 1.000023769340146), ('last decade', 1.0000237663479035), ('workplace', 1.000023756539092), ('severe information', 1.0000237520497044), ('monitor', 1.0000237460344055), ('feature locality', 1.0000237403265182), ('information security', 1.0000237345081164), ('other published', 1.0000237310927427), ('quantify factors', 1.0000237309812066), ('cortical neurons', 1.0000237295885905), ('move', 1.0000237294292333), ('structured exploration', 1.0000237240604881), ('end dialogue', 1.00002372381202), ('recurrent highway', 1.0000237202786542), ('human labor', 1.000023717869124), ('skip thought neighbor', 1.0000237127578022), ('notable difficulties', 1.0000237126509945), ('single typhoon', 1.0000237100359701), ('pairs', 1.0000236983904527), ('networks cd', 1.0000236980839796), ('neural nlu', 1.0000236969111764), ('spatial question', 1.000023695032653), ('most sequences', 1.0000236947356815), ('standard sensitivity', 1.0000236900113348), ('traditional', 1.0000236884217142), ('sentence levels', 1.0000236820017687), ('incorrect labels', 1.000023677329668), ('squares', 1.000023668410516), ('predict missing', 1.00002364544385), ('predicting', 1.000023632301835), ('previous attempts', 1.0000236303640948), ('flexible approach', 1.0000236216468235), ('gain insight', 1.0000236144390238), ('discrete space', 1.000023613321627), ('linear chains', 1.000023612576544), ('dropout penalty', 1.0000236073607784), ('art feature', 1.0000236001393468), ('observed target', 1.0000235989518877), ('vectors sequences', 1.0000235950272516), ('many mammals including', 1.0000235911322537), ('tremendous cost', 1.0000235888292375), ('efficiency', 1.0000235822353907), ('intermap', 1.0000235790527876), ('review could', 1.0000235767441392), ('deep transition', 1.0000235758278126), ('proposed attention', 1.0000235752874125), ('pattern completion', 1.0000235648349356), ('standard techniques', 1.0000235641232786), ('most questions', 1.000023563889854), ('considerable challenge', 1.0000235622436173), ('maturational schedule', 1.0000235578093613), ('later stage', 1.000023555209979), ('sensorimotor development', 1.0000235529269945), ('stochastic differential', 1.0000235485936817), ('use named', 1.0000235410707234), ('gated activation', 1.0000235239615949), ('lack', 1.0000235192266234), ('field approach', 1.0000235178565617), ('crucial pieces', 1.0000235170610066), ('german translation', 1.000023513528823), ('second demonstration', 1.0000235040901946), ('nmfs', 1.0000235035931628), ('perform weight', 1.0000234947297024), ('various domains', 1.0000234937113825), ('soft way', 1.000023492903607), ('careful analysis', 1.0000234805131794), ('statistical dialogue', 1.0000234689369356), ('carry information', 1.0000234666246026), ('current output', 1.0000234617960002), ('glm t', 1.0000234593544142), ('appropriate value', 1.000023451989368), ('development', 1.000023450891554), ('rapid advances', 1.000023439682188), ('purpose', 1.000023434117025), ('shift', 1.000023432314794), ('biometric decision defuzzification', 1.0000234270286998), ('rl involve', 1.0000234264223746), ('exploration', 1.0000234228258773), ('metaphor identification', 1.0000234071105234), ('new scoring', 1.0000233928986346), ('innermost layer', 1.0000233903868307), ('competing notions', 1.000023389072447), ('simple model', 1.0000233840191093), ('approach relies', 1.000023383155986), ('off policy', 1.0000233778286283), ('art features', 1.000023376273708), ('better alternative', 1.0000233653999557), ('different training', 1.00002336533092), ('multi media', 1.0000233619295438), ('match srnn', 1.0000233588158696), ('open challenge', 1.0000233568961434), ('conclusions converge', 1.000023356668427), ('storage power', 1.000023355269915), ('formalize', 1.0000233535168683), ('cases representation', 1.0000233521091144), ('negative biases', 1.0000233495503912), ('special long', 1.0000233466182151), ('complicated reward', 1.000023342642162), ('second flow', 1.0000233358537536), ('multi level', 1.0000233348889953), ('mctest dataset', 1.000023329561775), ('novel communication', 1.0000233266873821), ('gated', 1.0000233265846856), ('systematic methods', 1.000023320627682), ('mathematical consequences', 1.0000233203074693), ('views', 1.0000233192089831), ('contexts', 1.0000233163909364), ('modification affects', 1.0000233105995604), ('model reveals', 1.0000233090814046), ('practice training', 1.0000233050879588), ('matrix attending', 1.0000232985157318), ('uncertain predictions', 1.0000232961701412), ('event', 1.0000232955830357), ('sequence level', 1.000023289783361), ('systematic study', 1.000023278511709), ('explanations can', 1.0000232749948263), ('umc 65nm', 1.0000232732465693), ('read', 1.0000232684915662), ('many languages', 1.000023265526249), ('first one', 1.0000232606592205), ('register', 1.0000232545153163), ('main streams', 1.0000232532276883), ('median point', 1.0000232518138972), ('various methods', 1.0000232450521658), ('farm', 1.0000232409645406), ('traditional nn', 1.0000232405944252), ('implicit posteriors', 1.0000232341395972), ('time vary', 1.000023226192864), ('identity', 1.000023221625431), ('slot filling', 1.000023218921443), ('art end', 1.000023216550293), ('inner product', 1.0000232111752816), ('pointer', 1.000023200156969), ('adequacy fluency', 1.0000231724472608), ('discriminate', 1.0000231723171173), ('design deficiencies', 1.000023171283861), ('cf setting', 1.0000231671544935), ('words containing', 1.0000231662799939), ('physical properties', 1.0000231549013112), ('further study', 1.000023148892468), ('challenge', 1.0000231386425569), ('scarselli et', 1.000023134174473), ('mitigation', 1.0000231305807425), ('cnns including', 1.0000231278035732), ('current performance', 1.0000231256249072), ('controlling gene', 1.0000231241394801), ('unique combination', 1.0000231215771367), ('classification regions', 1.0000231139821179), ('training using', 1.0000231130047665), ('most contexts', 1.000023107922792), ('task confronted', 1.0000231061932592), ('given question', 1.0000231050896955), ('clinical information', 1.0000230979398796), ('best snn', 1.000023095350545), ('different angle', 1.000023095100248), ('probabilistic maxout units', 1.0000230935137309), ('rigorous definition', 1.0000230834156416), ('control strategy', 1.0000230798139909), ('joint training', 1.0000230778415768), ('corpus', 1.0000230740533829), ('infer phrases', 1.0000230673729467), ('word spellings', 1.0000230609364555), ('explore ways', 1.0000230579049534), ('common approach', 1.0000230517160547), ('particular given', 1.0000230488696191), ('different target', 1.0000230450705216), ('general sentence', 1.0000230425534378), ('conditions', 1.0000230387968745), ('performances taking', 1.0000230359863438), ('word ordering', 1.0000230340797076), ('mnist cifar10', 1.0000230303922673), ('classical connectionist viewpoint', 1.0000230296872443), ('select penalty', 1.0000230133129755), ('big n', 1.0000229913742034), ('density based', 1.000022986846574), ('increase', 1.0000229853775786), ('focused research', 1.0000229776280547), ('accurate', 1.0000229738989148), ('unpaired output', 1.00002295779833), ('inductive transfer', 1.0000229576670103), ('crowd workers', 1.0000229527287683), ('gestures language', 1.0000229454425338), ('drop', 1.000022937232691), ('isolation', 1.0000229287369056), ('better interpretation', 1.0000229281145108), ('typical ann', 1.0000229245578185), ('paper motivates', 1.000022924221436), ('such sources', 1.0000229221133075), ('crucial ingredient', 1.000022920373945), ('memristive', 1.0000229167547112), ('mathematical generalization', 1.000022901462628), ('complex novel', 1.0000228982010728), ('synthetic gradients', 1.000022894803534), ('lack compositionality', 1.0000228886340599), ('simple form', 1.0000228853400088), ('alignment', 1.0000228702704927), ('location', 1.0000228688126278), ('proposed causal', 1.000022855386672), ('legends championships', 1.0000228530945536), ('products can', 1.0000228522431789), ('accurate ground', 1.000022847666198), ('cognitive state', 1.0000228429853768), ('spatial location', 1.0000228339069333), ('items', 1.0000228334165313), ('cool networks', 1.0000228279010899), ('neurons crashes', 1.0000228239187339), ('vqa v1.0', 1.000022821633172), ('output tied', 1.000022819639147), ('aggregate', 1.0000228166897929), ('interpretability finding', 1.0000228122239294), ('novel representation', 1.0000228115179484), ('small perturbations', 1.0000228103723534), ('strong priors', 1.000022807365117), ('primary difficulty', 1.0000228060873744), ('hebbian plastic connections', 1.000022798657349), ('ideal pairwise', 1.0000227983998213), ('puck', 1.0000227976799734), ('theory', 1.0000227919979525), ('classification obtaining', 1.0000227893857392), ('mirror neurons', 1.0000227722557264), ('quadrupedal walker', 1.0000227694231107), ('topic space', 1.0000227677919507), ('music modeling', 1.000022764485817), ('spatiotemporal', 1.0000227548704788), ('acoustic gmm', 1.0000227534904351), ('processes', 1.0000227517168672), ('predicting toxicity', 1.0000227423224348), ('extending attention', 1.0000227411626998), ('special structure', 1.0000227323221547), ('q', 1.0000227310776324), ('deductive', 1.000022726530928), ('uncontrolled environments', 1.0000227218140392), ('human associations', 1.0000227191792133), ('notation', 1.0000227048396015), ('alternative techniques', 1.0000227026720094), ('manifold embeddings', 1.0000226973145594), ('conceptual issues', 1.000022694819568), ('spatial vaes', 1.0000226905403702), ('earlier experience', 1.0000226896802302), ('mairal et', 1.0000226878569936), ('confidence region', 1.000022686416046), ('negative result', 1.0000226852387606), ('reconstruction', 1.0000226826726413), ('unique significance', 1.0000226775625234), ('art gans', 1.0000226746156864), ('multi layered', 1.0000226742115415), ('posterior confidence', 1.0000226686647882), ('deception possibility', 1.0000226664835326), ('audiovisual classification', 1.0000226618350223), ('many recommendation', 1.0000226528969185), ('logarithmic regret', 1.000022651030445), ('several modifications', 1.0000226488894637), ('different stairs', 1.0000226404079007), ('unknown sentiments', 1.0000226228720037), ('other hand heart', 1.000022620779034), ('cho et', 1.000022611935333), ('standard', 1.0000226115590307), ('identify relations', 1.0000226075990408), ('simultaneous', 1.000022601947943), ('phrase pairs', 1.000022597018411), ('dqns', 1.0000225956620152), ('architecture trained', 1.0000225882366902), ('fundamental challenge', 1.0000225871229647), ('multiply', 1.0000225847344077), ('spatiotemporal brain', 1.0000225735953174), ('perturbations denote', 1.000022571614914), ('determine', 1.0000225708298742), ('continuous space', 1.0000225698059833), ('discriminators', 1.0000225607884032), ('last year', 1.0000225573132964), ('systematic approach', 1.0000225520280828), ('single typhoon coordinates', 1.0000225479019502), ('metric', 1.0000225468226798), ('facial action', 1.0000225458026921), ('chinese english', 1.0000225436621133), ('disentangled latent', 1.0000225436061743), ('prominent challenges', 1.000022542801351), ('model assumes', 1.0000225389905595), ('multiple approaches', 1.0000225379393632), ('gain intuition', 1.000022537288272), ('novel machine', 1.0000225341510123), ('approximate posterior', 1.0000225296267706), ('moderate author', 1.000022528838553), ('exit', 1.000022528358324), ('system comprises', 1.000022521053646), ('reciprocal connections', 1.0000225017169468), ('relevant target', 1.0000224888089608), ('texts written', 1.0000224802134456), ('cognitive', 1.000022480148504), ('primary task', 1.0000224753229998), ('many sequence', 1.0000224664017705), ('novel information', 1.0000224613106294), ('medical prescriptions comparing', 1.000022459571308), ('natural way', 1.0000224544986533), ('advantage values', 1.0000224518856478), ('simple averaging', 1.000022451146463), ('sources provide', 1.0000224450094808), ('different situations', 1.00002243546768), ('linguistic phrases', 1.000022428134424), ('correct assembly', 1.0000224280581809), ('simple kbqa system', 1.0000224244115092), ('configurations', 1.0000224179945685), ('reverse time', 1.0000224161704687), ('vqa v1', 1.0000224116051855), ('results highlight', 1.0000224100709965), ('mechanisms guide', 1.000022394023032), ('standard searchlight analysis', 1.000022378201018), ('tracking seeing', 1.0000223768718608), ('auxiliary tasks', 1.000022375267399), ('fit', 1.0000223704894093), ('individual responses', 1.000022367838026), ('observation action', 1.00002235709576), ('thinker', 1.0000223541877504), ('interpretation', 1.0000223538776432), ('phonetic information', 1.0000223491924431), ('optimum', 1.0000223483788995), ('classification phase', 1.0000223317945134), ('popular used', 1.0000223294585902), ('tag', 1.0000223251245333), ('state evaluations', 1.0000223222007687), ('other', 1.000022315080174), ('new machinery', 1.0000223140779143), ('traffic', 1.0000223097107135), ('synergy', 1.0000223048494234), ('knowledge gained', 1.0000223008427767), ('discover objects', 1.0000222895539905), ('electronic', 1.0000222888915165), ('research works', 1.0000222842123627), ('harness flexibility', 1.0000222807906731), ('detailed reconstructions', 1.0000222677343986), ('lid architecture', 1.0000222595477632), ('program space', 1.000022254350978), ('future researchers', 1.0000222468055748), ('key element', 1.0000222464343373), ('synthetic task', 1.0000222441988815), ('longer report', 1.0000222367793807), ('novel search', 1.0000222255554527), ('high accuracy', 1.000022214878964), ('use running', 1.000022213656079), ('replicate', 1.0000222085841604), ('label quality', 1.000022204829935), ('better correspondence', 1.0000221938923737), ('second technique', 1.0000221833573077), ('nlu architecture', 1.0000221832417702), ('different variants', 1.0000221795956672), ('model keeps', 1.000022171356136), ('visualise', 1.0000221648726844), ('tensors', 1.0000221615565876), ('several popular', 1.0000221591046354), ('large popular', 1.0000221577113053), ('parameterizable transfer function', 1.0000221465333867), ('double articulation analyzer', 1.0000221465333867), ('explain', 1.0000221457096863), ('linear surrogate rnns', 1.0000221423950055), ('major breakthroughs', 1.0000221379250518), ('unseen images', 1.0000221299479921), ('weight space', 1.000022122395187), ('speaker', 1.0000221221259358), ('map adaptation', 1.0000221162107548), ('primate retina', 1.0000221142939039), ('bottom layers', 1.0000221128511055), ('recall', 1.0000221115744485), ('conventional sub', 1.0000221103766034), ('probability', 1.0000221102623048), ('traditional cnns', 1.000022109091045), ('vocabulary', 1.0000221046793683), ('proposed modification', 1.0000221041294757), ('more learners', 1.0000221021369298), ('manipulating', 1.0000220984812156), ('conditional', 1.0000220958718984), ('neurons m', 1.0000220952541106), ('applying knowledge', 1.0000220928483976), ('specific forms', 1.0000220890591447), ('new sentence', 1.000022083795533), ('past year', 1.0000220826070183), ('student model', 1.0000220781063747), ('small sample sizes', 1.0000220759046021), ('several types', 1.0000220757063052), ('closest', 1.0000220702891154), ('art vqa', 1.0000220623974456), ('language learning', 1.0000220519677303), ('recommendation task', 1.0000220406883362), ('lifelong learning', 1.0000220371729163), ('mechanism', 1.0000220354737954), ('important type', 1.0000220346684991), ('configurations yielding', 1.000022033450669), ('such divide', 1.000022032104444), ('linear transformations', 1.0000220274458218), ('cause', 1.0000220270858555), ('memorize', 1.0000220168966056), ('many high', 1.0000220052175464), ('weight tuning', 1.0000220027285598), ('recent years achieving', 1.0000220007442673), ('contents', 1.0000219977332085), ('common lexicon', 1.0000219954377334), ('dictionary elements', 1.000021989806307), ('larger number', 1.0000219855299644), ('align', 1.0000219851251988), ('audiences based', 1.000021984473307), ('optimise', 1.0000219833444575), ('geometric', 1.0000219707854772), ('pretraining evaluates', 1.000021970638741), ('motion prediction', 1.0000219678975142), ('modest sizes', 1.0000219635086844), ('regular autoencoders detailed', 1.0000219627206188), ('neocortex', 1.0000219581021084), ('costly lda', 1.0000219578576446), ('intrinsic goals', 1.0000219553526408), ('aggregated state', 1.0000219493241143), ('intersection', 1.0000219480581498), ('average f1', 1.0000219451712067), ('sensor measurements', 1.0000219402863653), ('smiles format', 1.0000219371236312), ('art accuracies', 1.000021933361794), ('future surveys', 1.000021930133861), ('fast', 1.0000219271323327), ('large gtrsim10', 1.000021926981736), ('invariant', 1.0000219243807413), ('tighter region', 1.0000219218838728), ('ignore conditioning', 1.000021921323996), ('significant engineering', 1.0000219165368547), ('apprenticeship learning', 1.0000219154699235), ('cross modal', 1.000021900740158), ('compress nmt', 1.0000218896147044), ('hippocampus known', 1.0000218896111022), ('considerable gains', 1.0000218857776637), ('memory aspects', 1.0000218773518743), ('typical sizes', 1.0000218748432617), ('driver number', 1.0000218647557721), ('modalities', 1.000021863779544), ('minimal hand', 1.0000218635165508), ('good affinity', 1.0000218629729984), ('new threshold', 1.0000218529891383), ('formal language', 1.00002185202115), ('general late', 1.0000218399409453), ('wordnet freebase', 1.000021834663092), ('distributional hypothesis', 1.0000218262216305), ('very policy', 1.0000218234061902), ('tcga database', 1.0000218209973464), ('knowledge learnt', 1.0000218160420502), ('trained system', 1.0000218149034028), ('small changes', 1.000021814386649), ('mid sized', 1.00002181097357), ('test perplexity', 1.0000218109477532), ('recurrent policy', 1.00002180949989), ('different authors', 1.000021807966524), ('particular long', 1.0000218022673188), ('special drop', 1.0000217967773741), ('complex value', 1.000021794738804), ('construction', 1.0000217917064185), ('action related', 1.000021774228065), ('further', 1.000021762517268), ('novel model', 1.0000217605671435), ('face', 1.0000217526097483), ('new variance', 1.0000217517410095), ('different channels', 1.0000217475652047), ('flow', 1.000021740453672), ('trainable', 1.0000217368229858), ('generalizable', 1.000021734886986), ('amount', 1.000021719907737), ('previous hboa runs', 1.0000217180817859), ('advantage', 1.0000217117062367), ('traditional vae', 1.0000217058763365), ('certain probability', 1.0000217016561386), ('many classical', 1.000021697803726), ('monoid', 1.0000216963110544), ('traditional context', 1.000021695455869), ('baggage scanner', 1.0000216913351336), ('different seeds', 1.0000216831640965), ('homework assignments', 1.0000216755626894), ('misspecified model', 1.000021674774636), ('sentence regions', 1.0000216730820286), ('general concave', 1.0000216619531284), ('go', 1.0000216578005012), ('proposed arguments', 1.0000216560632018), ('benchmark hearthstone', 1.0000216492555296), ('contrast dropout', 1.000021649169162), ('sufficient width', 1.0000216410612521), ('active', 1.0000216388271332), ('spikes', 1.0000216347843576), ('surroundings will', 1.000021633507793), ('unwanted', 1.0000216298249658), ('comprehensive study', 1.0000216043575583), ('dialogue domains', 1.000021602923385), ('atoms yielding', 1.0000215756076105), ('negative factor', 1.0000215734646862), ('target policy', 1.0000215589464803), ('brain comprises', 1.0000215580386056), ('misclassify', 1.0000215471599823), ('higher', 1.0000215320729222), ('answers', 1.00002153111224), ('new products', 1.0000215282376719), ('augmentation', 1.0000215233984981), ('fewer number', 1.0000215189847095), ('reactive settings', 1.0000215183728127), ('mass impulse', 1.0000215022785732), ('approach will', 1.0000215016252092), ('cdm', 1.0000214877075762), ('means', 1.0000214785539214), ('many orders', 1.0000214770407072), ('more', 1.000021469694394), ('many current', 1.0000214662249451), ('richer characterizations', 1.0000214653200605), ('emphasize', 1.000021464457524), ('disease prediction', 1.0000214628553108), ('human tool', 1.0000214597996802), ('training stage', 1.000021454595534), ('signals', 1.0000214522677306), ('synaptic connections', 1.0000214500142808), ('scheme compensates', 1.0000214329990476), ('transformations', 1.0000214264300462), ('medical applications', 1.000021421476648), ('date synthesis', 1.0000213876059223), ('human engineered', 1.0000213874774238), ('imagination steps', 1.0000213823900619), ('training phase', 1.0000213792181003), ('fasttext', 1.0000213783414384), ('painter can', 1.0000213771797375), ('attributes highlighted', 1.000021376927382), ('theoretical side', 1.0000213735705332), ('neighborhood information', 1.0000213706999548), ('complex synapses', 1.000021370091527), ('intervention method', 1.0000213556955604), ('navigation task', 1.0000213547098185), ('varying sizes', 1.000021353293338), ('statistical', 1.0000213436545717), ('advanced diagnostic', 1.0000213361377555), ('science engineering', 1.0000213355884338), ('building block', 1.0000213308325077), ('tentative experiment', 1.0000213248435466), ('average 5.1x', 1.0000213166666116), ('statistical model', 1.0000213078196298), ('multiple planning', 1.0000213062899903), ('trend', 1.0000213018129056), ('atoms collected', 1.000021298055857), ('understanding feed', 1.0000212974751008), ('centroid', 1.0000212937939115), ('old cyrillic', 1.000021282855123), ('direct policy', 1.0000212814802418), ('existing lyrics', 1.00002127576456), ('explicit attention', 1.0000212755587325), ('spatiotemporal activity', 1.0000212747889385), ('empirical investigation', 1.0000212675380824), ('frequency prediction', 1.0000212636526855), ('novel techniques', 1.0000212543332758), ('large training', 1.000021251947114), ('separate papers', 1.000021246004796), ('fruitful path', 1.0000212403428492), ('successive events', 1.0000212397632813), ('earthquake time', 1.000021236847685), ('further advantages', 1.0000212365840533), ('alternative models', 1.0000212324365776), ('recent renaissance', 1.0000212168309186), ('sign determined', 1.0000212161686792), ('classification types', 1.000021215639347), ('chemistry data', 1.0000212143645022), ('dual', 1.0000212102144188), ('investigate', 1.00002120520055), ('rfn learning', 1.000021197923317), ('increasing interest', 1.000021197581279), ('superior performance', 1.0000211871900888), ('certain transformations', 1.0000211803538688), ('drug name', 1.000021177898677), ('separate language', 1.0000211632815568), ('rule', 1.0000211518840165), ('caption', 1.0000211486230053), ('developed theory', 1.0000211377043744), ('nearby codes', 1.000021137099789), ('tests', 1.0000211356184923), ('closed loop', 1.0000211341003928), ('powerful models', 1.000021133556404), ('sparse pathway', 1.0000211256940905), ('scripts', 1.000021121448703), ('providing', 1.0000211166376527), ('mean average', 1.0000211100033032), ('first set', 1.0000211011697928), ('topical relevance', 1.0000210915387353), ('subcomponent', 1.0000210895961104), ('platforms', 1.000021088566637), ('accelerated', 1.0000210824570583), ('hankel matrix decomposition', 1.0000210772098086), ('qrnns bradbury', 1.0000210737563597), ('previous satellite images', 1.000021070165962), ('extractive summarisation', 1.0000210667844123), ('facial actions', 1.000021065095656), ('voice ear', 1.0000210628539956), ('lateral shortcut connections', 1.0000210596501358), ('malfunction', 1.0000210469737247), ('initial', 1.00002104654308), ('explicit supervision', 1.000021045252399), ('model sizes', 1.0000210447233062), ('future frame', 1.0000210390274724), ('remedy', 1.0000210388270643), ('art sub', 1.0000210382643968), ('satellite imagery', 1.0000210352764085), ('failure', 1.0000210272293246), ('qbot can', 1.000021004662778), ('tune', 1.0000210046052302), ('other techniques', 1.000021002177784), ('successful approach', 1.000020997834558), ('complex hand', 1.0000209924577543), ('close proximity', 1.0000209898988834), ('research community', 1.0000209851084232), ('window', 1.0000209846609556), ('clinical notes', 1.0000209748221107), ('random distribution', 1.0000209747547468), ('further research', 1.0000209737056678), ('covariance matrix', 1.0000209709077224), ('specific sentiment', 1.0000209344231907), ('results reported', 1.0000209219543814), ('label bias', 1.0000209216479967), ('pretraining achieved', 1.0000209176234767), ('approach exceeds', 1.0000209149607258), ('superficial correlations', 1.0000209145015218), ('surprising existence', 1.0000209142853496), ('searchlight analysis', 1.0000209139573495), ('chinese implicit', 1.000020911667411), ('seek', 1.0000209078019515), ('coherent manner', 1.0000209034841103), ('add capacity', 1.0000208970963274), ('dark knowledge', 1.0000208967114113), ('sudden', 1.0000208911941217), ('training question', 1.0000208890533688), ('overall classification', 1.0000208885115875), ('high noise', 1.0000208881509265), ('explaining', 1.000020887877514), ('diagnostic purpose', 1.0000208811016646), ('bioactivity prediction', 1.000020880781846), ('novel vector', 1.0000208700784297), ('language story', 1.000020862540027), ('lstm baseline', 1.0000208619151976), ('critical part', 1.0000208451746628), ('normal situation', 1.0000208433554374), ('straight path', 1.0000208414181253), ('alexnet structure', 1.0000208360021836), ('digits', 1.0000208275522007), ('prediction horizons', 1.0000208104696393), ('resnet', 1.0000208082858917), ('morphology', 1.0000208076535264), ('effective advertisements', 1.0000208067712308), ('individual words', 1.0000208048312846), ('important task', 1.0000207985977712), ('resulting sequence', 1.0000207970582204), ('transductive inference', 1.0000207967736234), ('metaphor', 1.0000207966626034), ('worst performs', 1.000020793185857), ('larger question', 1.000020781905937), ('broad range', 1.0000207791466391), ('leverage', 1.0000207748357413), ('electronic health record', 1.0000207748007999), ('multiple microphone', 1.0000207718358098), ('universal noise', 1.000020769203039), ('approach formulates', 1.0000207669175534), ('such capacity', 1.0000207566763424), ('fuzzy dgp representation', 1.0000207544970081), ('relate self', 1.0000207500065188), ('uncertainty', 1.0000207492969415), ('transducer', 1.0000207470486195), ('true value', 1.0000207441880027), ('categorize', 1.0000207430730306), ('motion', 1.0000207352041501), ('novel theory', 1.0000207279316033), ('improve recommendations', 1.0000207169991018), ('approach uses', 1.0000207141745827), ('neocortical areas', 1.0000207079470422), ('task b', 1.0000207075207757), ('units', 1.000020703192289), ('clinical', 1.0000206873360988), ('pipe', 1.000020686847605), ('track', 1.000020684726323), ('ear piece', 1.0000206835260683), ('facilitate', 1.0000206793117734), ('consistent', 1.0000206740971636), ('popular view', 1.0000206732247898), ('individual modalities', 1.0000206521946244), ('group theoretic', 1.0000206400016671), ('classification results', 1.0000206360522803), ('truncation', 1.0000206268063683), ('generic', 1.00002062580874), ('various label noises', 1.0000206252919517), ('diagnostic process', 1.000020625122239), ('speaker differences', 1.0000206244572007), ('youtube', 1.0000206208568942), ('design clothes', 1.0000206197431305), ('molecules used', 1.0000206171306296), ('temperature parameter', 1.0000206076966067), ('disconnected decision', 1.0000206058779304), ('pretraining iterations', 1.0000205847537045), ('second step', 1.000020576881491), ('difficulty', 1.0000205737461432), ('attentive mixture', 1.0000205720147197), ('elicit', 1.0000205605374348), ('enrich libraries', 1.000020560455403), ('alternative manner', 1.0000205592310698), ('various label', 1.000020535906279), ('simplified attention', 1.0000205341481676), ('limited resources', 1.0000205317045907), ('differences', 1.0000205296404612), ('solution', 1.0000205256018972), ('nmt', 1.0000205215941145), ('meaningful regions', 1.0000205142474983), ('yield', 1.00002049841436), ('parametrize', 1.000020496798844), ('trainable task', 1.00002049161504), ('various noise', 1.0000204877947656), ('levels', 1.00002048775281), ('several cross', 1.0000204829785226), ('alternative', 1.0000204813395404), ('simulate heredity', 1.000020469442453), ('vocabulary words', 1.0000204603696452), ('forests icebergs', 1.000020452300407), ('activity gradients', 1.0000204466161757), ('reconstruct', 1.0000204451188053), ('play time', 1.0000204436846338), ('significant fraction', 1.0000204436182336), ('test samples', 1.0000204424607775), ('external', 1.0000204400477672), ('chain', 1.0000204304789677), ('low rank mvn', 1.0000204105692567), ('mathematical morphology', 1.0000203965057992), ('tanh', 1.0000203775568828), ('huge training', 1.0000203350431867), ('various candidate', 1.0000203296812917), ('different weights', 1.000020318509512), ('many sentence', 1.000020318152249), ('similar challenges', 1.0000203162726895), ('speech perception', 1.000020301733718), ('multiple research disciplines', 1.0000202998464385), ('labels corrupted', 1.0000202876912898), ('blackout', 1.0000202873903177), ('major categories', 1.0000202804049834), ('different sizes', 1.0000202784539716), ('reason', 1.0000202772253435), ('mass gathering', 1.0000202723458425), ('evolution', 1.000020265298886), ('time bptt', 1.0000202534097329), ('human eyes', 1.000020249407385), ('new technique', 1.000020246983831), ('novel aspect', 1.000020243682812), ('snli corpus', 1.0000202433313068), ('dropout can', 1.0000202361131958), ('rl techniques', 1.000020224942498), ('chemistry domain', 1.0000202042366193), ('combat', 1.000020200004962), ('easier', 1.000020195436649), ('class non', 1.0000201932358928), ('knowledge graph', 1.0000201888854312), ('rl agent', 1.0000201878922226), ('good predictor', 1.0000201840939063), ('single step', 1.0000201811818739), ('utilize', 1.0000201722938253), ('relation', 1.0000201662589674), ('contemporary fmri', 1.0000201639813524), ('hybrid training', 1.0000201628459477), ('candidate ones', 1.0000201620055669), ('proper conditioning', 1.00002015833355), ('translation selection', 1.000020153325536), ('collections', 1.0000201530133275), ('sensorimotor', 1.0000201326488838), ('digital mammography', 1.0000201274175475), ('representative phrases', 1.0000201217170308), ('simple technique', 1.0000201197681335), ('variational posteriors', 1.000020117062167), ('amplifying biases', 1.0000201144473162), ('target vocabulary', 1.0000201140104636), ('rich form', 1.000020113300435), ('encourage progress', 1.0000201121842953), ('cifar10 benchmark', 1.0000201111967304), ('standard imitation', 1.0000201107881135), ('other researchers', 1.0000201054077553), ('important part', 1.000020095425175), ('nominal pairs', 1.000020091921045), ('common sense', 1.0000200918015165), ('explicit self', 1.0000200911390533), ('minibatch', 1.0000200881344885), ('train atns', 1.0000200789212645), ('bird images', 1.000020078718621), ('reward', 1.0000200738991833), ('neural heart', 1.0000200732421838), ('attention discards', 1.0000200728771136), ('crucial ways', 1.0000200683213292), ('develop dialogue', 1.0000200663937828), ('fivo results', 1.000020065566348), ('experiments use', 1.0000200649152784), ('camera', 1.0000200639059476), ('label smoothing', 1.0000200430356248), ('effective technique', 1.0000200344396886), ('regular deconvolution operations', 1.0000200260125527), ('gans share', 1.000020025823042), ('presence', 1.0000200220961704), ('environmental speaker channel', 1.0000200219651545), ('protect patients', 1.0000200210183814), ('work extends', 1.0000200133960389), ('interpretable skills', 1.0000200123108947), ('previous classes', 1.000020006711832), ('whole words', 1.0000200044217888), ('new combinations', 1.0000199994561971), ('unk symbol', 1.000019998164443), ('compact model', 1.0000199965013559), ('detecting', 1.0000199899284756), ('stories', 1.00001998724638), ('significant drop', 1.0000199805795646), ('size created', 1.0000199666691405), ('generating headlines', 1.0000199571211006), ('training can', 1.0000199559108374), ('structured noise maesn', 1.0000199537149663), ('intra parcel variance', 1.0000199537149663), ('temporal attention gme', 1.0000199537149663), ('observation', 1.0000199496716804), ('spatial correlates', 1.000019942393331), ('schemes', 1.0000199327061803), ('learned policy', 1.000019928332121), ('meaningful sentences', 1.0000199188305714), ('several properties', 1.0000199177274578), ('sensor', 1.000019914202061), ('large margins', 1.0000199052827874), ('phonetic recogniser', 1.000019901729932), ('dominant approach', 1.0000198957829336), ('experiments illustrate', 1.000019893658232), ('range', 1.0000198928096158), ('amplify', 1.0000198834332368), ('saliency demonstrated', 1.000019883197595), ('numerous natural', 1.0000198807026333), ('stream', 1.0000198765145785), ('run', 1.0000198725028404), ('montreal institute', 1.0000198723576974), ('human response', 1.00001986340947), ('lightweight kalman', 1.0000198632325465), ('simplex', 1.000019850077041), ('psychophysical behavior', 1.0000198477834201), ('sum', 1.0000198409468517), ('aforementioned recurrent', 1.0000198409437848), ('long chain', 1.0000198396500715), ('simultaneous training', 1.000019839504684), ('special regime known', 1.0000198271480882), ('knowledge completion', 1.0000198230325126), ('frequency shifts', 1.0000198177617623), ('symbols using', 1.0000197984632364), ('real life', 1.0000197890293736), ('tensor valued', 1.0000197840196592), ('years hints', 1.000019783394922), ('rl use', 1.0000197820443673), ('modified model', 1.0000197790209058), ('next words', 1.0000197715771735), ('multiple related', 1.0000197686638368), ('weight compression', 1.000019768588805), ('linearity', 1.0000197659978296), ('assessing sentence', 1.000019765477285), ('questioner figures', 1.0000197616159443), ('rely', 1.0000197611843507), ('30s test', 1.0000197582907329), ('hand craft', 1.0000197544606044), ('issues related', 1.0000197478440818), ('proposed fast', 1.0000197422142543), ('broad attention', 1.0000197389075716), ('ensure', 1.0000197382778484), ('model ranked', 1.0000197299100078), ('contrary humans', 1.0000197190389681), ('potential influence', 1.000019716793123), ('residual', 1.0000197023412243), ('sound types', 1.0000197002308573), ('pure', 1.000019699919884), ('decoder relieve', 1.0000196930719292), ('rbp including', 1.0000196866224893), ('second sub', 1.000019664504781), ('new questions', 1.000019660574975), ('label units', 1.0000196584518282), ('geometric structure', 1.0000196541135378), ('propagation', 1.0000196496590485), ('different ways', 1.000019649052892), ('notable feature', 1.000019644987119), ('rectified factor', 1.0000196331196947), ('line lengths', 1.0000196249022557), ('proof', 1.0000196193294417), ('major trend', 1.0000196171122135), ('different fractions', 1.0000196116235114), ('nuclear norm', 1.00001960928247), ('complex one', 1.0000196063437392), ('multistep', 1.0000196046970673), ('improve confidence', 1.0000196009144584), ('r n', 1.0000195970251808), ('different discourse', 1.0000195952015123), ('libraries', 1.0000195889908607), ('art part', 1.000019569793424), ('proposed tracker', 1.0000195667659908), ('network srn', 1.0000195608778353), ('width', 1.0000195589480214), ('equivalence', 1.0000195587707392), ('corrupted labels', 1.0000195513397183), ('small sample', 1.0000195479998417), ('full', 1.00001954655026), ('observed time', 1.000019543313259), ('synaptic traits', 1.0000195379056713), ('policies', 1.000019535678123), ('crowd behavior', 1.0000195338718019), ('particles appointed', 1.0000195243991554), ('such automated scorers', 1.0000195217390362), ('new coarse', 1.0000195085820238), ('diffuse noise', 1.0000195084840016), ('skeleton sequence', 1.00001950786678), ('dnn acts', 1.0000194968022804), ('transformations exhibited', 1.0000194958091206), ('loop', 1.0000194916496818), ('particle', 1.0000194912437237), ('several dialogue', 1.0000194909225697), ('unique characteristics', 1.0000194888366518), ('applying growcut', 1.000019484439385), ('localized', 1.0000194806246046), ('weston et', 1.000019469438568), ('other pairs', 1.000019442365198), ('region growing', 1.0000194419487587), ('record performance', 1.0000194405966019), ('external sources', 1.0000194405705654), ('tele presence', 1.000019438007927), ('results reveal', 1.000019433768794), ('curriculum', 1.0000194255012909), ('synthetic', 1.000019420026951), ('superior object', 1.0000194197920995), ('traditional heart', 1.0000194078564184), ('transpose', 1.0000193918857625), ('second confidence', 1.0000193851085164), ('complex matrices', 1.0000193806693465), ('nearest generalisations', 1.0000193670599404), ('base', 1.0000193602270533), ('decide', 1.0000193445403147), ('qa', 1.0000193351054296), ('compositional solution', 1.0000193229564367), ('classical notions', 1.000019321292054), ('sgd', 1.0000193205865653), ('envision', 1.0000193103097579), ('flexible', 1.0000193058253457), ('curved components', 1.0000193040348648), ('convnet', 1.0000193021277302), ('networks lenet', 1.0000192959043324), ('unique ground', 1.000019295439819), ('top level', 1.0000192948711069), ('exist', 1.000019290283398), ('training procedures', 1.0000192828502656), ('overlap', 1.0000192806259338), ('compositional process', 1.0000192728584136), ('molecular', 1.0000192719079264), ('wang et', 1.000019270364063), ('analog', 1.0000192639015226), ('objectives', 1.0000192602800306), ('bilinear', 1.0000192519606135), ('reconsiders', 1.000019248641453), ('unprecedented size', 1.0000192447250982), ('approach involves', 1.0000192434121682), ('different perspectives', 1.0000192419617222), ('target sentence', 1.0000192379496715), ('gene ontology', 1.0000192368113794), ('generalizability', 1.000019223318172), ('accomplish', 1.0000192232118097), ('novel explanation', 1.000019214544129), ('different size', 1.0000192142155644), ('fitness inheritance', 1.0000192116132602), ('many ways', 1.0000192106661334), ('testing segments', 1.0000192041662492), ('very large', 1.0000191994836438), ('final task', 1.0000191775413425), ('triplet loss', 1.0000191760650103), ('subsequent stage', 1.000019175470884), ('art alternative', 1.0000191746142904), ('factor interactions', 1.0000191713402964), ('invalid lstm', 1.000019169740424), ('rnnlm training', 1.0000191550121351), ('sanity', 1.00001915144163), ('overlap percentage', 1.0000191471287392), ('variational posterior', 1.0000191470780824), ('network grnn', 1.0000191464335457), ('educational setting', 1.0000191396505713), ('whole', 1.0000191305868251), ('textual', 1.000019130104002), ('maxout units', 1.0000191227456723), ('topic mixing', 1.000019120563454), ('hottest topics', 1.000019117594536), ('genomics should', 1.0000191147547923), ('probability mass', 1.0000191144083768), ('observational data', 1.000019110759832), ('transcribe', 1.0000191045369418), ('la belled data', 1.000019097967777), ('actions taken', 1.0000190933731168), ('pls latent', 1.0000190873905042), ('raw sentence', 1.000019078557266), ('deeper', 1.0000190751967901), ('perplexities', 1.0000190700416165), ('combine', 1.0000190681686325), ('spike', 1.0000190673645981), ('classic classification', 1.000019064116509), ('advanced', 1.0000190589910993), ('neuron', 1.0000190576772685), ('direction', 1.0000190522889014), ('re construct', 1.0000190458528246), ('multiple research', 1.0000190433411003), ('synaptic clustering', 1.0000190391601835), ('large span', 1.0000190379325244), ('waveforms', 1.0000190376592326), ('original cnn', 1.0000190374513758), ('original', 1.0000190369098), ('outlier bands', 1.0000190348976044), ('compositional procedure', 1.000019033703202), ('acoustic source', 1.0000190325822051), ('consistent groups', 1.000019032569413), ('particular translational', 1.0000190308115298), ('toy pomdp', 1.000019028469777), ('tweet', 1.000019027363584), ('connection', 1.0000190231194928), ('inject', 1.0000190205544377), ('results motivate', 1.0000190164718472), ('competence progress', 1.000019004326376), ('transition', 1.0000189953505854), ('future feature', 1.000018992050049), ('first uses', 1.0000189882122166), ('less contrast', 1.0000189817527183), ('high number', 1.0000189817024574), ('information theory', 1.0000189807012005), ('adapting', 1.000018978838998), ('gps', 1.0000189735036698), ('parametrization', 1.0000189731961189), ('mammalian brain contains', 1.0000189716318), ('original models', 1.0000189678106075), ('general family', 1.000018964325274), ('spurious', 1.000018958856513), ('implicit curriculum', 1.0000189544006908), ('remove gender', 1.0000189526430248), ('mathematical concept', 1.000018952268272), ('dqn ddpg', 1.0000189384774618), ('learned transformations', 1.0000189316735872), ('musical pitch', 1.0000189279224665), ('sentence meanings', 1.000018926265867), ('production knowledge', 1.0000189259095256), ('aspects found', 1.0000189257965781), ('scatter can', 1.000018920561131), ('great degree', 1.0000189074320265), ('latest state', 1.0000189067197636), ('implicit discourse', 1.0000189030624755), ('various factors', 1.0000189022035497), ('addressed', 1.0000189007724536), ('dropout strategy', 1.0000188965635108), ('earlier results', 1.0000188945155748), ('experience', 1.00001888823724), ('translations', 1.0000188806515349), ('inertia classify', 1.000018876941799), ('man', 1.0000188733889164), ('concrete method', 1.0000188689598455), ('parameter moduli', 1.000018868898016), ('experiments illustrating', 1.0000188681739777), ('language impairments', 1.0000188627528297), ('results expose', 1.0000188609143403), ('actual fitness', 1.0000188453675298), ('quantitative localization', 1.0000188387129878), ('communication strategy', 1.0000188334720546), ('work uncovers', 1.0000188237861962), ('inter beat intervals', 1.0000188200800277), ('behavior compensating', 1.000018812303624), ('dnn adaptation', 1.000018807170864), ('deep stock market', 1.0000188033700523), ('arrange', 1.0000188006782749), ('mtl', 1.0000187892118895), ('supporting nmt', 1.0000187880960896), ('x ray', 1.0000187862007002), ('clusters', 1.0000187720719957), ('abstract shapes', 1.0000187711728172), ('powerful directed', 1.0000187695066847), ('discourse relation', 1.0000187676969734), ('conditioning vector', 1.0000187590688503), ('custom', 1.000018748691394), ('propose taking', 1.0000187426319789), ('benefit people', 1.0000187400611567), ('diversity measure', 1.0000187223909072), ('interest can', 1.000018715625019), ('kdd cup', 1.000018701478778), ('human marking', 1.000018698672103), ('extended duration', 1.00001869695063), ('learn discriminating', 1.0000186806341629), ('vgg face', 1.0000186760263514), ('rapid', 1.0000186756770773), ('same effectiveness', 1.000018668029106), ('models work', 1.0000186609319979), ('continuous sentences', 1.000018655574796), ('indoor images', 1.0000186554103945), ('valuable knowledge', 1.0000186524419716), ('8.', 1.0000186511860043), ('difficulties encountered', 1.0000186491981846), ('tighten', 1.0000186436007137), ('approaches treat', 1.0000186370388677), ('current natural', 1.000018631689698), ('results attained', 1.0000186289463062), ('final loss', 1.0000186262727309), ('critical step', 1.000018625528852), ('margin based', 1.0000186211507893), ('understand gene', 1.0000186196824137), ('expectation', 1.0000186169984369), ('proximity', 1.0000186070071566), ('conventional feed', 1.0000186021074893), ('abundant data', 1.0000186007315603), ('dmn', 1.0000185990466237), ('rapid growth', 1.0000185974540459), ('similar scenes', 1.0000185851899228), ('last one', 1.0000185850548073), ('galaxy images', 1.0000185846319039), ('learner texts', 1.0000185762846467), ('social insect', 1.0000185540401907), ('exogenous contrast', 1.0000185531128227), ('clear', 1.0000185462941955), ('dimension', 1.0000185422090249), ('new end', 1.0000185402015227), ('specific photographs', 1.0000185349050426), ('adaptive locomotion', 1.000018529531524), ('third technique', 1.00001852289594), ('structures', 1.0000185200859986), ('broken records', 1.0000185182830654), ('things', 1.000018515183684), ('same way', 1.0000185140864568), ('adversaries', 1.0000185120082867), ('nse models', 1.0000185080500958), ('density advantages', 1.0000185068446246), ('sluice networks', 1.0000185059746705), ('recover', 1.0000185023378574), ('human rappers', 1.0000185019458436), ('utterances', 1.0000184998745116), ('practical issues', 1.0000184923628304), ('contrastive', 1.0000184868781081), ('pls', 1.0000184866232076), ('planning', 1.0000184860858885), ('emotion lexicon expansion', 1.0000184827550178), ('causality analysis', 1.000018475328956), ('best morpheme', 1.0000184716288818), ('method beats', 1.0000184691398843), ('time may', 1.0000184661877392), ('single utterances', 1.0000184657899498), ('mmd measure', 1.0000184609970197), ('squad corpus', 1.000018460235595), ('situ hybridization', 1.0000184498248021), ('alter', 1.0000184484533505), ('closest fit', 1.0000184479298737), ('action types', 1.000018441109735), ('negligible loss', 1.0000184348718912), ('use curriculum', 1.0000184308056461), ('natural benign', 1.000018428740836), ('de novo', 1.0000184245343495), ('transmission rate', 1.0000184244773849), ('final model', 1.0000184240661154), ('nist openmt12', 1.0000184235722926), ('chemical property', 1.0000184162618662), ('presented experiments', 1.0000184156247707), ('seed', 1.0000184103522969), ('selective generation', 1.000018407272886), ('plausible answer', 1.0000184050545735), ('normal activities', 1.000018397223937), ('real transduction', 1.0000183918622112), ('digit classification', 1.0000183751842695), ('unseen categories', 1.000018372253193), ('current unit', 1.0000183719931492), ('initializations', 1.000018371577917), ('formulations include', 1.000018368241384), ('setting', 1.0000183655060775), ('different part', 1.0000183602810255), ('other individuals', 1.0000183558965734), ('hierarchical dqn', 1.0000183518668075), ('neurons engaged', 1.0000183505806208), ('decoy answers', 1.0000183432409078), ('conventional phonetic', 1.0000183291539158), ('spatial attention', 1.0000183190194782), ('conceptual', 1.0000183088149153), ('large pool', 1.0000183078474842), ('advanced chemical', 1.0000183064489052), ('standard searchlight', 1.000018297695182), ('vice versa', 1.0000182832413942), ('tar get', 1.000018276789774), ('shallow pattern', 1.0000182712641548), ('advent', 1.0000182671005553), ('geometrical measure', 1.0000182600796705), ('focused', 1.0000182569779679), ('policies trained', 1.0000182522849115), ('neural enquirer', 1.0000182443518886), ('results reach', 1.00001824365917), ('distal reward', 1.0000182318586834), ('motor actions', 1.0000182316622874), ('evaluations', 1.000018229153824), ('varied samples', 1.0000182229368193), ('subject', 1.000018213621924), ('daume iii', 1.0000182131226973), ('series', 1.0000182100093002), ('aspect', 1.0000182078268973), ('simpler designs', 1.0000182069316157), ('dropout rates', 1.0000182035576464), ('small variations', 1.0000182032067568), ('position', 1.0000181970785142), ('cardiac dynamics', 1.000018197052223), ('community', 1.0000181891603808), ('large extent', 1.000018186690387), ('events', 1.000018166168382), ('interpretable cells', 1.0000181625804174), ('avoid', 1.000018161169503), ('compact feature', 1.0000181600212341), ('continual lifelong', 1.000018159786217), ('cortical processing', 1.0000181506137915), ('variable', 1.000018140741884), ('pixeldcl may', 1.0000181340469059), ('many training', 1.0000181284735812), ('probabilities', 1.0000181284136744), ('collect lending', 1.0000181279118152), ('cross selling', 1.000018122800007), ('multiplication', 1.0000181214117967), ('drive', 1.000018120342071), ('part explained', 1.0000181200159008), ('review', 1.0000181153819505), ('curse', 1.0000181105517845), ('complex statistics', 1.0000181054747237), ('style', 1.0000180998272834), ('smart phones', 1.0000180972250674), ('tensor', 1.0000180943545576), ('several strengths', 1.0000180787806123), ('medicinal chemists', 1.0000180739668196), ('popular mdp', 1.0000180673122052), ('linguistic regularities', 1.0000180652951511), ('factor model', 1.0000180551042548), ('more gradual', 1.0000180499147304), ('sound sources', 1.0000180313893152), ('observational features', 1.000018028285009), ('conventional curriculum', 1.000018026360907), ('stock trading', 1.0000180263121565), ('multiple timescales', 1.000018021813776), ('sequential lms', 1.0000180203688034), ('devastating consequences', 1.0000180151335796), ('environment leading', 1.0000180143491915), ('cd', 1.0000180102939655), ('building', 1.000018008610904), ('causal accuracy', 1.0000180071623825), ('regions salient', 1.000018000553694), ('distant time', 1.0000179960054234), ('double articulation', 1.0000179861211362), ('key ingredient', 1.0000179856128477), ('local state', 1.0000179830001663), ('rap lyrics', 1.0000179772636175), ('comparative results', 1.0000179730230099), ('inject corpus', 1.000017970992751), ('long snake', 1.0000179689969706), ('art system', 1.000017964165039), ('cognitive tasks', 1.0000179625993884), ('threshold', 1.0000179600374317), ('instability problem', 1.0000179524114161), ('stationary part', 1.0000179517244578), ('many disciplines', 1.0000179490914596), ('compelling results', 1.0000179360954777), ('extraction procedure', 1.0000179319540785), ('predictron accumulates', 1.0000179289385371), ('shortlist vocabulary', 1.0000179262278803), ('slots', 1.0000179259597415), ('power efficiency', 1.0000179163657839), ('movie reviews', 1.0000179121684043), ('tackle', 1.000017911876825), ('success', 1.000017909939414), ('new techniques', 1.0000179054630878), ('language variation', 1.0000178841451413), ('vast number', 1.0000178812647074), ('tamil translation', 1.0000178776650401), ('intermediate stages', 1.0000178662823804), ('planner trained', 1.000017859824505), ('important facet', 1.0000178557669779), ('scientific publications', 1.0000178545744864), ('affinity', 1.00001785319331), ('general conditioning', 1.0000178525738923), ('hboa efficiency', 1.0000178518286333), ('conventional training', 1.0000178434914941), ('proposed sans', 1.0000178335017795), ('script', 1.0000178235206083), ('fourth generation', 1.0000178070761958), ('entire duration', 1.000017799340739), ('pendubot swing', 1.0000177956632048), ('expectation semiring', 1.0000177956632048), ('optical anomalies', 1.000017793871757), ('approach seeks', 1.0000177718827572), ('art sentiment', 1.0000177664085603), ('such effects', 1.0000177601171454), ('actual training', 1.0000177597706075), ('tuning size', 1.000017748879914), ('new terms', 1.0000177462897433), ('poor predictor', 1.0000177437777356), ('industrial benchmark', 1.0000177429905506), ('learn associations', 1.0000177338552152), ('narrative context', 1.0000177312174878), ('left', 1.0000177296732435), ('bilinear relational', 1.000017726963105), ('shallower ones', 1.00001772112694), ('recent studies', 1.0000177102271464), ('device variability', 1.0000176975854556), ('longitudinal scenarios', 1.0000176967458814), ('art proximity', 1.0000176962234857), ('submodular diversity', 1.000017693758539), ('physics', 1.0000176920133312), ('alternative semi', 1.0000176881274014), ('acoustic units', 1.0000176723878447), ('standard mctest', 1.0000176701637014), ('real brains', 1.0000176700001846), ('positive results', 1.000017669615828), ('short piece', 1.0000176682296067), ('behaviour trained', 1.0000176628923771), ('novel structure', 1.000017652731944), ('acoustic frames', 1.0000176520932036), ('first technique', 1.0000176510988859), ('study shows', 1.0000176480392955), ('cases', 1.0000176424712504), ('vgp achieves', 1.000017630092016), ('capacity training', 1.0000176252538384), ('highway networks', 1.0000176207385665), ('distributions', 1.0000176105420908), ('past years', 1.000017608773056), ('overcomplete kernel', 1.0000176042787459), ('highway', 1.000017595805738), ('eye movement', 1.0000175952852868), ('sensors', 1.0000175940892642), ('ordinal categories', 1.0000175919873955), ('detailed', 1.000017591548964), ('new stage', 1.000017583721448), ('appropriate words', 1.0000175825994324), ('environmental speaker', 1.0000175801741844), ('generalized', 1.000017577966912), ('art phrase', 1.0000175746662254), ('rate', 1.0000175720106401), ('building trust', 1.000017567036331), ('challenging conditions', 1.000017567036331), ('cluding machine', 1.000017567036331), ('local', 1.0000175642040556), ('segment', 1.000017564059806), ('body parts', 1.0000175582573414), ('neurobiological phenomenon', 1.000017554458254), ('capacity convexity', 1.0000175491627867), ('few tens', 1.0000175447816981), ('universal standard', 1.000017543542793), ('morpheme level', 1.000017542399098), ('limited adaptation', 1.0000175377151046), ('great detail', 1.0000175375921305), ('past decade', 1.0000175329144125), ('words queen', 1.000017530937146), ('constant rate', 1.000017508604649), ('high value', 1.0000175069225348), ('adequate fusion', 1.0000175056850265), ('strategy', 1.000017504581366), ('recurrent ladder', 1.0000175011004302), ('paragraph', 1.000017500714199), ('approximate size', 1.0000174983511656), ('english translation', 1.0000174958871104), ('finer fusion', 1.0000174915976356), ('new perspective', 1.0000174889309923), ('value', 1.0000174889249842), ('fingerspelled letter', 1.0000174874937806), ('closed', 1.0000174790656928), ('direct strategies', 1.00001747875646), ('cheat', 1.000017475146491), ('task passed', 1.0000174741950096), ('automatic tightening', 1.000017464887164), ('disaster management', 1.0000174510978226), ('literature', 1.0000174369729096), ('recovery', 1.0000174367970434), ('others dates', 1.000017431108227), ('experts poe', 1.0000174303146478), ('stark contrast', 1.0000174301337792), ('distances', 1.0000174276924843), ('clinical environment', 1.0000174242813569), ('single cpg', 1.000017423311283), ('next generation', 1.0000174170039084), ('novel combinations', 1.0000174003480828), ('combat training', 1.0000173979387683), ('sketch', 1.000017397260593), ('practical discourse', 1.000017392813848), ('hand tailored', 1.0000173916641453), ('paper presents', 1.0000173909150976), ('quantitative rhyme density', 1.000017389338062), ('movie distances', 1.0000173780829142), ('direction following', 1.0000173714564702), ('torques problem', 1.0000173710395457), ('galaxy morphology classification', 1.0000173673583914), ('small molecules', 1.0000173645971406), ('smaller number', 1.0000173571571283), ('textual story', 1.0000173547216324), ('minor perturbations', 1.0000173517517528), ('good flow', 1.0000173513185742), ('term gravitation', 1.000017349207041), ('sentence meaning', 1.0000173481607209), ('potential actions', 1.0000173462830717), ('tandem models', 1.0000173460941728), ('smaller models', 1.0000173458655388), ('approach leads', 1.0000173425931866), ('questioner owing', 1.0000173408699033), ('experiments verify', 1.000017317377011), ('correlation', 1.0000173163619936), ('prolific activity', 1.000017313359926), ('unidirectional rnn', 1.000017312184076), ('psychological evidence', 1.0000173083131276), ('imitation', 1.0000172866007493), ('large action', 1.000017286537522), ('granger causal', 1.0000172828470668), ('interactions', 1.0000172817464372), ('enhance diagnosis', 1.0000172811172028), ('most models', 1.0000172780930279), ('networks qrnns', 1.0000172725493115), ('paper surveys', 1.000017264553345), ('aforementioned rnn', 1.000017263988156), ('academic research', 1.0000172601353314), ('optical', 1.000017260097814), ('depth investigation', 1.0000172490464867), ('inefficient distribution', 1.000017247717455), ('unfolding model', 1.0000172461003496), ('dropout dropconnect', 1.0000172442506974), ('adjacent', 1.000017244016779), ('auxiliary capacity', 1.0000172439332007), ('psychological experiments', 1.0000172435770538), ('measure progress', 1.0000172365759947), ('multipliers admm', 1.0000172345406118), ('unstructured data', 1.0000172281947324), ('sole source', 1.000017220134097), ('small minibatch', 1.0000172178431836), ('large contribution', 1.0000172112156016), ('name variation', 1.0000171985098842), ('accurate tuning', 1.0000171928234827), ('effect', 1.0000171896599734), ('recurrent cell', 1.000017185637506), ('novel word', 1.0000171824993058), ('simpler', 1.0000171701650244), ('gender recognition', 1.0000171620012777), ('traditional aco', 1.0000171601696444), ('integrate evidence', 1.0000171526338817), ('standard mctest dataset', 1.0000171498017574), ('constructions lead', 1.000017145927019), ('cells connectivity', 1.0000171435575012), ('sequencing given', 1.0000171392163528), ('strong', 1.0000171374407312), ('policy causes', 1.0000171371973614), ('bias amplification', 1.0000171344099096), ('glm', 1.0000171322652878), ('evaluations demonstrate', 1.0000171318413131), ('lstm remembers', 1.0000171295445752), ('joint sentence', 1.000017121210627), ('diverse dialogue', 1.00001711357767), ('compact dnn approaching', 1.0000171113889018), ('mid level', 1.0000171085251512), ('sca performs', 1.000017106436905), ('box', 1.0000171048776172), ('likely locations', 1.000017100052151), ('fitted q', 1.0000170916672195), ('nmts tend', 1.000017091535652), ('notations', 1.0000170902495085), ('assess reading', 1.0000170855174453), ('common', 1.0000170823411552), ('actual meaning', 1.0000170762082932), ('overwhelm', 1.0000170614546835), ('art translation', 1.00001705623782), ('management', 1.0000170536060446), ('cases transferability', 1.00001705106689), ('initial stages', 1.0000170449801797), ('predict surrounding', 1.0000170408127058), ('encourage', 1.000017037581373), ('model background', 1.0000170372339643), ('near state', 1.0000170363393912), ('functional gene', 1.0000170303486586), ('costly handcrafted', 1.0000170301630675), ('illustrate', 1.0000170256818668), ('important regions', 1.0000170190494126), ('recommend', 1.0000170124633827), ('second issue', 1.0000170091565665), ('normals', 1.0000170083403201), ('convnets predictions', 1.0000170076966004), ('teacher', 1.0000170012863994), ('trip', 1.0000169972062507), ('fear', 1.0000169875287408), ('universal', 1.0000169866184674), ('synthetic sequence', 1.0000169724138892), ('second part', 1.0000169635159573), ('historical satellite', 1.000016958136147), ('formulation', 1.0000169541984851), ('networks rlstm', 1.000016953278206), ('relevant', 1.0000169505237788), ('structural feature', 1.0000169444676936), ('equal size', 1.0000169421801148), ('modern', 1.0000169415082378), ('take', 1.0000169343792522), ('full utterances', 1.0000169269174506), ('cognitive process', 1.0000169257208693), ('great strides', 1.0000169206788574), ('natural connection', 1.000016920400308), ('variance', 1.0000169166641215), ('novel chemical', 1.0000169157760135), ('tightening', 1.0000169114315587), ('simple defences', 1.0000169107907149), ('universality', 1.0000169095530098), ('mimic de', 1.0000169090474385), ('space occupancy', 1.0000169077470376), ('sudden drift', 1.0000168933552935), ('synthesize', 1.000016889454129), ('talk', 1.0000168892389127), ('formulation scales', 1.0000168797974922), ('abrupt erasure', 1.0000168734539967), ('ones', 1.000016871399328), ('policy space', 1.0000168641460694), ('approach links', 1.0000168606588684), ('stock market', 1.0000168495156116), ('sentence characteristics', 1.0000168494499335), ('maximum mean', 1.0000168492176245), ('memory skills', 1.000016842587505), ('highway connections', 1.0000168423462068), ('significant importance', 1.0000168421686266), ('unrelated categories', 1.000016839194335), ('schedule surgeries', 1.0000168373642697), ('conversion', 1.0000168323304723), ('mechanisms underlying', 1.0000168262690932), ('healthcare using', 1.000016825773571), ('automatic sa', 1.0000168251339951), ('mammalian brain', 1.0000168248095107), ('concepts', 1.0000168097312392), ('novel entailment', 1.0000168065373647), ('approach results', 1.000016782491363), ('involve females', 1.000016776801549), ('nmfs attains', 1.000016773956504), ('anns yielding', 1.0000167733862302), ('real documents', 1.0000167587586688), ('novel language', 1.0000167537192768), ('renormalization', 1.0000167497522765), ('vgp generates', 1.000016748313457), ('crowd', 1.000016733510835), ('local correction', 1.0000167278268257), ('studies show', 1.0000167265939577), ('bnns result', 1.0000167197226468), ('such observations', 1.0000167180413382), ('frames', 1.0000167120200012), ('sentiment intensity', 1.0000167108882874), ('directed', 1.0000167101577027), ('dialectic concept', 1.00001670441131), ('unify', 1.0000167036661907), ('differential', 1.0000167035706955), ('conclusive performance', 1.0000166976921445), ('second uses', 1.0000166792769927), ('composition procedure', 1.000016678356251), ('single sentence', 1.0000166702266131), ('statistical bias', 1.000016669439464), ('numerous traffic', 1.0000166673722124), ('notion', 1.000016662268678), ('vanilla', 1.0000166574805143), ('theoretical framework', 1.0000166513104398), ('topologies', 1.0000166500857486), ('meteoric rise', 1.0000166384954976), ('match', 1.000016628294937), ('art nmt', 1.000016619457986), ('gestures', 1.0000166136627158), ('snn', 1.0000166118311906), ('vaes', 1.0000166109012496), ('slot', 1.0000166072941419), ('only attempt', 1.0000166057144466), ('predicting snow', 1.0000165933246272), ('pay attention', 1.00001659056292), ('outlier', 1.0000165839995323), ('rapid transitions', 1.0000165832201862), ('local training', 1.0000165826848717), ('mind', 1.0000165749588659), ('existing research', 1.0000165643216847), ('play othello', 1.0000165642033847), ('summarisation', 1.0000165633417017), ('energy', 1.000016560247681), ('transferable chemical', 1.0000165567370805), ('better improvement', 1.0000165339932934), ('previous runs', 1.00001653278432), ('relevant marks', 1.000016514011809), ('best model', 1.0000165133075967), ('little loss', 1.0000165056288028), ('transduce facts', 1.0000165011213722), ('different body parts', 1.0000165010055708), ('reproduce', 1.000016500480632), ('new drcn', 1.0000164967217566), ('research area', 1.0000164932326885), ('observations', 1.000016492584922), ('aim', 1.000016491456074), ('first sub', 1.000016475819043), ('symbols', 1.000016473645384), ('traditional surrogates', 1.000016469189173), ('ungrounded vocabulary', 1.0000164552484312), ('stability plasticity', 1.0000164531826747), ('recent research', 1.0000164502734947), ('d', 1.0000164501767363), ('better sentiment', 1.000016449803711), ('anomaly', 1.0000164484145833), ('protect', 1.0000164459918608), ('pure rl', 1.000016437890201), ('next', 1.0000164351541536), ('decisions', 1.00001641633362), ('distill', 1.0000164041949462), ('experimental result', 1.000016403697985), ('conjunction', 1.0000163944779767), ('key areas', 1.0000163909891886), ('scalar rewards', 1.0000163892922527), ('full training', 1.0000163828052413), ('toxicity activity', 1.0000163766581516), ('re rank', 1.000016373448444), ('out', 1.000016360155987), ('third degree', 1.0000163503973971), ('scientific concepts', 1.0000163491980523), ('surge', 1.0000163485313167), ('script discrimination', 1.0000163466760676), ('conventional nmt', 1.000016343610629), ('right pass', 1.0000163329779392), ('ell', 1.000016323106167), ('main topic', 1.000016314769682), ('inherent structure', 1.0000163145965788), ('energy time', 1.000016313328059), ('original cbt', 1.0000163027363838), ('experimental insights', 1.0000163002745277), ('dimensional space', 1.0000162864566873), ('delta distribution', 1.0000162856388057), ('many situations', 1.000016284096053), ('converge', 1.0000162782716011), ('gesture', 1.0000162760270925), ('wer', 1.000016272768894), ('advertisement', 1.0000162663520216), ('flat ground', 1.0000162662598981), ('low curvature', 1.000016265849908), ('active speaker', 1.0000162651408435), ('risks', 1.000016261754332), ('adoption', 1.0000162605595504), ('story reading', 1.0000162603256333), ('delicate balance', 1.0000162600334006), ('utility', 1.0000162488622122), ('fundamental uncertainty', 1.0000162457273793), ('several parts', 1.0000162437042701), ('standard regression', 1.0000162432289517), ('wsj si', 1.0000162417754113), ('completely different', 1.000016241109476), ('limited transmission', 1.0000162297314454), ('win', 1.0000162288674033), ('margin achieving', 1.0000162262535062), ('galaxy', 1.0000162260679426), ('typical cross', 1.0000162226710803), ('manifold', 1.0000162159013615), ('initial experiments', 1.0000162148032907), ('formalism', 1.0000162085253494), ('sense', 1.0000162021166026), ('primary reason', 1.0000162009406248), ('significant variations', 1.000016191890237), ('n', 1.0000161835364128), ('step fashion', 1.0000161803889007), ('self attention', 1.0000161759407864), ('visual loss', 1.0000161730886972), ('unseen', 1.0000161684889053), ('galaxy morphology prediction', 1.0000161603415894), ('different polices', 1.0000161598660418), ('aqm', 1.00001615844571), ('product space', 1.0000161447523952), ('attention combining', 1.000016139900483), ('important aspect', 1.0000161293151717), ('invariance', 1.000016124732502), ('small cost', 1.0000161163649073), ('probabilistic maxout', 1.0000161162363046), ('people would', 1.000016111179499), ('reach infants', 1.0000161056040955), ('smoothness', 1.0000161040490598), ('stepping stones', 1.0000161026531098), ('pool', 1.000016102362887), ('re tuning', 1.000016098123165), ('quick reduct', 1.0000160849466304), ('intelligence', 1.000016078046712), ('school test', 1.000016075159758), ('board locations', 1.0000160734334724), ('mining', 1.000016072477633), ('good model', 1.0000160678412404), ('teacher model', 1.0000160651056003), ('vocal tract parameterization', 1.000016060527024), ('thesis', 1.00001605263271), ('group size', 1.000016052006152), ('extract drug', 1.0000160462984757), ('regret', 1.0000160392543038), ('increased amounts', 1.0000160369836844), ('third alternative', 1.000016031709389), ('arrival', 1.0000160280305244), ('chinese discourse', 1.0000160276291528), ('unit', 1.0000160268309624), ('recurrence', 1.0000160243486875), ('fundamental functions', 1.0000160141116268), ('linguistic capacities', 1.000016011773237), ('fourth quantity', 1.0000159967247586), ('sphere', 1.0000159831697064), ('emnist having', 1.0000159705664324), ('reconstruction classification', 1.0000159658565013), ('key diagnoses', 1.000015959677956), ('cell can', 1.000015956841863), ('mujoco domain', 1.0000159551939791), ('cd dnn', 1.0000159551939791), ('brain anatomy', 1.000015950555335), ('thinking', 1.0000159420278096), ('such industries', 1.00001593720768), ('modest parameter', 1.0000159361929728), ('conventional', 1.0000159274187341), ('wikipedia', 1.000015926444101), ('forgy', 1.0000159262190704), ('learners', 1.0000159171095688), ('work demonstrating', 1.0000159078989124), ('correlations', 1.000015906983902), ('experimental part', 1.0000158968665351), ('associative memory am', 1.0000158961582497), ('hindsight may', 1.0000158943839317), ('individual members', 1.000015891026859), ('successful policy', 1.0000158874857235), ('thresholded affinity', 1.0000158861736583), ('such setting', 1.0000158849604044), ('reusing subword', 1.0000158811028024), ('high nuisance', 1.0000158802316657), ('compositionality', 1.000015879498374), ('compensate', 1.00001587717928), ('infants learning', 1.0000158770601446), ('isolet dataset', 1.0000158731896962), ('dropout discourages', 1.0000158699280106), ('secondary analysis', 1.0000158628222977), ('common world', 1.000015857134912), ('scores', 1.0000158554410794), ('disturbing extent', 1.0000158531193875), ('stimulus', 1.0000158444438518), ('multivariate', 1.0000158396958874), ('impossibility', 1.000015838753143), ('reasonable success', 1.000015834140958), ('navigation', 1.0000158298345472), ('distant languages', 1.0000158247382172), ('mdp', 1.000015821168191), ('languages', 1.0000158092502778), ('parcellation accuracy', 1.0000158064158091), ('bottom', 1.0000158047152201), ('compose', 1.0000157929197258), ('used', 1.0000157924959534), ('hebbian plastic', 1.0000157922306623), ('arc', 1.0000157913226093), ('homemaker debiasing', 1.0000157902066316), ('use shareboost', 1.0000157902066316), ('confer interpretability', 1.0000157902066316), ('improve hboa', 1.0000157902066316), ('initialize tpot', 1.0000157902066316), ('bench mark', 1.000015781439478), ('humans differentiating', 1.0000157662483955), ('convincing identity', 1.0000157657520654), ('perturbations', 1.0000157585701417), ('many years', 1.0000157534869725), ('weather', 1.0000157530360445), ('dominant features', 1.00001575272352), ('kdef images', 1.0000157506331742), ('maximin affinities', 1.0000157506331742), ('chromatin marks', 1.0000157506331742), ('first principles', 1.0000157471608058), ('broken', 1.0000157449012201), ('bee colony', 1.0000157428548968), ('possible', 1.0000157308989828), ('expanded emotion', 1.0000157298799155), ('gates', 1.0000157284485485), ('historical documents', 1.0000157281765525), ('abstracts', 1.000015725518931), ('eliminate', 1.0000157115080541), ('existing phrase', 1.0000157113153822), ('fundamental theorem', 1.0000157091215045), ('apparent diffusion', 1.0000156909364109), ('model promising', 1.0000156865960428), ('original yolov2', 1.0000156860404261), ('other candidate', 1.000015685844288), ('digital memcomputing', 1.0000156850021047), ('omnidirectional locomotion', 1.000015679091041), ('social consensus', 1.0000156787643026), ('encouraging results', 1.0000156714143738), ('facial', 1.0000156710072146), ('sleep eegs', 1.0000156662685666), ('hemodynamic response', 1.0000156628460344), ('few examples', 1.000015658735012), ('same sentence', 1.0000156567726948), ('functions', 1.0000156514898597), ('art inception', 1.0000156469614199), ('powerful', 1.000015644060484), ('single tower', 1.000015643701628), ('deconvolutional layers', 1.000015641529682), ('re', 1.0000156372221536), ('only cost', 1.0000156352243246), ('deep stock', 1.0000156293082005), ('exploratory behavior', 1.0000156256184365), ('temperature density', 1.000015616789487), ('art values', 1.000015613044033), ('manner', 1.0000156085892151), ('physical', 1.0000156058660143), ('evaluation settings', 1.0000156024590814), ('neocortical', 1.000015600119732), ('novel task', 1.0000155989826354), ('high agreement', 1.0000155900092624), ('classical registration', 1.0000155829568218), ('gender definition', 1.0000155822348857), ('media', 1.0000155809082873), ('several categories', 1.000015570274824), ('fovea surrounded', 1.0000155650580347), ('compact dnn', 1.0000155648004525), ('o d', 1.0000155464510116), ('complementarity', 1.000015546026108), ('audience discourse', 1.0000155401782505), ('newborns aged', 1.000015538593335), ('subsume', 1.000015538211464), ('several thousands', 1.0000155371870363), ('proposed end', 1.000015534955174), ('core hypothesis', 1.0000155311173418), ('power', 1.0000155272729923), ('contemporary approaches', 1.0000155240364093), ('collect', 1.0000155226546112), ('various ir', 1.0000155214612867), ('present research', 1.0000155203866001), ('usefulness', 1.000015517893315), ('tight region', 1.0000155168623663), ('paper positions', 1.0000155150441847), ('novel variant', 1.0000155080793567), ('clinical data', 1.000015507055748), ('quantification', 1.0000155025779638), ('time changes', 1.0000154987323426), ('sensory motor', 1.0000154921553142), ('confidence', 1.0000154882849683), ('approach stabilizes', 1.000015483831454), ('valuations may', 1.0000154828318626), ('time dilated', 1.0000154786982711), ('assumption', 1.0000154755204758), ('high triplet', 1.0000154755184925), ('compensates', 1.0000154701928903), ('extensive trial', 1.000015469760794), ('general theory', 1.0000154685032332), ('initial results', 1.00001545024141), ('cross modal dataflow', 1.0000154455528893), ('composition', 1.0000154449584684), ('deal', 1.0000154407947173), ('wmt english', 1.000015439573508), ('art standard', 1.0000154323560666), ('other group', 1.0000154252414728), ('nets', 1.000015422163603), ('dense', 1.0000154201370013), ('results confirm', 1.0000154160125931), ('event prediction', 1.0000154111333064), ('subspaces', 1.0000154111252646), ('implicit relations', 1.000015410125198), ('trees', 1.000015409610703), ('different guiding', 1.000015404966041), ('memcomputing method', 1.0000153947345196), ('current exploration', 1.00001539413724), ('similar amounts', 1.0000153940057608), ('cultural learning', 1.00001539066872), ('recent literature', 1.000015389015278), ('long sentences', 1.0000153848511677), ('analogy', 1.0000153806048784), ('erdos selfridge', 1.0000153730011911), ('lm', 1.0000153719335905), ('trained', 1.0000153709840132), ('closed form', 1.0000153617550933), ('different numbers', 1.0000153497569233), ('human studies', 1.0000153485839993), ('practical side', 1.0000153392968214), ('brains', 1.0000153369365257), ('elements', 1.0000153362261686), ('architecture vdcnn', 1.00001533175019), ('model drnet', 1.00001533175019), ('improved strength', 1.0000153287201825), ('new gaits', 1.0000153270232626), ('extreme cases', 1.0000153104527976), ('teller sees', 1.0000153087049033), ('relative increases', 1.0000153063074386), ('training aspect', 1.000015305588519), ('feasibility', 1.000015303250926), ('studies sentences', 1.000015297144861), ('role', 1.0000152944443448), ('salient records', 1.0000152940656737), ('first issue', 1.0000152787986623), ('enhanced efficiency', 1.000015272353473), ('shallow ones', 1.000015269723592), ('human study', 1.000015237217435), ('strengthen position', 1.0000152341874504), ('theorem', 1.0000152320354478), ('recent', 1.000015230945046), ('systematic analysis', 1.0000152293245692), ('picture', 1.0000152278279486), ('work improves', 1.0000152233795288), ('likes', 1.0000152194907985), ('material covered', 1.0000152161519948), ('language learners', 1.0000152132902105), ('ideological community', 1.0000152104563644), ('physics experiments', 1.0000152068665513), ('shapes', 1.0000152066482684), ('prior works', 1.0000152056376084), ('further contrast', 1.0000151995981716), ('consequence', 1.0000151979511451), ('certain age', 1.0000151946867901), ('common goal', 1.0000151916708613), ('positive factor', 1.0000151809914655), ('primitive', 1.000015168494703), ('joint task', 1.0000151658072405), ('wide reaching', 1.0000151561591453), ('41m lines', 1.0000151549418055), ('empirical gains', 1.0000151503517167), ('works', 1.0000151405480244), ('short swa', 1.0000151383894869), ('clinicians notes', 1.000015129788978), ('aspects', 1.0000151240859292), ('benchmark classification', 1.000015121269447), ('likelihood', 1.0000151165179738), ('resulting approach', 1.0000150974084365), ('long standing', 1.0000150903433698), ('novel end', 1.0000150903184926), ('factor analysis', 1.000015089384111), ('high attention', 1.0000150636616425), ('prime importance', 1.0000150595269945), ('co adapting', 1.0000150529635192), ('perception', 1.000015052337152), ('topics', 1.0000150389719453), ('psychological attributes', 1.0000150358033029), ('include', 1.000015030136595), ('content analysis', 1.0000150300031465), ('reformulate', 1.0000150279274724), ('criterion', 1.0000150247839266), ('resolve', 1.0000150115203803), ('examine', 1.0000150057686492), ('best state', 1.000015004341619), ('composition part', 1.0000150032385142), ('correction', 1.0000149900392057), ('detail', 1.000014990035776), ('new splits', 1.0000149792423072), ('current practice', 1.0000149789581416), ('minutes overbooked', 1.000014971872102), ('pharmaceuticals based', 1.000014971872102), ('convnets measured', 1.000014971872102), ('swwae uses', 1.000014971872102), ('coral correlation alignment', 1.0000149670793714), ('calculation', 1.000014967068135), ('genomics challenges', 1.0000149638561118), ('hybrid k', 1.0000149623306387), ('phonetic lid systems', 1.0000149592091114), ('different fields', 1.0000149577635289), ('sophisticated', 1.000014954544908), ('large state', 1.0000149515624033), ('rigorous', 1.0000149437567087), ('behaviors', 1.0000149333091017), ('lexical semantics', 1.0000149323210408), ('statistically significant', 1.000014927876157), ('single unk', 1.000014925158704), ('par', 1.0000149208862839), ('reversal', 1.0000149184409628), ('reason relations', 1.0000149020637337), ('new reading', 1.0000148998688327), ('similar phenomenon', 1.000014897806692), ('gain', 1.0000148807035005), ('technical ingredients', 1.0000148747334734), ('pnet', 1.0000148686244645), ('human activities', 1.0000148663327746), ('actuator', 1.0000148653384806), ('experiments based', 1.0000148582426054), ('holistic intervention', 1.0000148564883204), ('other sentence', 1.000014854910108), ('experiences', 1.000014844716759), ('unseen compositions', 1.000014843470276), ('mass friction', 1.0000148390163932), ('ib', 1.000014838587985), ('current world', 1.0000148347169031), ('free', 1.000014831841032), ('standard evidence', 1.0000148278036147), ('intrinsic', 1.000014820016518), ('similar movies', 1.0000148174996684), ('adaptation', 1.0000148173043493), ('ctc gram', 1.0000148151729942), ('effort', 1.0000148121132013), ('observations many', 1.0000148056149134), ('solubility dataset', 1.000014774682954), ('safety', 1.0000147742114514), ('morphology classification', 1.0000147740687002), ('millions', 1.0000147740386147), ('traditional phrase', 1.0000147730469606), ('inter beat', 1.0000147710350256), ('corrupted', 1.0000147663578964), ('surgery case', 1.0000147662264152), ('theoretical approach', 1.0000147654143494), ('exploratory', 1.0000147632500218), ('addition induce', 1.0000147629755733), ('power area', 1.0000147552804184), ('painter classification', 1.0000147349400972), ('bucher et', 1.0000147345886867), ('patient names', 1.0000147264209243), ('careful training', 1.0000147203590715), ('topological', 1.0000147191496211), ('predictive transition', 1.0000147163758168), ('important factor', 1.0000147119361178), ('abnormal activity', 1.0000147014179404), ('pwl function', 1.000014701285341), ('serve', 1.0000146971280148), ('shuffling', 1.0000146915331707), ('large scale chromatin', 1.0000146867145514), ('continuous flow', 1.0000146707050754), ('one', 1.0000146528956175), ('financial industry', 1.0000146525755136), ('trivial', 1.0000146522549853), ('enforce', 1.000014648104797), ('final performance', 1.0000146417011717), ('importance determined', 1.0000146329455921), ('neuroscience', 1.0000146294617451), ('lifted architecture', 1.000014628079118), ('cost terms', 1.0000146188699972), ('biological evolution', 1.000014617582912), ('characteristics', 1.0000146155768297), ('disentangled', 1.0000146144931215), ('distinct approaches', 1.0000146132796877), ('sa experiments', 1.0000146081165482), ('triplet', 1.0000146029643457), ('genomic technologies', 1.0000145950035144), ('developmental psychology', 1.0000145941546428), ('conversation', 1.0000145941366179), ('common household', 1.0000145851724542), ('individual choreographer', 1.0000145842244215), ('test rfns', 1.0000145782837915), ('large health', 1.0000145705756505), ('model gp', 1.000014567526133), ('phrase', 1.0000145584326445), ('mcts', 1.0000145564472922), ('plan', 1.0000145544483034), ('motor learning', 1.0000145449502122), ('creased complexity', 1.0000145437931462), ('description experiments', 1.0000145401441622), ('torcs', 1.0000145378345004), ('fuzzy dgp', 1.0000145353385868), ('grbms can', 1.0000145267978662), ('da method', 1.0000145266604015), ('lateral connection', 1.000014525595433), ('aristotelian concept', 1.0000145222062782), ('generality', 1.000014521773447), ('unique', 1.0000145188333789), ('candidate intentions', 1.000014507204627), ('explanations', 1.000014501413173), ('different nature', 1.0000144992592683), ('preliminary experiment', 1.0000144932277735), ('closeness', 1.000014492050618), ('scientific articles', 1.0000144891440854), ('speaking proceeds', 1.000014473835825), ('questioner s', 1.000014473683001), ('clear interpretation', 1.0000144661167178), ('supervision', 1.0000144612604276), ('rnnmorph model might', 1.0000144611285084), ('recent history', 1.0000144584931991), ('improved curriculum', 1.0000144545040963), ('lip synchronisation', 1.0000144467857388), ('medical prescriptions', 1.0000144464477212), ('partial reinitialization', 1.0000144436022964), ('discourse', 1.0000144389046268), ('truncated radon', 1.0000144377481222), ('stem science', 1.00001443692195), ('experiments lead', 1.0000144349508873), ('arguments', 1.0000144345921058), ('circle square', 1.0000144313100945), ('proper places', 1.000014422476594), ('state visitation', 1.0000144218152582), ('particular focus', 1.0000144215567084), ('imp cnn', 1.0000144183757764), ('fcn system', 1.0000144100296728), ('separation', 1.0000144078716198), ('aforementioned diversity', 1.0000144021847437), ('montufar et', 1.0000143998296274), ('lms', 1.000014398520277), ('importance', 1.0000143975460687), ('enough capacity', 1.0000143971640316), ('powerful model', 1.0000143959303855), ('heteroscedasticity', 1.000014389397937), ('second task', 1.000014386126148), ('novel tool', 1.0000143816252751), ('many episodes', 1.000014378547892), ('large collections', 1.000014372550422), ('recent study', 1.000014370936534), ('movie synopses', 1.0000143666038945), ('pwl activation', 1.0000143666038945), ('competitive mechanism', 1.0000143624124964), ('f1', 1.0000143619265083), ('social settings', 1.0000143602094693), ('rbms', 1.0000143562909236), ('big variety', 1.0000143406750241), ('complement', 1.0000143387919058), ('same question', 1.0000143384605384), ('malfunction compensation', 1.0000143329894484), ('biomimetic phantoms', 1.0000143257981025), ('feudal rl', 1.000014323511175), ('organizing', 1.0000143226378067), ('stop ask', 1.0000143170947522), ('common practice', 1.0000143157523105), ('bounds', 1.0000143143004983), ('large family', 1.0000143035338027), ('constructing', 1.0000143029786719), ('scientific papers', 1.0000142991211673), ('ts', 1.0000142946898691), ('wrong direction', 1.0000142792135456), ('improved wasserstein', 1.0000142728259398), ('time scales', 1.000014267648992), ('inconsistent dimensions', 1.0000142629922004), ('diverse paintings', 1.0000142425083314), ('sinogram domain', 1.0000142425005767), ('latex', 1.000014237590582), ('supervised student', 1.0000142352251409), ('interest lies', 1.0000142271666976), ('ctakes', 1.0000142251367234), ('broader understanding', 1.0000142128206988), ('different speakers', 1.000014207447397), ('class selectivity', 1.000014196990993), ('rich morphology', 1.0000141881695925), ('novel form', 1.0000141881373557), ('architectural', 1.000014186558869), ('family', 1.0000141830786233), ('successful training', 1.0000141749578522), ('acoustic states', 1.0000141728030785), ('utterance', 1.0000141606589255), ('chromatin measurements', 1.0000141529150357), ('expressiveness', 1.0000141489153116), ('preliminary results', 1.0000141366665534), ('past', 1.0000141329581202), ('resnet rir', 1.0000141310618063), ('ssvm subgradient', 1.0000141310618063), ('noise categories', 1.0000141300270597), ('popular children', 1.000014128837092), ('novel domains', 1.0000141248869776), ('signer', 1.0000141234897206), ('wnn', 1.0000141171844414), ('small target', 1.000014110844041), ('cells', 1.0000141098821018), ('baselines', 1.00001410918165), ('ignore', 1.0000141075089874), ('corrections provides', 1.0000141035363175), ('previous satellite', 1.000014098403587), ('ask', 1.0000140962928012), ('several cases', 1.000014090363765), ('multiple measures', 1.0000140883148103), ('appropriate', 1.0000140779150464), ('intention', 1.0000140679159604), ('rbm', 1.0000140635598869), ('capacity', 1.0000140624168843), ('clinical outcomes', 1.0000140568530922), ('busy road junction', 1.000014053420118), ('tuning', 1.000014046056917), ('disease progression', 1.000014045557769), ('severe noise', 1.0000140179325332), ('flexible wire', 1.0000140129793056), ('similar symbols', 1.000014010029862), ('singular', 1.0000140098194363), ('soft', 1.0000140084421658), ('parcellation', 1.0000139860102395), ('substantial benefits', 1.0000139845234473), ('invasive techniques', 1.0000139823166525), ('compositional split', 1.000013982234445), ('news', 1.000013973530926), ('scientific knowledge', 1.0000139609936953), ('intensive care units', 1.0000139528871292), ('severe cupping artifacts', 1.0000139528871292), ('noisy versions mtae', 1.0000139528871292), ('kbqa system', 1.000013951913018), ('language development', 1.0000139511233963), ('music sight', 1.0000139506191459), ('age', 1.0000139495414406), ('transferring', 1.0000139479650094), ('new areas', 1.0000139440083202), ('lattice', 1.0000139418742022), ('new formulation', 1.00001394124552), ('dozens', 1.0000139406129247), ('frequency', 1.0000139403041646), ('meaning acting', 1.000013930168866), ('various forms', 1.0000139300307966), ('facial expression', 1.0000139239816042), ('training horizon', 1.0000139224541886), ('connections', 1.0000139218171924), ('fixed', 1.0000139092824412), ('major part', 1.000013897840464), ('ladder network', 1.0000138940935548), ('such category', 1.0000138872072513), ('final results', 1.0000138816504744), ('interpretations', 1.0000138726563907), ('first attempts', 1.0000138687222926), ('situ plasticity', 1.0000138658921207), ('vanishing', 1.0000138633130535), ('high expected', 1.0000138618987717), ('chemical properties', 1.0000138473931608), ('divide', 1.0000138467159942), ('human communication', 1.0000138428861935), ('causal', 1.0000138405874774), ('special class', 1.0000138401756171), ('employ', 1.0000138366773055), ('effective imposition', 1.0000138334670468), ('kind', 1.000013827818033), ('biological', 1.000013822077596), ('experimental study', 1.000013815329279), ('popular area', 1.0000138120992959), ('attain', 1.0000138070713473), ('different places', 1.0000138067142639), ('bias', 1.0000138057155925), ('desirable choice', 1.000013792777939), ('exploitation', 1.0000137922712737), ('detected', 1.0000137826387823), ('unseen relation', 1.0000137817554404), ('prednet architecture', 1.0000137711825827), ('dcnn dann', 1.0000137711825827), ('other child', 1.000013760242929), ('dataset desiredb', 1.0000137598237329), ('such regions', 1.0000137552100492), ('clinical practice', 1.0000137357773442), ('new hypotheses', 1.0000137347845799), ('vqa setting', 1.0000137336306476), ('defensive mechanism', 1.000013733159305), ('great benefit', 1.0000137193253624), ('new loss', 1.0000137137246414), ('respond', 1.000013713671947), ('larger size', 1.0000137094288777), ('ontonotes surpassing', 1.0000137025484532), ('webqa show', 1.0000137025484532), ('webquestions demonstrate', 1.0000137025484532), ('activity', 1.0000136947290927), ('individual pieces', 1.000013680786565), ('dirichlet', 1.0000136782212947), ('quaero task', 1.000013677524691), ('intra parcel', 1.0000136717094752), ('skin lesions', 1.0000136709230656), ('drcn transforms', 1.0000136709230656), ('blood tests', 1.0000136709230656), ('health specialists', 1.0000136709230656), ('esom term', 1.0000136709230656), ('discovery radiomics', 1.0000136709230656), ('keyvec representations', 1.0000136709230656), ('blackbox intervention', 1.0000136704023268), ('turbid media', 1.000013667090644), ('level', 1.00001366650968), ('predictron consists', 1.0000136662515515), ('predictron yielded', 1.0000136662515515), ('dybm can', 1.0000136662515515), ('indefinite knowledge', 1.0000136658542969), ('maxout', 1.0000136622906846), ('choice', 1.0000136612859485), ('others', 1.000013660030467), ('residual network resnet', 1.0000136585282013), ('other works', 1.0000136514746651), ('significant', 1.0000136308413483), ('distant', 1.000013624969403), ('mathematical', 1.0000136245061684), ('multiple choice', 1.0000136183910981), ('null', 1.0000136123660401), ('performances', 1.0000136122022745), ('safety reasons', 1.0000136118754772), ('item', 1.0000136100043733), ('great success', 1.0000136086033597), ('great extent', 1.000013604734151), ('schedule', 1.000013604138287), ('automatic model', 1.0000136038173735), ('empirical evidence', 1.00001360109236), ('bag', 1.000013598619839), ('sms', 1.00001359858184), ('general field', 1.0000135876905736), ('k n', 1.0000135874193934), ('findings show', 1.0000135849757377), ('special regime', 1.0000135828115404), ('length', 1.0000135797039085), ('synaptic probability', 1.0000135761342972), ('gather', 1.0000135694567223), ('severe strengths', 1.0000135666170278), ('existing vqa', 1.0000135564511052), ('study investigating', 1.0000135497644382), ('tate galleries', 1.0000135495245739), ('mlp abc', 1.0000135495245739), ('sg dni', 1.0000135495245739), ('chor rnn', 1.0000135495245739), ('sustained development', 1.0000135447421825), ('place', 1.000013542666426), ('equal parts', 1.0000135348030363), ('novel response', 1.0000135287387413), ('short', 1.000013510064167), ('lateral connections', 1.000013505536057), ('local neighbourhoods', 1.0000134981058248), ('atoms', 1.0000134980145452), ('negligible training', 1.0000134944147752), ('massive label', 1.000013494137395), ('observed effects', 1.0000134862232706), ('modulation strategy', 1.0000134843871549), ('linguistic', 1.0000134817898938), ('chinese sentence', 1.000013479555505), ('daume', 1.0000134790857147), ('novel sequence', 1.0000134769634144), ('master', 1.0000134749022886), ('developmental studies', 1.0000134727823118), ('bandit', 1.0000134682930923), ('survey will', 1.0000134673909902), ('moves', 1.0000134615868543), ('transposition', 1.000013457300381), ('prime', 1.0000134451524065), ('deconvolutional networks', 1.0000134381582586), ('novel sources', 1.0000134378290069), ('market based', 1.0000134326764374), ('dictionary', 1.000013429496661), ('density', 1.0000134261423834), ('slow training', 1.0000134167456447), ('labeling', 1.000013409110156), ('experimental studies', 1.0000134089991188), ('bridge', 1.0000133955874426), ('issue', 1.0000133901130699), ('emit', 1.0000133824563568), ('monitoring', 1.000013376082149), ('new class', 1.000013375053112), ('medical investigations', 1.0000133607599597), ('babble noise', 1.0000133518304342), ('investigations', 1.0000133515456335), ('procedure', 1.00001334708015), ('total variation', 1.0000133372960878), ('size d', 1.0000133321372828), ('accumulative elbo', 1.0000133286268322), ('mnist usps', 1.0000133286268322), ('animal', 1.0000133262752853), ('modification', 1.0000133256755495), ('framewise', 1.0000133254337595), ('think', 1.0000133177749646), ('disease grading', 1.0000133150139987), ('relus drelus', 1.0000133150139987), ('faithful propagation', 1.0000133080538247), ('produced lyrics', 1.0000133073627775), ('repeat', 1.0000133028170226), ('disentangle', 1.000013295552057), ('uncover', 1.0000132941559479), ('keep', 1.0000132776594495), ('third stage', 1.000013267103832), ('statistical relations', 1.0000132641420223), ('depict', 1.000013258854495), ('direct', 1.0000132530212658), ('teacher student', 1.0000132470306617), ('systematic case', 1.0000132397425177), ('k', 1.000013237917323), ('accuracies', 1.00001323687807), ('simple lines', 1.0000132354544786), ('stereotypical motor', 1.0000132279495952), ('developmental visuomotor', 1.000013227142778), ('underlying prospect', 1.0000132235457813), ('priors', 1.0000132227082843), ('estimators', 1.0000132202368939), ('responses', 1.0000132187546331), ('outer layers', 1.0000132063183598), ('selective attention', 1.0000132038741987), ('largest skeleton', 1.0000131939506551), ('classical nlp', 1.0000131887713013), ('memory blstm', 1.000013187931181), ('survey', 1.0000131860061947), ('lenet', 1.0000131850128728), ('typhoon eye', 1.000013182193861), ('assume', 1.0000131733102915), ('report', 1.0000131692373013), ('several decades', 1.0000131628609048), ('prior state', 1.0000131570373028), ('ablation studies', 1.0000131365779472), ('gru', 1.0000131334548246), ('emotion lexicon', 1.0000131105614358), ('shrink', 1.000013103031152), ('contemporary fmri studies', 1.000013102725272), ('effective tool', 1.0000130961317104), ('selection', 1.0000130938097749), ('diagnostic grading', 1.0000130912430587), ('reverse', 1.0000130897456905), ('booking', 1.0000130896547277), ('clean training', 1.0000130773651126), ('density estimation', 1.0000130773264098), ('piece', 1.0000130731254049), ('adequacy', 1.000013067838544), ('further experiments', 1.0000130649422843), ('general practice', 1.0000130646069723), ('assumptions', 1.0000130559989135), ('patient sleep', 1.0000130540047742), ('novel dialogue', 1.000013052302755), ('current investigation', 1.0000130493994144), ('inception', 1.0000130437403592), ('few years', 1.0000130410776065), ('workshop summary', 1.0000130365657), ('work opens', 1.0000130361734005), ('short phrases', 1.0000130255761257), ('art architectures', 1.000013012189006), ('invert', 1.000013003020038), ('scatter', 1.0000129971884135), ('deepmatch tree', 1.0000129959124693), ('surgery durations', 1.0000129959124693), ('dropout regularisation', 1.0000129959124693), ('freedom', 1.0000129899806842), ('other demonstration', 1.0000129885316187), ('operator', 1.000012983423497), ('pinpoint', 1.0000129786388667), ('results give', 1.000012974976747), ('oonp parser', 1.0000129745509647), ('conditioning', 1.0000129301415355), ('stud ies', 1.0000129297519036), ('novel mechanism', 1.0000129285739523), ('promote', 1.000012926700208), ('penultimate layer', 1.000012922002657), ('comparative study', 1.0000129217270104), ('rnnmorph model', 1.00001291261188), ('aforementioned sparsification', 1.00001291261188), ('further investigation', 1.0000129102382975), ('humans animals', 1.0000128988022885), ('sensitivity', 1.0000128936136832), ('work demonstrates', 1.0000128907056633), ('describe', 1.0000128872448677), ('slight decrease', 1.000012887057901), ('art range', 1.0000128862072148), ('innermost', 1.0000128847098528), ('exact', 1.0000128826242203), ('highest area', 1.0000128820277756), ('abundant training', 1.0000128820277756), ('only world', 1.0000128820277756), ('expensive', 1.0000128813062954), ('super', 1.0000128803992314), ('nature', 1.0000128797424352), ('visual search', 1.0000128786576143), ('first group', 1.000012865913882), ('emergence', 1.0000128637303591), ('robocup dataset', 1.0000128597614724), ('entire class', 1.000012854349608), ('fill', 1.0000128542324136), ('indicator parameter', 1.0000128457597173), ('few', 1.0000128392263161), ('people behave', 1.000012838101502), ('differentiable', 1.0000128256595937), ('impact', 1.000012815888558), ('anomalies', 1.0000128131137904), ('intuitive theories', 1.0000128065845937), ('engineering', 1.0000127758142168), ('stdp', 1.0000127695487953), ('sensory memory', 1.0000127677531638), ('unprecedented scales', 1.0000127595167154), ('follow', 1.0000127589617858), ('other branches', 1.0000127478610494), ('goals', 1.0000127446485563), ('previous results', 1.000012743061446), ('distributional', 1.000012742030628), ('existence', 1.000012735734813), ('imagination tree', 1.0000127298372106), ('scientific', 1.000012727708708), ('googlenet', 1.0000127118927689), ('operations', 1.0000127080998407), ('various numbers', 1.0000127023418646), ('dialogue process', 1.0000126953613644), ('spoken', 1.0000126823483586), ('argue', 1.0000126674702423), ('grow', 1.0000126492299957), ('global', 1.0000126487692798), ('side', 1.0000126458314595), ('hypothesis', 1.0000126440863373), ('experiments survey', 1.0000126419314517), ('scientist', 1.000012632235076), ('explanation', 1.0000126259279674), ('similar', 1.0000126201709276), ('dude benchmark', 1.0000126174176969), ('bioasq training', 1.0000126071894708), ('mazebase version', 1.0000126071894708), ('pdtb benchmark', 1.0000126071894708), ('motor planning', 1.0000126017753643), ('same drug', 1.0000125953186254), ('argument', 1.0000125849629768), ('constituent n', 1.000012573356298), ('small', 1.0000125683296632), ('chromatin factors', 1.0000125640776545), ('variation', 1.0000125383615708), ('novel pipe', 1.0000125374721425), ('chinese poem', 1.0000125374721425), ('vgp demonstrating', 1.0000125309007675), ('rectified', 1.000012529295865), ('htrts competition', 1.00001251365674), ('x', 1.000012513556134), ('small trees', 1.000012512054867), ('recommendations', 1.0000125085120963), ('peers', 1.000012496835072), ('true', 1.0000124880471575), ('mixture', 1.0000124826671872), ('sharp contrast', 1.0000124816372338), ('detect underfitting', 1.0000124780476876), ('untangle confounding', 1.0000124780476876), ('diagnostic', 1.0000124773137526), ('resnet generalizing', 1.0000124708423463), ('fsmn can', 1.0000124708423463), ('awareness', 1.0000124620477238), ('favorable performance', 1.0000124590201527), ('induction', 1.0000124481231765), ('list', 1.0000124358626055), ('severe side', 1.0000124349231465), ('crowd worker', 1.0000124272263178), ('proposed variant', 1.0000124220316255), ('rbp', 1.0000124138078976), ('medical paper', 1.0000124097907694), ('previous studies', 1.0000124074251255), ('l', 1.000012405143283), ('cell achieves', 1.0000123875998728), ('manual', 1.0000123820149975), ('great efforts', 1.0000123736184736), ('latter role', 1.0000123713651323), ('northeastern hemisphere', 1.0000123713651323), ('novel settings', 1.0000123646400354), ('linear transformation', 1.0000123645134817), ('proximodistal organization', 1.0000123594045165), ('many activities', 1.000012354531165), ('former utilizes', 1.0000123527249127), ('distillation increases', 1.0000123428806842), ('aims', 1.000012331003133), ('demonstration', 1.00001233086628), ('recogniser', 1.000012323878684), ('element', 1.0000123162550965), ('pure dcnn', 1.0000123158782706), ('mass', 1.0000123129113108), ('longer term', 1.0000123101808798), ('inner layers', 1.000012301760137), ('clinical relevance', 1.000012301760137), ('medical event', 1.000012301760137), ('spoken term', 1.000012301760137), ('visitors', 1.000012283564863), ('velocity', 1.0000122661555813), ('previous state', 1.000012254182174), ('effects', 1.0000122477265063), ('channel', 1.0000122471732305), ('interactive fcns', 1.000012246116224), ('future nteractions', 1.000012246116224), ('explicit delexicalisation', 1.000012246116224), ('such mnns', 1.000012246116224), ('many mammals', 1.000012246116224), ('pictorial scribbles', 1.000012246116224), ('various state', 1.000012246116224), ('environmental resources', 1.000012246116224), ('higher concentration', 1.000012246116224), ('deconvolutional operations', 1.000012246116224), ('stale gradients', 1.000012246116224), ('common man', 1.000012246116224), ('medical events', 1.000012246116224), ('atrous convolutions', 1.000012246116224), ('large population', 1.000012246116224), ('study panel', 1.0000122249662504), ('labelled', 1.0000122178348523), ('mechanisms', 1.0000122096231552), ('intensive care', 1.000012208462236), ('severe cupping', 1.000012208462236), ('high energy', 1.000012208462236), ('definition', 1.0000122081541116), ('extent', 1.00001220750963), ('novel eda', 1.0000121926280723), ('traditional alternatives', 1.0000121802473638), ('gan', 1.0000121798062995), ('challenging zsc', 1.0000121779059115), ('meaningful', 1.000012169578318), ('new insights', 1.0000121667530235), ('cool', 1.0000121659796912), ('chemnet pre', 1.0000121654021166), ('parameterizable transfer', 1.0000121595806952), ('derivative', 1.0000121445980577), ('changes', 1.000012141816179), ('important successes', 1.0000121353070694), ('probable pathology', 1.0000121353070694), ('improvement', 1.000012120213182), ('associate', 1.0000121033308211), ('minibatch size', 1.0000120932990009), ('attractiveness happiness', 1.000012090944807), ('o yolov2', 1.000012090944807), ('exploratory data analysis', 1.0000120884117765), ('fire', 1.0000120721229593), ('central', 1.000012067599144), ('modifications', 1.0000120631729594), ('saliency', 1.0000120574063462), ('certain', 1.000012054890802), ('learning channel', 1.0000120372542423), ('second challenge', 1.0000120291122958), ('structural support', 1.0000120091035607), ('cat environment', 1.0000120009517122), ('push', 1.0000119744502693), ('intermediate', 1.0000119732929968), ('keyword spotter', 1.0000119732143213), ('untangle', 1.0000119646492027), ('researchers', 1.0000119609121294), ('premise', 1.000011955017272), ('rankings correlate', 1.0000119415957665), ('observe', 1.0000119384371668), ('discussions', 1.0000119336169586), ('full supervision', 1.000011930812145), ('fmllr', 1.0000119296693792), ('break', 1.000011927793913), ('studies words', 1.0000119172990114), ('squad', 1.000011889464712), ('cqa', 1.0000118777227338), ('children might', 1.0000118651284022), ('secondary training', 1.000011864845054), ('competitor', 1.000011847829081), ('misclassification', 1.0000118305780046), ('works done', 1.000011819692747), ('targets', 1.0000118130938993), ('surrogate', 1.000011808051468), ('training period', 1.0000118014975632), ('phoneme', 1.0000117778633006), ('topology', 1.0000117691405876), ('navigational', 1.000011766312147), ('long time', 1.0000117653872058), ('novel training', 1.0000117538941449), ('likelihood ratio', 1.0000117412949503), ('acquisition', 1.0000117274263207), ('novel type', 1.0000117262261663), ('discuss', 1.0000117261309944), ('ami distant', 1.0000117169181395), ('evidence', 1.0000117110371392), ('sensory', 1.0000117071687051), ('force', 1.0000117039423517), ('behave', 1.0000116996390729), ('deductive reasoning', 1.0000116931151697), ('distillation leads', 1.0000116893238924), ('credit card', 1.0000116888187935), ('focal leaf', 1.000011686896251), ('brain imaging', 1.0000116779654127), ('sufficient', 1.0000116638253012), ('wide span', 1.0000116567594457), ('curve', 1.0000116506161025), ('receive', 1.0000116426103072), ('training effectiveness', 1.0000116412251552), ('training grbms', 1.0000116387374456), ('hyperspectral', 1.0000116372392802), ('circuits', 1.0000116303901188), ('phase', 1.0000116281077744), ('added', 1.0000116239551538), ('overall decrease', 1.0000116006543025), ('relus', 1.0000115886069294), ('locations', 1.000011584117587), ('quasi', 1.000011582969764), ('notions', 1.000011581315126), ('new family', 1.0000115726811367), ('ensembles', 1.0000115560662572), ('dependence', 1.0000115529342493), ('reparameterization', 1.0000115431228136), ('margin', 1.0000115428490717), ('propagate', 1.000011529756203), ('circuit', 1.000011525889745), ('diabetic retinopathy', 1.0000115238538543), ('complex alphasyllabary', 1.000011513350757), ('crucial part', 1.000011513350757), ('progress', 1.0000115104638267), ('expressivity', 1.0000115102068738), ('car corpus', 1.0000115029785046), ('new treatment', 1.0000114780898317), ('fly', 1.0000114615032727), ('calculate', 1.0000114582624708), ('first wave', 1.0000114518665177), ('ssvm training', 1.0000114252735905), ('repeatability', 1.000011423071708), ('steepest', 1.0000114118584842), ('arts techniques', 1.0000113990920299), ('leaky capped', 1.000011396657983), ('retrain', 1.0000113944864502), ('qbot', 1.000011393127165), ('new energy', 1.0000113929158319), ('ncca s', 1.0000113910846762), ('coordinates', 1.0000113874776355), ('ami meeting', 1.0000113709769083), ('perturb', 1.0000113704347604), ('posenet allows', 1.0000113696992792), ('arnet can', 1.0000113696992792), ('competition occurs', 1.0000113696992792), ('adasent can', 1.0000113696992792), ('tpot can', 1.0000113696992792), ('activities', 1.0000113473885115), ('noisy crowd', 1.0000113185820088), ('human effort', 1.000011313272475), ('cost', 1.0000113118682636), ('detector', 1.000011310794144), ('traverse', 1.0000113063349545), ('fix', 1.000011306121134), ('black', 1.000011304314809), ('dl', 1.0000113011185976), ('distinctive feature', 1.0000113007227942), ('benchmark weathergov', 1.0000112982407205), ('original teacher', 1.0000112982407205), ('msrpar task', 1.0000112982407205), ('visdial dataset', 1.0000112982407205), ('arts', 1.0000112960125256), ('single patient', 1.0000112865787691), ('diffuse', 1.0000112777507209), ('multitudes', 1.0000112702989095), ('speller', 1.0000112683805207), ('product', 1.0000112460987807), ('maximum dialectic', 1.0000112202822924), ('hybrid', 1.0000112043103193), ('modality', 1.0000112029665096), ('estimating', 1.0000112018744425), ('suggest', 1.0000112016316758), ('diseases may', 1.0000111981506004), ('derivatives', 1.0000111889525034), ('lock', 1.0000111847318178), ('grant proposal', 1.000011183078739), ('multilabel classification', 1.0000111803692435), ('elm', 1.0000111763098427), ('contribution consists', 1.0000111732552455), ('systematic taxonomy', 1.0000111700618974), ('communication', 1.00001116975158), ('results shed', 1.0000111596609864), ('sca', 1.0000111579545556), ('haystack', 1.0000111458148035), ('experiments indicate', 1.0000111364900603), ('degree', 1.000011133194773), ('average compared', 1.0000111323643033), ('anns', 1.0000111225528052), ('eye', 1.0000111191591272), ('bioactivity', 1.0000111109183598), ('policy leads', 1.0000111064636188), ('similar circumstances', 1.000011101705351), ('strings', 1.000011093113312), ('matrix multiplication', 1.0000110706411478), ('start', 1.0000110687002104), ('advantages', 1.0000110605945594), ('disembodied', 1.0000110527098212), ('like', 1.00001103935459), ('mctest', 1.0000110060023333), ('duration', 1.0000110033726244), ('random variables', 1.0000110023362196), ('small adaptations', 1.0000109981290033), ('comparable results', 1.0000109936535544), ('stability', 1.0000109796752905), ('e2e kws', 1.0000109788132416), ('choose', 1.0000109644814301), ('values', 1.0000109620009527), ('bases', 1.0000109549750786), ('express', 1.0000109475455663), ('arts methods', 1.000010932978297), ('findings', 1.000010930472658), ('stanford', 1.000010929189179), ('ablations', 1.0000109280433813), ('propositional logic', 1.0000109219242739), ('other cases', 1.0000109154089987), ('ams', 1.0000109122848113), ('replacement', 1.0000109011875042), ('fourier transform', 1.000010884997743), ('people', 1.0000108811690358), ('theoretical justification', 1.0000108676274164), ('ordinal', 1.000010851660733), ('proposed mechanism', 1.0000108497288833), ('norm', 1.0000108485329993), ('inter', 1.0000108460257637), ('attractiveness', 1.0000108459440222), ('fnn', 1.000010840250072), ('mission', 1.0000108321007117), ('decrease', 1.0000108309384554), ('auxiliary', 1.000010828593785), ('compositional', 1.0000108146391502), ('network arnet', 1.0000108145346223), ('vgp', 1.0000108123204607), ('lattices', 1.0000108092460438), ('trec', 1.0000107958313122), ('retain', 1.00001077823039), ('better team', 1.0000107730160843), ('degrade', 1.0000107474818716), ('factoid', 1.0000107383824375), ('neuronal', 1.0000107173554622), ('point', 1.0000107144076786), ('lattice resembles', 1.0000107069444268), ('faster', 1.0000107066031516), ('hundreds', 1.0000106981186148), ('motivate', 1.0000106923743408), ('art teacher', 1.0000106806241502), ('art trade', 1.0000106803593867), ('divergence', 1.0000106786650673), ('attend', 1.0000106656684196), ('music', 1.0000106600992134), ('statistics', 1.0000106539916986), ('attempt', 1.0000106464553284), ('alternatives', 1.000010639013457), ('gigaword dataset', 1.0000106368281987), ('avletters dataset', 1.0000106368281987), ('establish', 1.000010635956967), ('pay', 1.0000106344588435), ('squeezenet', 1.0000106288106694), ('logmelspec features', 1.0000106261517239), ('holistic', 1.0000106254997827), ('current models', 1.000010614964143), ('weather observation', 1.0000106090006404), ('skeleton', 1.0000106028145808), ('natural situation', 1.000010599896449), ('post training', 1.0000105988411983), ('behaviors including', 1.0000105872296896), ('modulation', 1.0000105711671146), ('electroencephalography', 1.00001057060442), ('adopt', 1.0000105457392976), ('numerous', 1.0000105444057723), ('models discovered', 1.000010534266485), ('timing', 1.0000105334254743), ('traditional sentence', 1.0000105214693684), ('addition topicrnn', 1.0000105179155498), ('contrast animals', 1.0000105179155498), ('mammo grams', 1.0000105179155498), ('starting', 1.0000105118406322), ('painter', 1.0000104986896583), ('consider', 1.0000104976492779), ('skill', 1.0000104889050023), ('foresee', 1.000010478750006), ('modern day', 1.0000104773411445), ('designing', 1.0000104753959993), ('quantitative rhyme', 1.000010472517683), ('roles', 1.000010463694298), ('convnets', 1.0000104570380435), ('plug', 1.0000104515841783), ('experimental effort', 1.0000104515297261), ('isolate', 1.0000104451457148), ('intuition', 1.0000104322432666), ('implications', 1.0000104268640713), ('valuable', 1.0000104241803873), ('impose', 1.0000104235623408), ('novel family', 1.0000104200558808), ('rich family', 1.0000104200558808), ('galaxies', 1.000010416981999), ('energy efficiency', 1.0000104136975614), ('spectrum', 1.0000103993712668), ('eer', 1.0000103988510012), ('board games', 1.0000103923680408), ('skills', 1.0000103672046228), ('insight', 1.0000103632332589), ('developmental', 1.0000103551153576), ('perturbed', 1.0000103481237408), ('gene expression', 1.0000103380001903), ('nest', 1.0000103291823772), ('block', 1.0000103291802946), ('adjustment', 1.0000103176870152), ('convolutional framelet expansion', 1.0000103109758627), ('assessments', 1.0000103021430193), ('points', 1.0000102835951117), ('desire fulfillment', 1.0000102823463495), ('sde', 1.000010280551981), ('flatter', 1.0000102804107822), ('larger', 1.0000102775409825), ('spite', 1.0000102616254523), ('listener', 1.0000102557984705), ('snli', 1.0000102443833923), ('sleep', 1.0000102440122256), ('abilities', 1.0000102435018285), ('characterize', 1.0000102418555485), ('aos', 1.000010224217796), ('simple kbqa', 1.0000102240042688), ('important step', 1.0000102195653096), ('logarithmic', 1.0000102087103357), ('historical', 1.0000102008862692), ('current', 1.0000102008862692), ('excellent results', 1.0000101968085073), ('zsl', 1.0000101831334436), ('exclusion', 1.000010175046222), ('background', 1.0000101704581212), ('partial', 1.0000101656575098), ('procure', 1.0000101384715747), ('toy', 1.0000101063558284), ('general', 1.0000101058207997), ('useful', 1.0000101057345827), ('torques', 1.000010097420579), ('systematic', 1.0000100946197281), ('trajectories', 1.0000100914093193), ('turn', 1.0000100913920331), ('diffusion', 1.0000100892743768), ('attachment', 1.000010080624944), ('degradation', 1.0000100770797378), ('small proportion', 1.0000100567850052), ('novel class', 1.0000100532090768), ('single drug', 1.0000100532090768), ('intent', 1.0000100499700373), ('example copynet', 1.0000100459741466), ('skin lesion', 1.0000100459741466), ('training chemnet', 1.0000100459741466), ('album summarization', 1.0000100459741466), ('other leading', 1.0000100387457638), ('regular training', 1.0000100384608834), ('recurrent randnns', 1.0000100384608834), ('split', 1.0000100270977013), ('bnns', 1.0000100183817808), ('relevant associations', 1.0000100183495153), ('babble', 1.000010014473412), ('art building', 1.000010001088228), ('ground', 1.0000099947700667), ('overhead', 1.000009993256654), ('devise', 1.0000099876268838), ('transferable', 1.000009974373611), ('chemical', 1.0000099683080244), ('essential ingredient', 1.000009967083612), ('phrases', 1.0000099659262236), ('person', 1.000009963705705), ('constructions', 1.0000099546008807), ('variability', 1.0000099457099312), ('bnn', 1.0000099422491413), ('expect', 1.0000099400584164), ('authorship', 1.0000099303576684), ('factors', 1.0000099264397275), ('entire', 1.000009906057361), ('late', 1.0000098989925341), ('quaero', 1.0000098968177267), ('alternate', 1.0000098875238497), ('unpredictable', 1.0000098860432725), ('stochastic differential equation', 1.0000098847758356), ('distinguish', 1.0000098706484333), ('drcn', 1.000009854939625), ('molecules', 1.0000098547860863), ('unmixing', 1.000009841484642), ('bring', 1.0000098321935234), ('pso mismo', 1.0000098280214813), ('central pattern generator', 1.0000098264191954), ('sinogram', 1.0000098105132966), ('tandem', 1.0000098074748636), ('biomedical', 1.000009799075875), ('policy training', 1.0000097928380343), ('invariances', 1.000009749337975), ('single cell', 1.0000097451527903), ('impressive examples', 1.000009737010735), ('dissertation', 1.000009731958047), ('executor', 1.0000097271464883), ('surgery', 1.0000097224491113), ('plant species', 1.0000097179817307), ('body part', 1.0000097179817307), ('kidney loss', 1.0000097179817307), ('art cldnn', 1.0000097179817307), ('neucube connectivity', 1.0000097179817307), ('motor policy', 1.0000097179817307), ('bags', 1.0000097053311225), ('actual', 1.0000096960227012), ('quadrupedal', 1.0000096861558196), ('network dfdqn', 1.0000096839835948), ('discard', 1.0000096753804033), ('rnnlm', 1.0000096625745016), ('main driving', 1.0000096539600756), ('rmsprop', 1.000009652638776), ('psychological representations', 1.0000096246753587), ('guide', 1.0000096145101423), ('organisers', 1.000009608416615), ('objection', 1.0000095957205082), ('conventional attention', 1.0000095944409113), ('debias', 1.00000958360698), ('consecutive waves', 1.0000095835981815), ('beat', 1.0000095784063434), ('rare', 1.0000095777845583), ('health', 1.0000095738438635), ('stimuli', 1.0000095696062994), ('terminology', 1.0000095683757453), ('movie', 1.0000095486914171), ('employees', 1.0000095455622606), ('medical abstracts', 1.0000095341858521), ('digital preservation', 1.0000095283216421), ('behaviour', 1.0000095194559386), ('first reported', 1.0000095127831992), ('phonetic lid', 1.0000094834624793), ('discussion', 1.0000094813436857), ('syllable', 1.0000094684645768), ('interval', 1.0000094682073795), ('regard', 1.0000094681670104), ('adjust', 1.000009464326022), ('reasons', 1.000009459074095), ('drmm yields', 1.0000094547934915), ('change', 1.0000094506695034), ('movies', 1.0000094344448536), ('analogs', 1.0000094312557282), ('lower', 1.0000094239563575), ('latter performs', 1.0000094110241213), ('observational', 1.000009394072408), ('ae', 1.000009384519939), ('difficulties', 1.0000093783571085), ('lagrange multiplier', 1.0000093766970013), ('epoch', 1.0000093700163533), ('meaning', 1.0000093633237326), ('sans', 1.0000093369661878), ('chain rule', 1.0000093360901186), ('become', 1.0000093306670708), ('segments', 1.0000093302086004), ('degrees', 1.000009292456222), ('drug', 1.0000092916848284), ('principal', 1.000009257763595), ('professional', 1.0000092530582934), ('carry', 1.0000092446770366), ('questioner', 1.0000092330309123), ('novel measure', 1.0000092247678212), ('lighting', 1.0000092161728225), ('language communication', 1.0000092087014694), ('grbms', 1.0000092061169015), ('phrases associated', 1.0000092059291863), ('minimisation', 1.0000091949912755), ('proposed corrnet', 1.0000091797639106), ('synthesized offspring', 1.0000091797639106), ('proposed m', 1.0000091797639106), ('maintain', 1.0000091738068453), ('limits', 1.0000091571472995), ('previous hboa', 1.000009151121857), ('high mountain', 1.000009151121857), ('neurodevelopmental biology', 1.000009151121857), ('other areas', 1.000009151121857), ('american sign', 1.000009151121857), ('nonparametric', 1.0000091500773094), ('strength', 1.0000091393473023), ('montalbano gesture', 1.0000091389893437), ('compactness term', 1.0000091388919585), ('researches', 1.0000091359817411), ('satisfaction', 1.0000091106768112), ('certainty', 1.0000091045308956), ('mat', 1.000009103442323), ('super resolution upsampling', 1.0000090926745258), ('teller', 1.0000090839347562), ('look', 1.0000090811438582), ('fulfill', 1.0000090559503103), ('language stories', 1.0000090405153856), ('planet', 1.0000090386090892), ('principles', 1.0000090327975089), ('prerequisite', 1.000009026394603), ('prevent', 1.0000090259016459), ('photograph', 1.000009016124641), ('skip', 1.000009005062621), ('pwl functions', 1.0000089979805717), ('foveal', 1.0000089979225628), ('transitions', 1.0000089954261187), ('parts', 1.0000089819926745), ('recent researches', 1.0000089334316045), ('counteract', 1.0000089270119994), ('main steps', 1.0000089212046555), ('m', 1.0000089191911894), ('sizes', 1.0000089189948067), ('realizing', 1.000008918929949), ('unfolding', 1.0000089092863902), ('assess', 1.0000088981601118), ('current leading', 1.0000088934332714), ('linear algebra', 1.0000088921553458), ('new state', 1.000008888285899), ('inflated sense', 1.0000088881228497), ('benefits', 1.0000088865397352), ('supervisory signal', 1.000008885693866), ('mythos', 1.000008877867758), ('heart rate', 1.0000088767825028), ('othello', 1.0000088744151252), ('dropping', 1.0000088696658704), ('gram', 1.0000088676172592), ('bird', 1.0000088580756685), ('classifications', 1.0000088546256583), ('predictron end', 1.0000088544659311), ('postulates', 1.000008839968033), ('spatial memory', 1.000008839804435), ('isolet', 1.0000088391282924), ('particular', 1.0000088105584344), ('loss surfaces', 1.000008803534996), ('clm', 1.0000087986789832), ('scenes', 1.0000087956338988), ('lines', 1.0000087666895088), ('mixed', 1.0000087594127265), ('pursue', 1.0000087586182387), ('better', 1.00000875563035), ('epochs', 1.0000087449338892), ('parkinson s', 1.000008741672708), ('cell', 1.0000087389846815), ('scoring', 1.000008731797283), ('quantitative', 1.0000087287039399), ('la belled', 1.0000087226439969), ('co', 1.0000087144911864), ('overview', 1.00000870514309), ('demonstrations', 1.0000086961341035), ('sensory input', 1.0000086956423535), ('ideas', 1.000008684964085), ('emerge', 1.000008679381861), ('lsa', 1.000008676486437), ('ambiguity', 1.0000086761467053), ('found', 1.0000086717671732), ('coupling', 1.0000086659693657), ('spherical', 1.000008665439851), ('fool', 1.0000086600615283), ('reflect', 1.0000086467508815), ('answerer', 1.0000086430290356), ('motor', 1.0000086302150386), ('cyclical', 1.000008618410932), ('regions', 1.0000085865934847), ('locality', 1.000008586055413), ('experienced', 1.000008583065482), ('easy', 1.0000085742456257), ('lrp', 1.0000085596975066), ('longest', 1.0000085552063753), ('mt', 1.0000085512503418), ('criteria', 1.000008547130404), ('gap', 1.0000085444107625), ('discrimination', 1.0000085200795517), ('realize', 1.0000085194992565), ('polyphonic music', 1.0000085096767242), ('curvature', 1.0000084937050913), ('lipschitz', 1.0000084880571547), ('retreat', 1.000008484063832), ('memory elstm', 1.000008473852968), ('memory dlstm', 1.000008473852968), ('children', 1.000008463298209), ('entailments', 1.0000084451942928), ('ratings', 1.0000084417641195), ('strategies', 1.0000084124205622), ('ehr', 1.0000084039049715), ('years', 1.0000083921263385), ('reviews', 1.0000083914010904), ('theorems', 1.0000083797374624), ('representative', 1.0000083619472617), ('shape', 1.0000083603116325), ('defense', 1.0000083601675371), ('academic', 1.000008347985891), ('justify', 1.0000083241268631), ('amounts', 1.0000083217370737), ('phenomena', 1.0000083199710978), ('scene', 1.0000083113443967), ('taxonomy', 1.0000083036780243), ('som', 1.000008297312352), ('coordinated', 1.0000082958624081), ('constructed', 1.0000082919034607), ('lip', 1.0000082895765365), ('corresponding', 1.0000082834203796), ('o', 1.0000082813666622), ('transferability', 1.0000082778348334), ('directions', 1.00000827067339), ('innovations', 1.0000082655927827), ('incomplete', 1.0000082653201292), ('chemistry', 1.0000082618809945), ('emotion', 1.0000082579493583), ('learned', 1.00000823538519), ('terpret specification', 1.0000082328383253), ('existing state', 1.00000823267741), ('hypotheses', 1.000008231730533), ('author', 1.000008231150566), ('catastrophic', 1.0000082278122195), ('gold standard', 1.0000082252368536), ('healthcare', 1.0000082095049037), ('working memory', 1.000008203599098), ('album', 1.0000082034261755), ('joint', 1.0000082000920316), ('exhibit', 1.0000081987866627), ('network dbrnn', 1.0000081892727122), ('networks mdrnn', 1.0000081892727122), ('harness', 1.00000818873873), ('essence', 1.0000081809943493), ('recognize', 1.0000081800157719), ('save', 1.0000081776549585), ('synonyms', 1.0000081710175313), ('conclude', 1.0000081662287699), ('reservoir', 1.0000081643961947), ('middle', 1.000008147395321), ('iapr tc12', 1.0000081463036439), ('rank', 1.000008139982268), ('attains results', 1.0000081322880212), ('resnets', 1.0000081319278484), ('hands', 1.0000081157477712), ('experimentation', 1.0000081139658679), ('k shot', 1.0000080947936358), ('compositions', 1.0000080904100825), ('lium', 1.00000808394543), ('plausible', 1.0000080816535626), ('neighborhood', 1.000008078864982), ('channels', 1.0000080499875226), ('honey', 1.0000080468277157), ('generalisations', 1.000008007182791), ('defense mechanisms', 1.0000080038942802), ('bradbury et', 1.0000079899802254), ('voice', 1.0000079899113612), ('ehrs', 1.0000079683471448), ('mixtures', 1.0000079609913195), ('downstream', 1.000007958118011), ('manifolds', 1.0000079554344377), ('psychological', 1.0000079508137691), ('sign', 1.0000079273284528), ('10k', 1.0000079210348485), ('sentiwordnet', 1.000007918761645), ('tease', 1.0000079150901677), ('supervise', 1.0000079015872891), ('give', 1.0000078899536557), ('subjects', 1.000007881881818), ('population', 1.0000078814495363), ('highway network', 1.000007874519247), ('internal', 1.0000078480716177), ('conjecture', 1.0000078356977833), ('course', 1.000007834024725), ('descriptiveness', 1.000007830643079), ('recognise', 1.0000078216487653), ('mammo', 1.000007821332406), ('clms', 1.0000078204495577), ('rest', 1.000007815747353), ('diabetic', 1.0000077853964582), ('successful', 1.0000077853964582), ('game theory', 1.0000077852656581), ('birth', 1.00000778023258), ('plant plant', 1.0000077779824275), ('cortical', 1.000007776242864), ('resolution', 1.0000077661131301), ('drawer', 1.0000077588739198), ('constrain', 1.0000077452702931), ('fivo', 1.000007743420824), ('clinicians', 1.0000077161936516), ('breast cancer', 1.0000077134579204), ('efficacy', 1.0000077130954397), ('observation period', 1.0000077034891446), ('authors', 1.0000077017276194), ('electroencephalograms', 1.0000076921287673), ('limited', 1.0000076855305584), ('dsr', 1.0000076807866343), ('satisfy', 1.0000076735649777), ('diversity', 1.0000076641064408), ('result achieved', 1.0000076529650923), ('disaster', 1.0000076355013932), ('tcga', 1.000007634704398), ('finding', 1.0000076203805344), ('network dcnn', 1.0000076177304775), ('hope', 1.0000076036251673), ('specific', 1.000007602813838), ('steps', 1.000007601544904), ('disciplines', 1.0000075980529841), ('predictron', 1.000007589167998), ('associated', 1.0000075619652389), ('philosophy', 1.000007539929843), ('curate', 1.000007537270573), ('isotropic', 1.0000075353883928), ('typical', 1.000007523268678), ('dude', 1.0000075229455512), ('results presented', 1.000007513695477), ('sa', 1.0000075052468156), ('much value', 1.0000074993880876), ('homework', 1.000007490188342), ('preservation', 1.0000074796439054), ('indices', 1.0000074752121737), ('conversations', 1.000007469330012), ('conflict', 1.0000074625498743), ('first person narrative', 1.0000074526535694), ('formulations', 1.000007438075666), ('undesirable', 1.0000074320673564), ('curved', 1.0000074275431654), ('placement', 1.000007415541848), ('substitute', 1.0000073922680721), ('note', 1.0000073920129586), ('ladder', 1.000007374674079), ('beginning', 1.0000073706927486), ('crucial', 1.0000073411650143), ('center', 1.0000073350292364), ('imagine', 1.0000073110434458), ('health informatics', 1.000007308127183), ('early', 1.000007303778707), ('imagination', 1.000007296223081), ('third', 1.000007294633143), ('adult', 1.0000072943616674), ('narrative', 1.0000072819807713), ('rectifier', 1.000007278837912), ('pdtb', 1.0000072736562067), ('cooperative', 1.0000072402720883), ('signers', 1.0000072370816495), ('regulariser', 1.0000072256254915), ('advances', 1.0000072217085807), ('rand', 1.0000072015038826), ('best', 1.0000071979158183), ('multilabel', 1.0000071911732809), ('b', 1.000007185106893), ('body', 1.0000071750260775), ('pcg', 1.0000071685535543), ('mistake', 1.000007166811136), ('snn emulation', 1.000007157900845), ('hindsight', 1.0000071530610048), ('earlier', 1.0000071500471805), ('diverse', 1.0000071498109862), ('finance', 1.0000071448504924), ('accommodate', 1.0000071368025611), ('widespread', 1.0000071321664132), ('child', 1.000007098049013), ('vision science', 1.0000070936634768), ('notable', 1.0000070912538142), ('skin', 1.0000070906345546), ('cognitive science', 1.0000070884966208), ('property', 1.0000070835932118), ('searchlight', 1.000007071426973), ('chapter', 1.0000070703622725), ('network hdnn', 1.000007065794348), ('ecgs', 1.0000070634620513), ('salient', 1.0000070615414962), ('human eye', 1.0000070572138648), ('related result', 1.0000070419708909), ('vocal tract', 1.0000070400276821), ('long term potentiation', 1.0000070189524117), ('life', 1.0000070126913922), ('bleu4', 1.000007002157235), ('outcomes', 1.0000069948215644), ('stairs', 1.0000069682592034), ('cheap', 1.000006960780386), ('articles', 1.000006958551764), ('growcut', 1.000006957829553), ('mirror', 1.0000069497888633), ('vgg', 1.0000069467328403), ('learnt', 1.0000069245786443), ('spherical harmonics', 1.0000069169304435), ('grounding', 1.0000069139441035), ('generalise', 1.000006904790931), ('gigaword', 1.000006895566547), ('significance', 1.0000068929333916), ('ontonotes', 1.000006872856822), ('probe', 1.000006868572871), ('spaces', 1.0000068651165945), ('compete', 1.0000068645261708), ('commercial', 1.000006863372994), ('pwl', 1.0000068551336545), ('car', 1.0000068461202223), ('particles', 1.0000068387332397), ('e', 1.0000068240955682), ('pictures', 1.0000068234137653), ('studies shows', 1.0000068199164869), ('formulate', 1.0000068156700643), ('shallow', 1.0000068111256435), ('outline', 1.0000068036473697), ('suppliers', 1.0000067971222772), ('collective', 1.000006794339721), ('suit', 1.000006779615999), ('pop', 1.000006778236484), ('validity', 1.0000067744631822), ('steer', 1.0000067605274297), ('gibbs', 1.0000067573179376), ('rules', 1.0000067463011306), ('genomics', 1.0000067323305482), ('screening', 1.0000067302780267), ('varying', 1.0000067256320169), ('distillation', 1.000006694087796), ('important', 1.0000066907848475), ('hop', 1.0000066825978955), ('revolutionise', 1.0000066598172914), ('recording', 1.0000066485535872), ('sda', 1.000006646864204), ('elaboration', 1.0000066390181948), ('dementia', 1.0000066371956506), ('gene', 1.0000066370360967), ('minutes', 1.0000066354346895), ('generating', 1.0000065897292565), ('inner', 1.0000065829429532), ('fixations', 1.0000065728868475), ('discovery', 1.0000065726083844), ('elbo', 1.000006559073028), ('pass', 1.0000065458468654), ('fall', 1.0000065379170227), ('issues', 1.0000065369091773), ('return', 1.0000065245171257), ('varied', 1.0000065042242923), ('speakers', 1.0000064914210807), ('500d', 1.000006489634393), ('applied', 1.0000064851787318), ('confer', 1.0000064807469442), ('typhoon', 1.0000064718539883), ('procedures', 1.0000064633608465), ('studies', 1.0000064612646988), ('sound', 1.000006432536453), ('pictorial', 1.0000064277965213), ('cognitive neuroscience', 1.0000064263291566), ('stock', 1.0000064033785623), ('statuses', 1.0000063629479774), ('morphological variation', 1.0000063600590858), ('neighboring', 1.0000063597151196), ('lifelong', 1.0000063527946255), ('closet', 1.0000063508469772), ('margins', 1.0000063478663788), ('groups', 1.0000063452115213), ('begin', 1.000006344488734), ('above', 1.0000063399552261), ('results will', 1.0000063386763425), ('rotation', 1.0000063374566752), ('combinations', 1.0000063302754554), ('worker', 1.0000063278237812), ('atns', 1.0000063262477596), ('satellite', 1.0000063190508546), ('conclusions', 1.0000063187442696), ('dqa', 1.0000063090293478), ('yolov2', 1.0000063058543887), ('relationships', 1.0000062965183145), ('variations', 1.0000062955374371), ('emotions', 1.0000062861327181), ('imdb', 1.0000062849966027), ('ways', 1.000006283789783), ('hard', 1.0000062683414175), ('clean', 1.0000062668503633), ('trust', 1.0000062629062119), ('stale', 1.0000062621608294), ('suggestion', 1.0000062590080772), ('properties', 1.00000625858936), ('waves', 1.0000062395134215), ('regards', 1.0000062221066197), ('short term', 1.000006208403801), ('struggle', 1.0000062074091944), ('american sign language', 1.0000061968084375), ('chinese', 1.0000061743743305), ('gender', 1.0000061612365556), ('film', 1.000006146950898), ('snail', 1.0000061422032582), ('defensive', 1.0000061333315236), ('walk', 1.0000061157315037), ('holy grail', 1.0000061129619566), ('movement', 1.0000061129026154), ('equal', 1.0000061017398292), ('nl', 1.0000061005543734), ('emnist', 1.0000060900297494), ('plasmodium', 1.0000060753492976), ('staphylococcus', 1.0000060753492976), ('head', 1.0000060731124802), ('forests', 1.0000060678267413), ('quantum field', 1.0000060559481945), ('introduction', 1.00000604082044), ('acer', 1.0000060333388363), ('potential', 1.0000060290602482), ('fine', 1.0000060218708355), ('uncertain', 1.0000060038923853), ('byproducts', 1.0000059971485544), ('dann', 1.000005990473852), ('max', 1.0000059637202083), ('entorhinal', 1.0000059603119618), ('cope', 1.0000059597364124), ('english penn', 1.0000059532483072), ('scales', 1.0000059460740292), ('audiovisual', 1.0000059441290994), ('biological target', 1.0000058931301647), ('additional', 1.0000058861225698), ('ear', 1.0000058851699847), ('tendency', 1.000005884483014), ('plasticity', 1.0000058836673489), ('entry', 1.0000058830652772), ('areas', 1.0000058819229747), ('transduction', 1.000005864749477), ('succeed', 1.0000058647129766), ('t', 1.0000058500998443), ('less', 1.000005846547237), ('coarse', 1.0000058422742368), ('guarantee', 1.0000058358532944), ('region', 1.0000058348412657), ('transcriptions', 1.000005808297785), ('cider', 1.0000058076378968), ('balls', 1.0000058057658032), ('indicate', 1.0000057964394249), ('actor', 1.0000057940155924), ('modest', 1.0000057903307786), ('srn', 1.0000057737703272), ('metaphorical composition', 1.0000057657924417), ('investigation', 1.0000057581342723), ('times', 1.0000057508915485), ('endeavor', 1.0000057406047205), ('resort', 1.0000057387542998), ('unrelated', 1.0000057271897802), ('polyphonic', 1.000005716505835), ('road', 1.0000057054148228), ('enrich', 1.0000056929004508), ('bleu', 1.0000056869405216), ('blood', 1.000005684976723), ('great', 1.0000056845673173), ('resonate', 1.0000056841988945), ('regional', 1.0000056835840294), ('players', 1.000005681225816), ('potentiality', 1.0000056696210184), ('hdp', 1.00000566839977), ('qmdp', 1.000005664430191), ('imitate', 1.00000565893061), ('achieving', 1.0000056560128554), ('penalty', 1.0000056545419596), ('science', 1.0000056500158552), ('compression ratio', 1.0000056480269173), ('cpg', 1.000005635718371), ('offer', 1.0000056302178852), ('gaps', 1.000005622115694), ('supervised growcut', 1.000005621932922), ('put', 1.0000056057826754), ('paraphrasing', 1.0000055794130387), ('stem', 1.0000055600640494), ('superiority', 1.000005545191207), ('real line', 1.0000055409577582), ('omniglot', 1.000005540516078), ('lebesgue', 1.0000055254571818), ('measure theory', 1.0000055141426483), ('impairments', 1.0000055088452757), ('catastrophes', 1.0000054986441438), ('student teacher', 1.000005474309032), ('couple', 1.0000054642365448), ('suffer', 1.0000054608244069), ('unpaired', 1.0000054600758084), ('span', 1.0000054510719707), ('extrinsic', 1.0000054398869178), ('good', 1.000005439638036), ('conduct', 1.0000054297370304), ('operation', 1.0000054268004666), ('hippocampus', 1.0000054226526132), ('differential equations', 1.00000541423172), ('nasnet', 1.000005393178396), ('scarce', 1.000005380001864), ('kyoto university', 1.0000053797186228), ('consumer', 1.0000053716382054), ('environmental', 1.0000053630695573), ('right', 1.000005358764896), ('lsst', 1.0000053477528286), ('strengths', 1.0000053438808147), ('averages', 1.0000053438634329), ('memcomputing', 1.0000053406868543), ('related', 1.0000053330061827), ('additional experiments', 1.000005321950766), ('intensive', 1.0000053207822324), ('lottery', 1.0000053180546469), ('reprocess', 1.000005284079677), ('complicated', 1.0000052812192843), ('equality', 1.0000052741815342), ('41m', 1.0000052708958405), ('rap', 1.0000052669291766), ('smiles', 1.0000052559044232), ('situations', 1.0000052513687816), ('successes', 1.0000052455432826), ('biology', 1.0000052454341213), ('stimulation', 1.0000052292860664), ('interesting', 1.0000052292801747), ('molecular biology', 1.0000052279558989), ('phonetic', 1.000005225408225), ('predilection', 1.0000052187283148), ('competition', 1.0000051974797926), ('wave', 1.0000051847228502), ('emergency department', 1.0000051818576396), ('post', 1.0000051798544274), ('hopes', 1.000005166027214), ('orbits', 1.0000051622214776), ('audience', 1.0000051587662688), ('narratives', 1.0000051555440186), ('newtonian', 1.000005139100829), ('secondary', 1.0000051353431352), ('history', 1.0000051352767299), ('expense', 1.000005101085184), ('transduce', 1.000005046765213), ('entries', 1.000005045746086), ('products', 1.0000050449717173), ('intervention', 1.0000050301342656), ('ann', 1.0000050250665142), ('genome', 1.0000050217316454), ('candidates', 1.0000050130396374), ('imbalance', 1.000005010320403), ('leg', 1.0000050062983064), ('iris pima', 1.0000049849079682), ('stereotypical', 1.000004981440479), ('ratio', 1.0000049812897434), ('majorization', 1.000004957946919), ('lake', 1.0000049572366458), ('reasonable', 1.0000049404206006), ('hold', 1.0000049321145483), ('conclusion', 1.0000049128516306), ('article', 1.0000048918320734), ('audiences', 1.0000048904137118), ('lead', 1.000004889185712), ('wall', 1.0000048837533464), ('statistical mechanics', 1.0000048808586617), ('deconvolutional', 1.0000048745966355), ('decoys', 1.0000048566609088), ('training schemes', 1.0000048506928343), ('stop', 1.000004846142602), ('experiment', 1.0000048429232908), ('rhyme', 1.0000048274732052), ('surgery records', 1.0000048239183206), ('trade', 1.0000048182248438), ('discriminative bicluster', 1.0000048167411189), ('infants', 1.0000048042518366), ('clothes', 1.00000480194019), ('chemical industry', 1.0000047949510666), ('refer', 1.0000047900005844), ('measures', 1.0000047802853247), ('cognitive development', 1.0000047717318816), ('interrelation', 1.0000047613066714), ('board', 1.0000047603091975), ('arnet', 1.0000047454090013), ('subsequent', 1.0000047326833323), ('eda', 1.0000047269834489), ('disease', 1.000004725394253), ('trajectory', 1.0000047228091546), ('significant gains', 1.0000047153732998), ('contribution', 1.000004712589513), ('preserve', 1.0000047088032167), ('english', 1.0000047076739422), ('lid', 1.0000046916960643), ('lion', 1.0000046892139853), ('growth', 1.000004688229819), ('chemnet', 1.0000046839612993), ('temperature', 1.000004680441306), ('area', 1.0000046797975306), ('topical', 1.000004667992371), ('unrecognizable', 1.0000046641846512), ('majority', 1.0000046625279995), ('rnnai', 1.0000046610072846), ('biomedicine', 1.0000046481590863), ('know', 1.000004608794092), ('mdnn', 1.000004593986646), ('bloom', 1.0000045912075837), ('convolutional framelet', 1.000004571576407), ('clas', 1.000004561101714), ('symmetry', 1.0000045577583647), ('imbalanced', 1.000004554247475), ('can', 1.0000045475158865), ('apprenticeship', 1.0000045197007488), ('tpot', 1.0000045143785061), ('compound', 1.0000045013894983), ('selective', 1.0000045010758085), ('oncology', 1.0000044992100037), ('magnitudes', 1.0000044918220496), ('lecturer', 1.0000044878175949), ('motivation', 1.0000044803101085), ('fcn', 1.0000044791097258), ('translational', 1.0000044772851038), ('cardiac', 1.0000044751730635), ('deteriorate', 1.0000044746220238), ('ablation study', 1.0000044712550082), ('depending', 1.000004469474538), ('preexisting', 1.0000044575839686), ('baggage', 1.0000044539406452), ('ffnn', 1.000004450855901), ('network vggnet', 1.0000044279058817), ('categories', 1.0000044188431128), ('mazebase', 1.0000044152215035), ('ablation', 1.0000044007468245), ('choices', 1.0000043997118933), ('crux', 1.000004397216941), ('autism', 1.0000043861378038), ('microphone', 1.0000043801743714), ('high energy physics', 1.0000043763758044), ('phenomenon', 1.0000043754369683), ('health care', 1.0000043681020907), ('fovea', 1.0000043424342262), ('material', 1.0000043397944562), ('fooling', 1.0000043360444508), ('nse', 1.0000043144563484), ('aid', 1.000004304424077), ('legged', 1.0000042885858336), ('cancer', 1.0000042487525362), ('described', 1.0000042221630665), ('proper nouns', 1.000004214343141), ('pixeldcl', 1.0000041993635933), ('back', 1.0000041938719706), ('foolbox', 1.0000041836919675), ('independent', 1.0000041748268322), ('earthquake', 1.0000041661273416), ('paintings', 1.0000041605670429), ('progression', 1.0000041437496545), ('emergency', 1.0000041408847873), ('tar', 1.0000041404960607), ('biases', 1.0000041334726764), ('chemception', 1.0000041203550274), ('rates', 1.000004118842264), ('pronunciation', 1.0000041183934818), ('human skeleton', 1.000004100248025), ('neucube', 1.0000040957140348), ('spirit', 1.0000040954454246), ('renormalization group', 1.0000040852666894), ('extensive', 1.0000040787356779), ('shot', 1.000004075737098), ('hypothesize', 1.0000040738603269), ('absorb', 1.0000040713812064), ('catastrophe', 1.0000040526797358), ('association', 1.0000040261298864), ('rnn clm', 1.0000040232964063), ('freezing', 1.0000040123595086), ('lag', 1.0000040112661577), ('therapy', 1.000004008099443), ('medicine', 1.000003998745593), ('hemodynamic', 1.0000039929527818), ('newtonian mechanics', 1.0000039914082979), ('daily', 1.0000039752911607), ('name', 1.0000039714946733), ('tell', 1.0000039567011667), ('novelty', 1.0000039539629324), ('today', 1.000003943719125), ('coral correlation', 1.000003939612644), ('referent', 1.0000039387030004), ('blanks', 1.0000039376284573), ('specialise', 1.0000038900780215), ('circle', 1.0000038860893843), ('thousands', 1.0000038850817072), ('relations', 1.0000038676664822), ('benefit', 1.0000038535846196), ('forecast', 1.0000038517887477), ('favor', 1.0000038404474019), ('restaurant', 1.0000038353944207), ('popular', 1.0000038252997179), ('particle physics', 1.000003802092927), ('instability', 1.0000037855624884), ('phonetic transcription', 1.0000037660722223), ('committee', 1.0000037624383626), ('shed', 1.0000037564410962), ('equilibrium', 1.0000037543499283), ('morpheme', 1.0000037529613506), ('confirm', 1.0000037508954602), ('letters', 1.0000037399913824), ('numbers', 1.0000037377502433), ('quantity', 1.0000037374378217), ('consequences', 1.000003729287182), ('reported', 1.0000037169272857), ('breed', 1.0000037107969209), ('shortlist', 1.000003697881481), ('dialectical', 1.0000036971109802), ('damages', 1.000003693908435), ('states', 1.0000036918123167), ('hdnn', 1.000003691481149), ('deliver', 1.0000036797391827), ('cardiovascular', 1.0000036790731779), ('desire', 1.0000036742661007), ('shareboost', 1.0000036694246663), ('posenet', 1.0000036694246663), ('sprl', 1.0000036521980078), ('examining', 1.0000036374506454), ('credit', 1.000003583323327), ('practitioners', 1.0000035777955179), ('curb', 1.0000035362095538), ('squishednets', 1.0000035360783974), ('dialectic', 1.0000035328013928), ('state farm', 1.000003527533488), ('cast', 1.000003526997416), ('bonus', 1.0000035137510177), ('vary', 1.0000035124331224), ('interior', 1.0000035037506223), ('gaes', 1.0000035031695198), ('motions', 1.0000034979094068), ('observed', 1.0000034969919671), ('bear', 1.0000034942818787), ('german language', 1.0000034793330141), ('newborns', 1.0000034751194653), ('dentate gyrus', 1.0000034615493487), ('cardiovascular disease', 1.000003454518684), ('impair', 1.0000034517706538), ('woman', 1.00000344702043), ('concert', 1.0000034380203693), ('smaller', 1.0000034343901023), ('bee', 1.0000034048406792), ('heart', 1.0000033988323977), ('inspiration', 1.000003381670206), ('penultimate', 1.000003372819168), ('pgnn', 1.000003372268343), ('assistance', 1.000003368651147), ('promising', 1.0000033540433826), ('zsc datasets', 1.0000033491639624), ('topicrnn', 1.0000033460571902), ('reservoirs', 1.000003340447198), ('kafs', 1.0000033390243668), ('big', 1.000003327489671), ('moe', 1.0000033220146813), ('lower state', 1.0000033195350106), ('girl', 1.000003315110972), ('neucube spiking', 1.0000033129339072), ('proportion', 1.0000033068272491), ('merck', 1.0000033041338285), ('tower', 1.000003300664817), ('student', 1.0000032546359763), ('mauna loa', 1.000003251674006), ('intervene', 1.0000032483609052), ('birth rate', 1.000003229444105), ('resources', 1.0000032151802032), ('pretreatment', 1.0000031793709085), ('stage', 1.0000031703998784), ('pain', 1.0000031623747765), ('supplement', 1.00000316052743), ('research suggests', 1.0000031489013521), ('plant', 1.0000031457115865), ('appearance', 1.0000031394609143), ('reinstate', 1.0000031352143546), ('strong interaction', 1.000003127947083), ('scarcity', 1.0000031201623898), ('homemaker', 1.0000031117428543), ('fw', 1.0000031054163803), ('competence', 1.0000031047010185), ('dialectics', 1.0000031045903706), ('elucidate', 1.000003098480944), ('reading', 1.000003092674395), ('enwik8', 1.0000030836305354), ('cat', 1.0000030815109717), ('diagnose', 1.000003063478374), ('peak', 1.000003048704969), ('while', 1.0000030165383296), ('fundamental frequency', 1.000003008320715), ('scientific journals', 1.0000029765816014), ('modulate', 1.0000029749889263), ('pharmaceuticals', 1.0000029735947458), ('dna', 1.0000029468321803), ('believe', 1.000002935791893), ('pretrain', 1.0000029238287182), ('dcns', 1.000002902400668), ('fsmn', 1.000002893571724), ('see', 1.000002884709665), ('market', 1.000002873786219), ('npb', 1.0000028635846336), ('circnn', 1.0000028635846336), ('european', 1.0000028635846336), ('samdp', 1.0000028635846336), ('drae', 1.0000028328866546), ('inquiry', 1.0000028279065134), ('versatility', 1.0000028197998214), ('mammalian', 1.0000028138973631), ('corrections', 1.0000027997935002), ('kbqa', 1.0000027899333384), ('hippocampal entorhinal', 1.0000027822324977), ('iluga', 1.0000027761123587), ('75.3.', 1.0000027531258957), ('budget', 1.00000274131815), ('senses', 1.0000027210236362), ('dybm', 1.000002715174579), ('fields', 1.000002713679787), ('dearth', 1.0000027124863695), ('corrnet', 1.0000027106633722), ('learning metholodogies', 1.0000027078120002), ('dstc2', 1.0000027072313256), ('hippocampal', 1.0000027017601116), ('gains', 1.0000026994174653), ('medical oncology', 1.0000026896644538), ('regulatory', 1.0000026755745552), ('chemception augchemception', 1.0000026697062045), ('cerebrospinal', 1.0000026561098236), ('rich', 1.0000026561098236), ('unprecedented', 1.0000026561098236), ('la', 1.0000026561098236), ('atrous', 1.0000026561098236), ('bay area', 1.0000026454856255), ('mnns', 1.0000026439366987), ('situation', 1.000002638184315), ('vicinity', 1.0000026346160091), ('exceptional diversity', 1.0000026270933318), ('sgan', 1.0000026238385635), ('severe', 1.0000026227913075), ('surroundings', 1.0000025718836723), ('homeland', 1.0000025705794235), ('changing', 1.0000025667941268), ('result shows', 1.0000025609074452), ('bradbury', 1.0000025294820132), ('solubility', 1.0000025062733842), ('arabase', 1.0000025062733842), ('avletters', 1.0000025062733842), ('bioasq', 1.0000025062733842), ('school', 1.0000024726506624), ('unk', 1.0000024442802875), ('kidney', 1.0000024215295151), ('plsom', 1.0000024215295151), ('wsabie', 1.000002408516627), ('positions', 1.0000023882115023), ('patients', 1.0000023712620707), ('attempts', 1.000002334752257), ('several areas', 1.0000023331420418), ('propensity', 1.0000023206649375), ('hybridization', 1.0000023157148092), ('cbt', 1.0000023132532547), ('exemplify', 1.000002298418725), ('education', 1.0000022912703532), ('neighbourhood', 1.0000022846006706), ('multitude', 1.0000022845111667), ('lie', 1.000002280401896), ('mark', 1.0000022723292592), ('treatments', 1.0000022686877952), ('reencoder', 1.000002257756213), ('blstm', 1.000002257756213), ('webquestions', 1.000002253224503), ('webqa', 1.000002253224503), ('simplequestions', 1.000002253224503), ('training episodes', 1.0000022506886452), ('joints', 1.0000022486220048), ('randnns', 1.0000022486220048), ('automobile', 1.0000022486220048), ('tamil', 1.000002244786824), ('hyperquadrics', 1.0000022306968115), ('consumption', 1.000002216540642), ('gcnn', 1.000002202829846), ('randnn', 1.000002202829846), ('benn', 1.000002202829846), ('denn', 1.000002202829846), ('tens', 1.000002202482645), ('water', 1.000002200763435), ('treatment', 1.0000021590001438), ('constituent', 1.0000021570185473), ('lifetime', 1.0000021390521114), ('cf', 1.000002104126166), ('action research', 1.0000020954242879), ('involve', 1.0000020708210697), ('ours', 1.000002050483829), ('drelus', 1.000002050483829), ('returnn', 1.000002050483829), ('correntropy', 1.000002047155783), ('narrativeqa', 1.0000020430155716), ('muscle', 1.0000020084050945), ('toxicity', 1.0000019510021718), ('swwae', 1.0000019510021718), ('esom', 1.0000019510021718), ('masses', 1.0000019510021718), ('tumor', 1.0000019510021718), ('138k', 1.0000019510021718), ('copynet', 1.0000019510021718), ('buildings', 1.0000019510021718), ('breast', 1.0000019510021718), ('ames', 1.0000019510021718), ('keyvec', 1.0000019510021718), ('nobacktrack', 1.0000019510021718), ('rlstms', 1.0000019510021718), ('hill', 1.0000019492658503), ('marginalize', 1.0000019237572046), ('neuroner', 1.0000019119560293), ('prescriptions', 1.0000019052071567), ('pendubot', 1.0000018866588314), ('dialogues', 1.0000018832004043), ('stud', 1.000001874464087), ('concentrate', 1.000001866501536), ('category', 1.0000018531874186), ('compounds', 1.0000018455434532), ('bringing', 1.0000018103063382), ('relate', 1.0000018103063382), ('luck', 1.0000018103063382), ('undergo', 1.0000018103063382), ('judge', 1.0000018103063382), ('miss', 1.0000018103063382), ('appear', 1.0000018103063382), ('era', 1.0000017926560822), ('senones', 1.0000017882684802), ('dialect', 1.0000017759267366), ('achieved', 1.000001754266255), ('falls', 1.00000175290332), ('maesn', 1.0000017514535713), ('venations', 1.0000017514535713), ('deepmatch', 1.0000017514535713), ('esqns', 1.0000017514535713), ('dragan', 1.0000017514535713), ('adasent', 1.0000017514535713), ('abot', 1.0000017514535713), ('neurogenesis', 1.0000017514535713), ('economy', 1.0000017374460972), ('30s', 1.0000016999441101), ('htrts', 1.0000016999441101), ('occasion', 1.0000016999441101), ('species', 1.0000016950892665), ('diseases', 1.000001631369605), ('fashion', 1.000001631369605), ('tissues', 1.0000016268589813), ('neuralnetworks', 1.0000016268589813), ('regimes', 1.0000016268589813), ('sluice', 1.0000016268589813), ('will', 1.0000016067689816), ('regime', 1.0000015658089114), ('dcgan', 1.00000155828325), ('anatomy', 1.0000015439187353), ('charit', 1.0000015193640828), ('nrm', 1.0000015140748255), ('clinic', 1.0000015013440529), ('catalogue', 1.0000015013440529), ('formation', 1.0000015013440529), ('painting', 1.000001469606177), ('thanks', 1.00000146497548), ('rnnsearch', 1.000001445284999), ('dbrnn', 1.0000014396658017), ('prednet', 1.0000014396658017), ('tbcnn', 1.0000014396658017), ('dcnn', 1.0000014396658017), ('chromatin', 1.0000014294617119), ('metholodogies', 1.0000013540988895), ('pmc', 1.000001352215576), ('deconvnet', 1.0000013253777875), ('cldnn', 1.0000013128340026), ('abundances', 1.0000013099638616), ('mnn', 1.000001291850917), ('convolutional framelets', 1.0000012772347477), ('performed', 1.000001234973228), ('anatomical structures', 1.0000012091873194), ('bechnmark', 1.0000011772708641), ('prospect', 1.0000011522469883), ('choreographer', 1.0000010414983884), ('solo', 1.0000010414983884), ('bodies', 1.000001030867348), ('discharge', 1.0000010088207123), ('claims', 1.0000010009388647), ('conducted', 1.0000009972390875), ('investigated', 1.0000009972390875), ('participated', 1.0000009972390875), ('abundance', 1.0000009810551491), ('amendment', 1.0000009457048107), ('elstm', 1.0000009105611307), ('stages', 1.0000008942249283), ('period', 1.0000008853021298), ('da', 1.0000008261870053), ('fpsrl', 1.0000007278613596), ('investigators', 1.0000007240779802), ('regimen', 1.0000007203147843), ('merits', 1.0000005422594598), ('zsc', 1.000000380365391), ('guesswhat', 1.000000380365391), ('episodes', 1.000000264558933)]
[LOG]: Error count: 0
